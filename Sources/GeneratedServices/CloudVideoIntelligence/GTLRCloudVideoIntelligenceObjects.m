// NOTE: This file was generated by the ServiceGenerator.

// ----------------------------------------------------------------------------
// API:
//   Cloud Video Intelligence API (videointelligence/v1)
// Description:
//   Detects objects, explicit content, and scene changes in videos. It also
//   specifies the region for annotation and transcribes speech to text.
//   Supports both asynchronous API and streaming API.
// Documentation:
//   https://cloud.google.com/video-intelligence/docs/

#import <GoogleAPIClientForREST/GTLRCloudVideoIntelligenceObjects.h>

// ----------------------------------------------------------------------------
// Constants

// GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoRequest.features
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoRequest_Features_ExplicitContentDetection = @"EXPLICIT_CONTENT_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoRequest_Features_FaceDetection = @"FACE_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoRequest_Features_FeatureUnspecified = @"FEATURE_UNSPECIFIED";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoRequest_Features_LabelDetection = @"LABEL_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoRequest_Features_LogoRecognition = @"LOGO_RECOGNITION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoRequest_Features_ObjectTracking = @"OBJECT_TRACKING";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoRequest_Features_PersonDetection = @"PERSON_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoRequest_Features_ShotChangeDetection = @"SHOT_CHANGE_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoRequest_Features_SpeechTranscription = @"SPEECH_TRANSCRIPTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoRequest_Features_TextDetection = @"TEXT_DETECTION";

// GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ExplicitContentFrame.pornographyLikelihood
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ExplicitContentFrame_PornographyLikelihood_LikelihoodUnspecified = @"LIKELIHOOD_UNSPECIFIED";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ExplicitContentFrame_PornographyLikelihood_Likely = @"LIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ExplicitContentFrame_PornographyLikelihood_Possible = @"POSSIBLE";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ExplicitContentFrame_PornographyLikelihood_Unlikely = @"UNLIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ExplicitContentFrame_PornographyLikelihood_VeryLikely = @"VERY_LIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ExplicitContentFrame_PornographyLikelihood_VeryUnlikely = @"VERY_UNLIKELY";

// GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress.feature
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress_Feature_ExplicitContentDetection = @"EXPLICIT_CONTENT_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress_Feature_FaceDetection = @"FACE_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress_Feature_FeatureUnspecified = @"FEATURE_UNSPECIFIED";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress_Feature_LabelDetection = @"LABEL_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress_Feature_LogoRecognition = @"LOGO_RECOGNITION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress_Feature_ObjectTracking = @"OBJECT_TRACKING";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress_Feature_PersonDetection = @"PERSON_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress_Feature_ShotChangeDetection = @"SHOT_CHANGE_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress_Feature_SpeechTranscription = @"SPEECH_TRANSCRIPTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress_Feature_TextDetection = @"TEXT_DETECTION";

// GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentFrame.pornographyLikelihood
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentFrame_PornographyLikelihood_LikelihoodUnspecified = @"LIKELIHOOD_UNSPECIFIED";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentFrame_PornographyLikelihood_Likely = @"LIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentFrame_PornographyLikelihood_Possible = @"POSSIBLE";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentFrame_PornographyLikelihood_Unlikely = @"UNLIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentFrame_PornographyLikelihood_VeryLikely = @"VERY_LIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentFrame_PornographyLikelihood_VeryUnlikely = @"VERY_UNLIKELY";

// GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelDetectionConfig.labelDetectionMode
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelDetectionConfig_LabelDetectionMode_FrameMode = @"FRAME_MODE";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelDetectionConfig_LabelDetectionMode_LabelDetectionModeUnspecified = @"LABEL_DETECTION_MODE_UNSPECIFIED";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelDetectionConfig_LabelDetectionMode_ShotAndFrameMode = @"SHOT_AND_FRAME_MODE";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelDetectionConfig_LabelDetectionMode_ShotMode = @"SHOT_MODE";

// GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ExplicitContentFrame.pornographyLikelihood
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ExplicitContentFrame_PornographyLikelihood_LikelihoodUnspecified = @"LIKELIHOOD_UNSPECIFIED";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ExplicitContentFrame_PornographyLikelihood_Likely = @"LIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ExplicitContentFrame_PornographyLikelihood_Possible = @"POSSIBLE";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ExplicitContentFrame_PornographyLikelihood_Unlikely = @"UNLIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ExplicitContentFrame_PornographyLikelihood_VeryLikely = @"VERY_LIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ExplicitContentFrame_PornographyLikelihood_VeryUnlikely = @"VERY_UNLIKELY";

// GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress.feature
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress_Feature_ExplicitContentDetection = @"EXPLICIT_CONTENT_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress_Feature_FaceDetection = @"FACE_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress_Feature_FeatureUnspecified = @"FEATURE_UNSPECIFIED";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress_Feature_LabelDetection = @"LABEL_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress_Feature_LogoRecognition = @"LOGO_RECOGNITION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress_Feature_ObjectTracking = @"OBJECT_TRACKING";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress_Feature_PersonDetection = @"PERSON_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress_Feature_ShotChangeDetection = @"SHOT_CHANGE_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress_Feature_SpeechTranscription = @"SPEECH_TRANSCRIPTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress_Feature_TextDetection = @"TEXT_DETECTION";

// GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ExplicitContentFrame.pornographyLikelihood
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ExplicitContentFrame_PornographyLikelihood_LikelihoodUnspecified = @"LIKELIHOOD_UNSPECIFIED";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ExplicitContentFrame_PornographyLikelihood_Likely = @"LIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ExplicitContentFrame_PornographyLikelihood_Possible = @"POSSIBLE";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ExplicitContentFrame_PornographyLikelihood_Unlikely = @"UNLIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ExplicitContentFrame_PornographyLikelihood_VeryLikely = @"VERY_LIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ExplicitContentFrame_PornographyLikelihood_VeryUnlikely = @"VERY_UNLIKELY";

// GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress.feature
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress_Feature_ExplicitContentDetection = @"EXPLICIT_CONTENT_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress_Feature_FaceDetection = @"FACE_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress_Feature_FeatureUnspecified = @"FEATURE_UNSPECIFIED";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress_Feature_LabelDetection = @"LABEL_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress_Feature_LogoRecognition = @"LOGO_RECOGNITION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress_Feature_ObjectTracking = @"OBJECT_TRACKING";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress_Feature_PersonDetection = @"PERSON_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress_Feature_ShotChangeDetection = @"SHOT_CHANGE_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress_Feature_SpeechTranscription = @"SPEECH_TRANSCRIPTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress_Feature_TextDetection = @"TEXT_DETECTION";

// GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ExplicitContentFrame.pornographyLikelihood
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ExplicitContentFrame_PornographyLikelihood_LikelihoodUnspecified = @"LIKELIHOOD_UNSPECIFIED";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ExplicitContentFrame_PornographyLikelihood_Likely = @"LIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ExplicitContentFrame_PornographyLikelihood_Possible = @"POSSIBLE";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ExplicitContentFrame_PornographyLikelihood_Unlikely = @"UNLIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ExplicitContentFrame_PornographyLikelihood_VeryLikely = @"VERY_LIKELY";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ExplicitContentFrame_PornographyLikelihood_VeryUnlikely = @"VERY_UNLIKELY";

// GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress.feature
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress_Feature_CelebrityRecognition = @"CELEBRITY_RECOGNITION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress_Feature_ExplicitContentDetection = @"EXPLICIT_CONTENT_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress_Feature_FaceDetection = @"FACE_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress_Feature_FeatureUnspecified = @"FEATURE_UNSPECIFIED";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress_Feature_LabelDetection = @"LABEL_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress_Feature_LogoRecognition = @"LOGO_RECOGNITION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress_Feature_ObjectTracking = @"OBJECT_TRACKING";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress_Feature_PersonDetection = @"PERSON_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress_Feature_ShotChangeDetection = @"SHOT_CHANGE_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress_Feature_SpeechTranscription = @"SPEECH_TRANSCRIPTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress_Feature_TextDetection = @"TEXT_DETECTION";

// GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress.feature
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress_Feature_ExplicitContentDetection = @"EXPLICIT_CONTENT_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress_Feature_FaceDetection = @"FACE_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress_Feature_FeatureUnspecified = @"FEATURE_UNSPECIFIED";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress_Feature_LabelDetection = @"LABEL_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress_Feature_LogoRecognition = @"LOGO_RECOGNITION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress_Feature_ObjectTracking = @"OBJECT_TRACKING";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress_Feature_PersonDetection = @"PERSON_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress_Feature_ShotChangeDetection = @"SHOT_CHANGE_DETECTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress_Feature_SpeechTranscription = @"SPEECH_TRANSCRIPTION";
NSString * const kGTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress_Feature_TextDetection = @"TEXT_DETECTION";

// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoProgress
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoProgress
@dynamic annotationProgress;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"annotationProgress" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoRequest
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoRequest
@dynamic features, inputContent, inputUri, locationId, outputUri, videoContext;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"features" : [NSString class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoResponse
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1AnnotateVideoResponse
@dynamic annotationResults;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"annotationResults" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationResults class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2AnnotateVideoProgress
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2AnnotateVideoProgress
@dynamic annotationProgress;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"annotationProgress" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2AnnotateVideoResponse
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2AnnotateVideoResponse
@dynamic annotationResults;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"annotationResults" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationResults class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2DetectedAttribute
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2DetectedAttribute
@dynamic confidence, name, value;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2DetectedLandmark
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2DetectedLandmark
@dynamic confidence, name, point;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2Entity
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2Entity
@dynamic descriptionProperty, entityId, languageCode;

+ (NSDictionary<NSString *, NSString *> *)propertyToJSONKeyMap {
  return @{ @"descriptionProperty" : @"description" };
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ExplicitContentAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ExplicitContentAnnotation
@dynamic frames, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ExplicitContentFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ExplicitContentFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ExplicitContentFrame
@dynamic pornographyLikelihood, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2FaceAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2FaceAnnotation
@dynamic frames, segments, thumbnail;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2FaceFrame class],
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2FaceSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2FaceDetectionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2FaceDetectionAnnotation
@dynamic thumbnail, tracks, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2FaceFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2FaceFrame
@dynamic normalizedBoundingBoxes, timeOffset;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"normalizedBoundingBoxes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2NormalizedBoundingBox class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2FaceSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2FaceSegment
@dynamic segment;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LabelAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LabelAnnotation
@dynamic categoryEntities, entity, frames, segments, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"categoryEntities" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2Entity class],
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LabelFrame class],
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LabelSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LabelFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LabelFrame
@dynamic confidence, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LabelSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LabelSegment
@dynamic confidence, segment;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LogoRecognitionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LogoRecognitionAnnotation
@dynamic entity, segments, tracks;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoSegment class],
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2NormalizedBoundingBox
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2NormalizedBoundingBox
@dynamic bottom, left, right, top;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2NormalizedBoundingPoly
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2NormalizedBoundingPoly
@dynamic vertices;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"vertices" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2NormalizedVertex class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2NormalizedVertex
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2NormalizedVertex
@dynamic x, y;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ObjectTrackingAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ObjectTrackingAnnotation
@dynamic confidence, entity, frames, segment, trackId, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ObjectTrackingFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ObjectTrackingFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ObjectTrackingFrame
@dynamic normalizedBoundingBox, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2PersonDetectionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2PersonDetectionAnnotation
@dynamic tracks, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2SpeechRecognitionAlternative
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2SpeechRecognitionAlternative
@dynamic confidence, transcript, words;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"words" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2WordInfo class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2SpeechTranscription
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2SpeechTranscription
@dynamic alternatives, languageCode;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"alternatives" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2SpeechRecognitionAlternative class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2TextAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2TextAnnotation
@dynamic segments, text, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2TextSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2TextFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2TextFrame
@dynamic rotatedBoundingBox, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2TextSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2TextSegment
@dynamic confidence, frames, segment;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2TextFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2TimestampedObject
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2TimestampedObject
@dynamic attributes, landmarks, normalizedBoundingBox, timeOffset;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"attributes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2DetectedAttribute class],
    @"landmarks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2DetectedLandmark class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2Track
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2Track
@dynamic attributes, confidence, segment, timestampedObjects;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"attributes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2DetectedAttribute class],
    @"timestampedObjects" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2TimestampedObject class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationProgress
@dynamic feature, inputUri, progressPercent, segment, startTime, updateTime;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationResults
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoAnnotationResults
@dynamic error, explicitAnnotation, faceAnnotations, faceDetectionAnnotations,
         frameLabelAnnotations, inputUri, logoRecognitionAnnotations,
         objectAnnotations, personDetectionAnnotations, segment,
         segmentLabelAnnotations, segmentPresenceLabelAnnotations,
         shotAnnotations, shotLabelAnnotations, shotPresenceLabelAnnotations,
         speechTranscriptions, textAnnotations;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"faceAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2FaceAnnotation class],
    @"faceDetectionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2FaceDetectionAnnotation class],
    @"frameLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LabelAnnotation class],
    @"logoRecognitionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LogoRecognitionAnnotation class],
    @"objectAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2ObjectTrackingAnnotation class],
    @"personDetectionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2PersonDetectionAnnotation class],
    @"segmentLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LabelAnnotation class],
    @"segmentPresenceLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LabelAnnotation class],
    @"shotAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoSegment class],
    @"shotLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LabelAnnotation class],
    @"shotPresenceLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2LabelAnnotation class],
    @"speechTranscriptions" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2SpeechTranscription class],
    @"textAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2TextAnnotation class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2VideoSegment
@dynamic endTimeOffset, startTimeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2WordInfo
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1beta2WordInfo
@dynamic confidence, endTime, speakerTag, startTime, word;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1DetectedAttribute
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1DetectedAttribute
@dynamic confidence, name, value;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1DetectedLandmark
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1DetectedLandmark
@dynamic confidence, name, point;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1Entity
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1Entity
@dynamic descriptionProperty, entityId, languageCode;

+ (NSDictionary<NSString *, NSString *> *)propertyToJSONKeyMap {
  return @{ @"descriptionProperty" : @"description" };
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentAnnotation
@dynamic frames, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentDetectionConfig
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentDetectionConfig
@dynamic model;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ExplicitContentFrame
@dynamic pornographyLikelihood, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceAnnotation
@dynamic frames, segments, thumbnail;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceFrame class],
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceDetectionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceDetectionAnnotation
@dynamic thumbnail, tracks, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceDetectionConfig
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceDetectionConfig
@dynamic includeAttributes, includeBoundingBoxes, model;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceFrame
@dynamic normalizedBoundingBoxes, timeOffset;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"normalizedBoundingBoxes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1NormalizedBoundingBox class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceSegment
@dynamic segment;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelAnnotation
@dynamic categoryEntities, entity, frames, segments, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"categoryEntities" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1Entity class],
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelFrame class],
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelDetectionConfig
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelDetectionConfig
@dynamic frameConfidenceThreshold, labelDetectionMode, model, stationaryCamera,
         videoConfidenceThreshold;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelFrame
@dynamic confidence, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelSegment
@dynamic confidence, segment;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LogoRecognitionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LogoRecognitionAnnotation
@dynamic entity, segments, tracks;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoSegment class],
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1NormalizedBoundingBox
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1NormalizedBoundingBox
@dynamic bottom, left, right, top;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1NormalizedBoundingPoly
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1NormalizedBoundingPoly
@dynamic vertices;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"vertices" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1NormalizedVertex class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1NormalizedVertex
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1NormalizedVertex
@dynamic x, y;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ObjectTrackingAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ObjectTrackingAnnotation
@dynamic confidence, entity, frames, segment, trackId, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ObjectTrackingFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ObjectTrackingConfig
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ObjectTrackingConfig
@dynamic model;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ObjectTrackingFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ObjectTrackingFrame
@dynamic normalizedBoundingBox, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1AnnotateVideoProgress
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1AnnotateVideoProgress
@dynamic annotationProgress;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"annotationProgress" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1AnnotateVideoResponse
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1AnnotateVideoResponse
@dynamic annotationResults;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"annotationResults" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationResults class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1DetectedAttribute
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1DetectedAttribute
@dynamic confidence, name, value;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1DetectedLandmark
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1DetectedLandmark
@dynamic confidence, name, point;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1Entity
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1Entity
@dynamic descriptionProperty, entityId, languageCode;

+ (NSDictionary<NSString *, NSString *> *)propertyToJSONKeyMap {
  return @{ @"descriptionProperty" : @"description" };
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ExplicitContentAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ExplicitContentAnnotation
@dynamic frames, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ExplicitContentFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ExplicitContentFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ExplicitContentFrame
@dynamic pornographyLikelihood, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1FaceAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1FaceAnnotation
@dynamic frames, segments, thumbnail;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1FaceFrame class],
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1FaceSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1FaceDetectionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1FaceDetectionAnnotation
@dynamic thumbnail, tracks, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1FaceFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1FaceFrame
@dynamic normalizedBoundingBoxes, timeOffset;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"normalizedBoundingBoxes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1NormalizedBoundingBox class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1FaceSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1FaceSegment
@dynamic segment;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LabelAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LabelAnnotation
@dynamic categoryEntities, entity, frames, segments, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"categoryEntities" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1Entity class],
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LabelFrame class],
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LabelSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LabelFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LabelFrame
@dynamic confidence, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LabelSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LabelSegment
@dynamic confidence, segment;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LogoRecognitionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LogoRecognitionAnnotation
@dynamic entity, segments, tracks;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoSegment class],
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1NormalizedBoundingBox
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1NormalizedBoundingBox
@dynamic bottom, left, right, top;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1NormalizedBoundingPoly
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1NormalizedBoundingPoly
@dynamic vertices;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"vertices" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1NormalizedVertex class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1NormalizedVertex
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1NormalizedVertex
@dynamic x, y;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ObjectTrackingAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ObjectTrackingAnnotation
@dynamic confidence, entity, frames, segment, trackId, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ObjectTrackingFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ObjectTrackingFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ObjectTrackingFrame
@dynamic normalizedBoundingBox, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1PersonDetectionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1PersonDetectionAnnotation
@dynamic tracks, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1SpeechRecognitionAlternative
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1SpeechRecognitionAlternative
@dynamic confidence, transcript, words;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"words" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1WordInfo class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1SpeechTranscription
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1SpeechTranscription
@dynamic alternatives, languageCode;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"alternatives" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1SpeechRecognitionAlternative class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1TextAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1TextAnnotation
@dynamic segments, text, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1TextSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1TextFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1TextFrame
@dynamic rotatedBoundingBox, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1TextSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1TextSegment
@dynamic confidence, frames, segment;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1TextFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1TimestampedObject
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1TimestampedObject
@dynamic attributes, landmarks, normalizedBoundingBox, timeOffset;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"attributes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1DetectedAttribute class],
    @"landmarks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1DetectedLandmark class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1Track
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1Track
@dynamic attributes, confidence, segment, timestampedObjects;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"attributes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1DetectedAttribute class],
    @"timestampedObjects" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1TimestampedObject class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationProgress
@dynamic feature, inputUri, progressPercent, segment, startTime, updateTime;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationResults
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoAnnotationResults
@dynamic error, explicitAnnotation, faceAnnotations, faceDetectionAnnotations,
         frameLabelAnnotations, inputUri, logoRecognitionAnnotations,
         objectAnnotations, personDetectionAnnotations, segment,
         segmentLabelAnnotations, segmentPresenceLabelAnnotations,
         shotAnnotations, shotLabelAnnotations, shotPresenceLabelAnnotations,
         speechTranscriptions, textAnnotations;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"faceAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1FaceAnnotation class],
    @"faceDetectionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1FaceDetectionAnnotation class],
    @"frameLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LabelAnnotation class],
    @"logoRecognitionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LogoRecognitionAnnotation class],
    @"objectAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1ObjectTrackingAnnotation class],
    @"personDetectionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1PersonDetectionAnnotation class],
    @"segmentLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LabelAnnotation class],
    @"segmentPresenceLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LabelAnnotation class],
    @"shotAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoSegment class],
    @"shotLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LabelAnnotation class],
    @"shotPresenceLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1LabelAnnotation class],
    @"speechTranscriptions" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1SpeechTranscription class],
    @"textAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1TextAnnotation class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1VideoSegment
@dynamic endTimeOffset, startTimeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1WordInfo
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p1beta1WordInfo
@dynamic confidence, endTime, speakerTag, startTime, word;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1AnnotateVideoProgress
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1AnnotateVideoProgress
@dynamic annotationProgress;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"annotationProgress" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1AnnotateVideoResponse
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1AnnotateVideoResponse
@dynamic annotationResults;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"annotationResults" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationResults class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1DetectedAttribute
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1DetectedAttribute
@dynamic confidence, name, value;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1DetectedLandmark
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1DetectedLandmark
@dynamic confidence, name, point;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1Entity
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1Entity
@dynamic descriptionProperty, entityId, languageCode;

+ (NSDictionary<NSString *, NSString *> *)propertyToJSONKeyMap {
  return @{ @"descriptionProperty" : @"description" };
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ExplicitContentAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ExplicitContentAnnotation
@dynamic frames, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ExplicitContentFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ExplicitContentFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ExplicitContentFrame
@dynamic pornographyLikelihood, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1FaceAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1FaceAnnotation
@dynamic frames, segments, thumbnail;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1FaceFrame class],
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1FaceSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1FaceDetectionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1FaceDetectionAnnotation
@dynamic thumbnail, tracks, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1FaceFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1FaceFrame
@dynamic normalizedBoundingBoxes, timeOffset;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"normalizedBoundingBoxes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1NormalizedBoundingBox class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1FaceSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1FaceSegment
@dynamic segment;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LabelAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LabelAnnotation
@dynamic categoryEntities, entity, frames, segments, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"categoryEntities" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1Entity class],
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LabelFrame class],
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LabelSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LabelFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LabelFrame
@dynamic confidence, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LabelSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LabelSegment
@dynamic confidence, segment;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LogoRecognitionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LogoRecognitionAnnotation
@dynamic entity, segments, tracks;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoSegment class],
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1NormalizedBoundingBox
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1NormalizedBoundingBox
@dynamic bottom, left, right, top;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1NormalizedBoundingPoly
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1NormalizedBoundingPoly
@dynamic vertices;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"vertices" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1NormalizedVertex class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1NormalizedVertex
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1NormalizedVertex
@dynamic x, y;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ObjectTrackingAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ObjectTrackingAnnotation
@dynamic confidence, entity, frames, segment, trackId, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ObjectTrackingFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ObjectTrackingFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ObjectTrackingFrame
@dynamic normalizedBoundingBox, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1PersonDetectionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1PersonDetectionAnnotation
@dynamic tracks, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1SpeechRecognitionAlternative
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1SpeechRecognitionAlternative
@dynamic confidence, transcript, words;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"words" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1WordInfo class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1SpeechTranscription
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1SpeechTranscription
@dynamic alternatives, languageCode;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"alternatives" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1SpeechRecognitionAlternative class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1TextAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1TextAnnotation
@dynamic segments, text, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1TextSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1TextFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1TextFrame
@dynamic rotatedBoundingBox, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1TextSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1TextSegment
@dynamic confidence, frames, segment;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1TextFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1TimestampedObject
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1TimestampedObject
@dynamic attributes, landmarks, normalizedBoundingBox, timeOffset;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"attributes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1DetectedAttribute class],
    @"landmarks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1DetectedLandmark class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1Track
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1Track
@dynamic attributes, confidence, segment, timestampedObjects;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"attributes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1DetectedAttribute class],
    @"timestampedObjects" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1TimestampedObject class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationProgress
@dynamic feature, inputUri, progressPercent, segment, startTime, updateTime;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationResults
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoAnnotationResults
@dynamic error, explicitAnnotation, faceAnnotations, faceDetectionAnnotations,
         frameLabelAnnotations, inputUri, logoRecognitionAnnotations,
         objectAnnotations, personDetectionAnnotations, segment,
         segmentLabelAnnotations, segmentPresenceLabelAnnotations,
         shotAnnotations, shotLabelAnnotations, shotPresenceLabelAnnotations,
         speechTranscriptions, textAnnotations;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"faceAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1FaceAnnotation class],
    @"faceDetectionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1FaceDetectionAnnotation class],
    @"frameLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LabelAnnotation class],
    @"logoRecognitionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LogoRecognitionAnnotation class],
    @"objectAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1ObjectTrackingAnnotation class],
    @"personDetectionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1PersonDetectionAnnotation class],
    @"segmentLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LabelAnnotation class],
    @"segmentPresenceLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LabelAnnotation class],
    @"shotAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoSegment class],
    @"shotLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LabelAnnotation class],
    @"shotPresenceLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1LabelAnnotation class],
    @"speechTranscriptions" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1SpeechTranscription class],
    @"textAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1TextAnnotation class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1VideoSegment
@dynamic endTimeOffset, startTimeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1WordInfo
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p2beta1WordInfo
@dynamic confidence, endTime, speakerTag, startTime, word;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1AnnotateVideoProgress
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1AnnotateVideoProgress
@dynamic annotationProgress;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"annotationProgress" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1AnnotateVideoResponse
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1AnnotateVideoResponse
@dynamic annotationResults;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"annotationResults" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationResults class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1Celebrity
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1Celebrity
@dynamic descriptionProperty, displayName, name;

+ (NSDictionary<NSString *, NSString *> *)propertyToJSONKeyMap {
  return @{ @"descriptionProperty" : @"description" };
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1CelebrityRecognitionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1CelebrityRecognitionAnnotation
@dynamic celebrityTracks, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"celebrityTracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1CelebrityTrack class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1CelebrityTrack
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1CelebrityTrack
@dynamic celebrities, faceTrack;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"celebrities" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1RecognizedCelebrity class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1DetectedAttribute
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1DetectedAttribute
@dynamic confidence, name, value;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1DetectedLandmark
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1DetectedLandmark
@dynamic confidence, name, point;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1Entity
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1Entity
@dynamic descriptionProperty, entityId, languageCode;

+ (NSDictionary<NSString *, NSString *> *)propertyToJSONKeyMap {
  return @{ @"descriptionProperty" : @"description" };
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ExplicitContentAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ExplicitContentAnnotation
@dynamic frames, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ExplicitContentFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ExplicitContentFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ExplicitContentFrame
@dynamic pornographyLikelihood, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1FaceAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1FaceAnnotation
@dynamic frames, segments, thumbnail;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1FaceFrame class],
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1FaceSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1FaceDetectionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1FaceDetectionAnnotation
@dynamic thumbnail, tracks, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1FaceFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1FaceFrame
@dynamic normalizedBoundingBoxes, timeOffset;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"normalizedBoundingBoxes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1NormalizedBoundingBox class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1FaceSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1FaceSegment
@dynamic segment;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelAnnotation
@dynamic categoryEntities, entity, frames, segments, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"categoryEntities" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1Entity class],
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelFrame class],
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelFrame
@dynamic confidence, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelSegment
@dynamic confidence, segment;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LogoRecognitionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LogoRecognitionAnnotation
@dynamic entity, segments, tracks;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoSegment class],
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1NormalizedBoundingBox
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1NormalizedBoundingBox
@dynamic bottom, left, right, top;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1NormalizedBoundingPoly
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1NormalizedBoundingPoly
@dynamic vertices;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"vertices" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1NormalizedVertex class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1NormalizedVertex
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1NormalizedVertex
@dynamic x, y;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ObjectTrackingAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ObjectTrackingAnnotation
@dynamic confidence, entity, frames, segment, trackId, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ObjectTrackingFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ObjectTrackingFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ObjectTrackingFrame
@dynamic normalizedBoundingBox, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1PersonDetectionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1PersonDetectionAnnotation
@dynamic tracks, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1RecognizedCelebrity
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1RecognizedCelebrity
@dynamic celebrity, confidence;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1SpeechRecognitionAlternative
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1SpeechRecognitionAlternative
@dynamic confidence, transcript, words;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"words" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1WordInfo class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1SpeechTranscription
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1SpeechTranscription
@dynamic alternatives, languageCode;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"alternatives" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1SpeechRecognitionAlternative class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1StreamingAnnotateVideoResponse
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1StreamingAnnotateVideoResponse
@dynamic annotationResults, annotationResultsUri, error;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1StreamingVideoAnnotationResults
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1StreamingVideoAnnotationResults
@dynamic explicitAnnotation, frameTimestamp, labelAnnotations,
         objectAnnotations, shotAnnotations;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"labelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelAnnotation class],
    @"objectAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ObjectTrackingAnnotation class],
    @"shotAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1TextAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1TextAnnotation
@dynamic segments, text, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1TextSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1TextFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1TextFrame
@dynamic rotatedBoundingBox, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1TextSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1TextSegment
@dynamic confidence, frames, segment;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1TextFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1TimestampedObject
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1TimestampedObject
@dynamic attributes, landmarks, normalizedBoundingBox, timeOffset;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"attributes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1DetectedAttribute class],
    @"landmarks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1DetectedLandmark class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1Track
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1Track
@dynamic attributes, confidence, segment, timestampedObjects;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"attributes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1DetectedAttribute class],
    @"timestampedObjects" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1TimestampedObject class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationProgress
@dynamic feature, inputUri, progressPercent, segment, startTime, updateTime;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationResults
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoAnnotationResults
@dynamic celebrityRecognitionAnnotations, error, explicitAnnotation,
         faceAnnotations, faceDetectionAnnotations, frameLabelAnnotations,
         inputUri, logoRecognitionAnnotations, objectAnnotations,
         personDetectionAnnotations, segment, segmentLabelAnnotations,
         segmentPresenceLabelAnnotations, shotAnnotations, shotLabelAnnotations,
         shotPresenceLabelAnnotations, speechTranscriptions, textAnnotations;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"faceAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1FaceAnnotation class],
    @"faceDetectionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1FaceDetectionAnnotation class],
    @"frameLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelAnnotation class],
    @"logoRecognitionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LogoRecognitionAnnotation class],
    @"objectAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1ObjectTrackingAnnotation class],
    @"personDetectionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1PersonDetectionAnnotation class],
    @"segmentLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelAnnotation class],
    @"segmentPresenceLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelAnnotation class],
    @"shotAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoSegment class],
    @"shotLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelAnnotation class],
    @"shotPresenceLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1LabelAnnotation class],
    @"speechTranscriptions" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1SpeechTranscription class],
    @"textAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1TextAnnotation class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1VideoSegment
@dynamic endTimeOffset, startTimeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1WordInfo
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1p3beta1WordInfo
@dynamic confidence, endTime, speakerTag, startTime, word;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1PersonDetectionAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1PersonDetectionAnnotation
@dynamic tracks, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"tracks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1Track class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1PersonDetectionConfig
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1PersonDetectionConfig
@dynamic includeAttributes, includeBoundingBoxes, includePoseLandmarks;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ShotChangeDetectionConfig
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ShotChangeDetectionConfig
@dynamic model;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1SpeechContext
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1SpeechContext
@dynamic phrases;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"phrases" : [NSString class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1SpeechRecognitionAlternative
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1SpeechRecognitionAlternative
@dynamic confidence, transcript, words;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"words" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1WordInfo class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1SpeechTranscription
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1SpeechTranscription
@dynamic alternatives, languageCode;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"alternatives" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1SpeechRecognitionAlternative class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1SpeechTranscriptionConfig
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1SpeechTranscriptionConfig
@dynamic audioTracks, diarizationSpeakerCount, enableAutomaticPunctuation,
         enableSpeakerDiarization, enableWordConfidence, filterProfanity,
         languageCode, maxAlternatives, speechContexts;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"audioTracks" : [NSNumber class],
    @"speechContexts" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1SpeechContext class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TextAnnotation
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TextAnnotation
@dynamic segments, text, version;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TextSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TextDetectionConfig
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TextDetectionConfig
@dynamic languageHints, model;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"languageHints" : [NSString class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TextFrame
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TextFrame
@dynamic rotatedBoundingBox, timeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TextSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TextSegment
@dynamic confidence, frames, segment;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"frames" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TextFrame class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TimestampedObject
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TimestampedObject
@dynamic attributes, landmarks, normalizedBoundingBox, timeOffset;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"attributes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1DetectedAttribute class],
    @"landmarks" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1DetectedLandmark class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1Track
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1Track
@dynamic attributes, confidence, segment, timestampedObjects;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"attributes" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1DetectedAttribute class],
    @"timestampedObjects" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TimestampedObject class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationProgress
@dynamic feature, inputUri, progressPercent, segment, startTime, updateTime;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationResults
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoAnnotationResults
@dynamic error, explicitAnnotation, faceAnnotations, faceDetectionAnnotations,
         frameLabelAnnotations, inputUri, logoRecognitionAnnotations,
         objectAnnotations, personDetectionAnnotations, segment,
         segmentLabelAnnotations, segmentPresenceLabelAnnotations,
         shotAnnotations, shotLabelAnnotations, shotPresenceLabelAnnotations,
         speechTranscriptions, textAnnotations;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"faceAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceAnnotation class],
    @"faceDetectionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1FaceDetectionAnnotation class],
    @"frameLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelAnnotation class],
    @"logoRecognitionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LogoRecognitionAnnotation class],
    @"objectAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1ObjectTrackingAnnotation class],
    @"personDetectionAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1PersonDetectionAnnotation class],
    @"segmentLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelAnnotation class],
    @"segmentPresenceLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelAnnotation class],
    @"shotAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoSegment class],
    @"shotLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelAnnotation class],
    @"shotPresenceLabelAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1LabelAnnotation class],
    @"speechTranscriptions" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1SpeechTranscription class],
    @"textAnnotations" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1TextAnnotation class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoContext
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoContext
@dynamic explicitContentDetectionConfig, faceDetectionConfig,
         labelDetectionConfig, objectTrackingConfig, personDetectionConfig,
         segments, shotChangeDetectionConfig, speechTranscriptionConfig,
         textDetectionConfig;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"segments" : [GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoSegment class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoSegment
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1VideoSegment
@dynamic endTimeOffset, startTimeOffset;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1WordInfo
//

@implementation GTLRCloudVideoIntelligence_GoogleCloudVideointelligenceV1WordInfo
@dynamic confidence, endTime, speakerTag, startTime, word;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleLongrunningCancelOperationRequest
//

@implementation GTLRCloudVideoIntelligence_GoogleLongrunningCancelOperationRequest
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleLongrunningListOperationsResponse
//

@implementation GTLRCloudVideoIntelligence_GoogleLongrunningListOperationsResponse
@dynamic nextPageToken, operations;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"operations" : [GTLRCloudVideoIntelligence_GoogleLongrunningOperation class]
  };
  return map;
}

+ (NSString *)collectionItemsKey {
  return @"operations";
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleLongrunningOperation
//

@implementation GTLRCloudVideoIntelligence_GoogleLongrunningOperation
@dynamic done, error, metadata, name, response;
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleLongrunningOperation_Metadata
//

@implementation GTLRCloudVideoIntelligence_GoogleLongrunningOperation_Metadata

+ (Class)classForAdditionalProperties {
  return [NSObject class];
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleLongrunningOperation_Response
//

@implementation GTLRCloudVideoIntelligence_GoogleLongrunningOperation_Response

+ (Class)classForAdditionalProperties {
  return [NSObject class];
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleProtobufEmpty
//

@implementation GTLRCloudVideoIntelligence_GoogleProtobufEmpty
@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleRpcStatus
//

@implementation GTLRCloudVideoIntelligence_GoogleRpcStatus
@dynamic code, details, message;

+ (NSDictionary<NSString *, Class> *)arrayPropertyToClassMap {
  NSDictionary<NSString *, Class> *map = @{
    @"details" : [GTLRCloudVideoIntelligence_GoogleRpcStatus_Details_Item class]
  };
  return map;
}

@end


// ----------------------------------------------------------------------------
//
//   GTLRCloudVideoIntelligence_GoogleRpcStatus_Details_Item
//

@implementation GTLRCloudVideoIntelligence_GoogleRpcStatus_Details_Item

+ (Class)classForAdditionalProperties {
  return [NSObject class];
}

@end
