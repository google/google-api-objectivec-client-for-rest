// NOTE: This file was generated by the ServiceGenerator.

// ----------------------------------------------------------------------------
// API:
//   Cloud Dataproc API (dataproc/v1)
// Description:
//   Manages Hadoop-based clusters and jobs on Google Cloud Platform.
// Documentation:
//   https://cloud.google.com/dataproc/

#import <GoogleAPIClientForREST/GTLRObject.h>

#if GTLR_RUNTIME_VERSION != 3000
#error This file was generated by a different version of ServiceGenerator which is incompatible with this GTLR library source.
#endif

@class GTLRDataproc_AcceleratorConfig;
@class GTLRDataproc_AutoscalingConfig;
@class GTLRDataproc_AutoscalingPolicy;
@class GTLRDataproc_AutoscalingPolicy_Labels;
@class GTLRDataproc_AuxiliaryServicesConfig;
@class GTLRDataproc_BasicAutoscalingAlgorithm;
@class GTLRDataproc_BasicYarnAutoscalingConfig;
@class GTLRDataproc_Batch;
@class GTLRDataproc_Batch_Labels;
@class GTLRDataproc_BatchOperationMetadata_Labels;
@class GTLRDataproc_Binding;
@class GTLRDataproc_Cluster;
@class GTLRDataproc_Cluster_Labels;
@class GTLRDataproc_ClusterConfig;
@class GTLRDataproc_ClusterMetrics;
@class GTLRDataproc_ClusterMetrics_HdfsMetrics;
@class GTLRDataproc_ClusterMetrics_YarnMetrics;
@class GTLRDataproc_ClusterOperation;
@class GTLRDataproc_ClusterOperationMetadata_Labels;
@class GTLRDataproc_ClusterOperationStatus;
@class GTLRDataproc_ClusterSelector;
@class GTLRDataproc_ClusterSelector_ClusterLabels;
@class GTLRDataproc_ClusterStatus;
@class GTLRDataproc_ConfidentialInstanceConfig;
@class GTLRDataproc_DiskConfig;
@class GTLRDataproc_EncryptionConfig;
@class GTLRDataproc_EndpointConfig;
@class GTLRDataproc_EndpointConfig_HttpPorts;
@class GTLRDataproc_EnvironmentConfig;
@class GTLRDataproc_ExecutionConfig;
@class GTLRDataproc_Expr;
@class GTLRDataproc_GceClusterConfig;
@class GTLRDataproc_GceClusterConfig_Metadata;
@class GTLRDataproc_GetPolicyOptions;
@class GTLRDataproc_GkeClusterConfig;
@class GTLRDataproc_GkeNodeConfig;
@class GTLRDataproc_GkeNodePoolAcceleratorConfig;
@class GTLRDataproc_GkeNodePoolAutoscalingConfig;
@class GTLRDataproc_GkeNodePoolConfig;
@class GTLRDataproc_GkeNodePoolTarget;
@class GTLRDataproc_HadoopJob;
@class GTLRDataproc_HadoopJob_Properties;
@class GTLRDataproc_HiveJob;
@class GTLRDataproc_HiveJob_Properties;
@class GTLRDataproc_HiveJob_ScriptVariables;
@class GTLRDataproc_IdentityConfig;
@class GTLRDataproc_IdentityConfig_UserServiceAccountMapping;
@class GTLRDataproc_InstanceGroupAutoscalingPolicyConfig;
@class GTLRDataproc_InstanceGroupConfig;
@class GTLRDataproc_InstanceReference;
@class GTLRDataproc_InstantiateWorkflowTemplateRequest_Parameters;
@class GTLRDataproc_Job;
@class GTLRDataproc_Job_Labels;
@class GTLRDataproc_JobPlacement;
@class GTLRDataproc_JobPlacement_ClusterLabels;
@class GTLRDataproc_JobReference;
@class GTLRDataproc_JobScheduling;
@class GTLRDataproc_JobStatus;
@class GTLRDataproc_KerberosConfig;
@class GTLRDataproc_KubernetesClusterConfig;
@class GTLRDataproc_KubernetesSoftwareConfig;
@class GTLRDataproc_KubernetesSoftwareConfig_ComponentVersion;
@class GTLRDataproc_KubernetesSoftwareConfig_Properties;
@class GTLRDataproc_LifecycleConfig;
@class GTLRDataproc_LoggingConfig;
@class GTLRDataproc_LoggingConfig_DriverLogLevels;
@class GTLRDataproc_ManagedCluster;
@class GTLRDataproc_ManagedCluster_Labels;
@class GTLRDataproc_ManagedGroupConfig;
@class GTLRDataproc_MetastoreConfig;
@class GTLRDataproc_Metric;
@class GTLRDataproc_MetricConfig;
@class GTLRDataproc_NamespacedGkeDeploymentTarget;
@class GTLRDataproc_NodeGroupAffinity;
@class GTLRDataproc_NodeInitializationAction;
@class GTLRDataproc_NodePool;
@class GTLRDataproc_Operation;
@class GTLRDataproc_Operation_Metadata;
@class GTLRDataproc_Operation_Response;
@class GTLRDataproc_OrderedJob;
@class GTLRDataproc_OrderedJob_Labels;
@class GTLRDataproc_ParameterValidation;
@class GTLRDataproc_PeripheralsConfig;
@class GTLRDataproc_PigJob;
@class GTLRDataproc_PigJob_Properties;
@class GTLRDataproc_PigJob_ScriptVariables;
@class GTLRDataproc_Policy;
@class GTLRDataproc_PrestoJob;
@class GTLRDataproc_PrestoJob_Properties;
@class GTLRDataproc_PySparkBatch;
@class GTLRDataproc_PySparkJob;
@class GTLRDataproc_PySparkJob_Properties;
@class GTLRDataproc_QueryList;
@class GTLRDataproc_RegexValidation;
@class GTLRDataproc_ReservationAffinity;
@class GTLRDataproc_RuntimeConfig;
@class GTLRDataproc_RuntimeConfig_Properties;
@class GTLRDataproc_RuntimeInfo;
@class GTLRDataproc_RuntimeInfo_Endpoints;
@class GTLRDataproc_SecurityConfig;
@class GTLRDataproc_SessionOperationMetadata_Labels;
@class GTLRDataproc_ShieldedInstanceConfig;
@class GTLRDataproc_SoftwareConfig;
@class GTLRDataproc_SoftwareConfig_Properties;
@class GTLRDataproc_SparkBatch;
@class GTLRDataproc_SparkHistoryServerConfig;
@class GTLRDataproc_SparkJob;
@class GTLRDataproc_SparkJob_Properties;
@class GTLRDataproc_SparkRBatch;
@class GTLRDataproc_SparkRJob;
@class GTLRDataproc_SparkRJob_Properties;
@class GTLRDataproc_SparkSqlBatch;
@class GTLRDataproc_SparkSqlBatch_QueryVariables;
@class GTLRDataproc_SparkSqlJob;
@class GTLRDataproc_SparkSqlJob_Properties;
@class GTLRDataproc_SparkSqlJob_ScriptVariables;
@class GTLRDataproc_SparkStandaloneAutoscalingConfig;
@class GTLRDataproc_StateHistory;
@class GTLRDataproc_Status;
@class GTLRDataproc_Status_Details_Item;
@class GTLRDataproc_TemplateParameter;
@class GTLRDataproc_ValueValidation;
@class GTLRDataproc_VirtualClusterConfig;
@class GTLRDataproc_WorkflowGraph;
@class GTLRDataproc_WorkflowMetadata_Parameters;
@class GTLRDataproc_WorkflowNode;
@class GTLRDataproc_WorkflowTemplate;
@class GTLRDataproc_WorkflowTemplate_Labels;
@class GTLRDataproc_WorkflowTemplatePlacement;
@class GTLRDataproc_YarnApplication;

// Generated comments include content from the discovery document; avoid them
// causing warnings since clang's checks are some what arbitrary.
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wdocumentation"

NS_ASSUME_NONNULL_BEGIN

// ----------------------------------------------------------------------------
// Constants - For some of the classes' properties below.

// ----------------------------------------------------------------------------
// GTLRDataproc_Batch.state

/**
 *  The batch cancellation was successful.
 *
 *  Value: "CANCELLED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Batch_State_Cancelled;
/**
 *  The batch is cancelling.
 *
 *  Value: "CANCELLING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Batch_State_Cancelling;
/**
 *  The batch is no longer running due to an error.
 *
 *  Value: "FAILED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Batch_State_Failed;
/**
 *  The batch is created before running.
 *
 *  Value: "PENDING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Batch_State_Pending;
/**
 *  The batch is running.
 *
 *  Value: "RUNNING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Batch_State_Running;
/**
 *  The batch state is unknown.
 *
 *  Value: "STATE_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Batch_State_StateUnspecified;
/**
 *  The batch completed successfully.
 *
 *  Value: "SUCCEEDED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Batch_State_Succeeded;

// ----------------------------------------------------------------------------
// GTLRDataproc_BatchOperationMetadata.operationType

/**
 *  Batch operation type.
 *
 *  Value: "BATCH"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_BatchOperationMetadata_OperationType_Batch;
/**
 *  Batch operation type is unknown.
 *
 *  Value: "BATCH_OPERATION_TYPE_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_BatchOperationMetadata_OperationType_BatchOperationTypeUnspecified;

// ----------------------------------------------------------------------------
// GTLRDataproc_ClusterOperationStatus.state

/**
 *  The operation is done; either cancelled or completed.
 *
 *  Value: "DONE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterOperationStatus_State_Done;
/**
 *  The operation has been created.
 *
 *  Value: "PENDING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterOperationStatus_State_Pending;
/**
 *  The operation is running.
 *
 *  Value: "RUNNING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterOperationStatus_State_Running;
/**
 *  Unused.
 *
 *  Value: "UNKNOWN"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterOperationStatus_State_Unknown;

// ----------------------------------------------------------------------------
// GTLRDataproc_ClusterStatus.state

/**
 *  The cluster is being created and set up. It is not ready for use.
 *
 *  Value: "CREATING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_State_Creating;
/**
 *  The cluster is being deleted. It cannot be used.
 *
 *  Value: "DELETING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_State_Deleting;
/**
 *  The cluster encountered an error. It is not ready for use.
 *
 *  Value: "ERROR"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_State_Error;
/**
 *  The cluster has encountered an error while being updated. Jobs can be
 *  submitted to the cluster, but the cluster cannot be updated.
 *
 *  Value: "ERROR_DUE_TO_UPDATE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_State_ErrorDueToUpdate;
/**
 *  The cluster is being repaired. It is not ready for use.
 *
 *  Value: "REPAIRING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_State_Repairing;
/**
 *  The cluster is currently running and healthy. It is ready for use.Note: The
 *  cluster state changes from "creating" to "running" status after the master
 *  node(s), first two primary worker nodes (and the last primary worker node if
 *  primary workers > 2) are running.
 *
 *  Value: "RUNNING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_State_Running;
/**
 *  The cluster is being started. It is not ready for use.
 *
 *  Value: "STARTING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_State_Starting;
/**
 *  The cluster is currently stopped. It is not ready for use.
 *
 *  Value: "STOPPED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_State_Stopped;
/**
 *  The cluster is being stopped. It cannot be used.
 *
 *  Value: "STOPPING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_State_Stopping;
/**
 *  The cluster state is unknown.
 *
 *  Value: "UNKNOWN"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_State_Unknown;
/**
 *  The cluster is being updated. It continues to accept and process jobs.
 *
 *  Value: "UPDATING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_State_Updating;

// ----------------------------------------------------------------------------
// GTLRDataproc_ClusterStatus.substate

/**
 *  The agent-reported status is out of date (may occur if Dataproc loses
 *  communication with Agent).Applies to RUNNING state.
 *
 *  Value: "STALE_STATUS"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_Substate_StaleStatus;
/**
 *  The cluster is known to be in an unhealthy state (for example, critical
 *  daemons are not running or HDFS capacity is exhausted).Applies to RUNNING
 *  state.
 *
 *  Value: "UNHEALTHY"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_Substate_Unhealthy;
/**
 *  The cluster substate is unknown.
 *
 *  Value: "UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ClusterStatus_Substate_Unspecified;

// ----------------------------------------------------------------------------
// GTLRDataproc_GceClusterConfig.privateIpv6GoogleAccess

/**
 *  Enables bidirectional private IPv6 access between Google Services and the
 *  Dataproc cluster.
 *
 *  Value: "BIDIRECTIONAL"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_GceClusterConfig_PrivateIpv6GoogleAccess_Bidirectional;
/**
 *  Private access to and from Google Services configuration inherited from the
 *  subnetwork configuration. This is the default Compute Engine behavior.
 *
 *  Value: "INHERIT_FROM_SUBNETWORK"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_GceClusterConfig_PrivateIpv6GoogleAccess_InheritFromSubnetwork;
/**
 *  Enables outbound private IPv6 access to Google Services from the Dataproc
 *  cluster.
 *
 *  Value: "OUTBOUND"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_GceClusterConfig_PrivateIpv6GoogleAccess_Outbound;
/**
 *  If unspecified, Compute Engine default behavior will apply, which is the
 *  same as INHERIT_FROM_SUBNETWORK.
 *
 *  Value: "PRIVATE_IPV6_GOOGLE_ACCESS_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_GceClusterConfig_PrivateIpv6GoogleAccess_PrivateIpv6GoogleAccessUnspecified;

// ----------------------------------------------------------------------------
// GTLRDataproc_GkeNodePoolTarget.roles

/**
 *  Run work associated with the Dataproc control plane (for example,
 *  controllers and webhooks). Very low resource requirements.
 *
 *  Value: "CONTROLLER"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_GkeNodePoolTarget_Roles_Controller;
/**
 *  At least one node pool must have the DEFAULT role. Work assigned to a role
 *  that is not associated with a node pool is assigned to the node pool with
 *  the DEFAULT role. For example, work assigned to the CONTROLLER role will be
 *  assigned to the node pool with the DEFAULT role if no node pool has the
 *  CONTROLLER role.
 *
 *  Value: "DEFAULT"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_GkeNodePoolTarget_Roles_Default;
/**
 *  Role is unspecified.
 *
 *  Value: "ROLE_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_GkeNodePoolTarget_Roles_RoleUnspecified;
/**
 *  Run work associated with a Spark driver of a job.
 *
 *  Value: "SPARK_DRIVER"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_GkeNodePoolTarget_Roles_SparkDriver;
/**
 *  Run work associated with a Spark executor of a job.
 *
 *  Value: "SPARK_EXECUTOR"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_GkeNodePoolTarget_Roles_SparkExecutor;

// ----------------------------------------------------------------------------
// GTLRDataproc_InstanceGroupConfig.preemptibility

/**
 *  Instances are non-preemptible.This option is allowed for all instance groups
 *  and is the only valid value for Master and Worker instance groups.
 *
 *  Value: "NON_PREEMPTIBLE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_InstanceGroupConfig_Preemptibility_NonPreemptible;
/**
 *  Preemptibility is unspecified, the system will choose the appropriate
 *  setting for each instance group.
 *
 *  Value: "PREEMPTIBILITY_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_InstanceGroupConfig_Preemptibility_PreemptibilityUnspecified;
/**
 *  Instances are preemptible.This option is allowed only for secondary worker
 *  groups.
 *
 *  Value: "PREEMPTIBLE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_InstanceGroupConfig_Preemptibility_Preemptible;

// ----------------------------------------------------------------------------
// GTLRDataproc_JobStatus.state

/**
 *  Job attempt has failed. The detail field contains failure details for this
 *  attempt.Applies to restartable jobs only.
 *
 *  Value: "ATTEMPT_FAILURE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_State_AttemptFailure;
/**
 *  The job cancellation was successful.
 *
 *  Value: "CANCELLED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_State_Cancelled;
/**
 *  A CancelJob request has been received, but is pending.
 *
 *  Value: "CANCEL_PENDING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_State_CancelPending;
/**
 *  Transient in-flight resources have been canceled, and the request to cancel
 *  the running job has been issued to the cluster.
 *
 *  Value: "CANCEL_STARTED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_State_CancelStarted;
/**
 *  The job has completed successfully.
 *
 *  Value: "DONE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_State_Done;
/**
 *  The job has completed, but encountered an error.
 *
 *  Value: "ERROR"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_State_Error;
/**
 *  The job is pending; it has been submitted, but is not yet running.
 *
 *  Value: "PENDING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_State_Pending;
/**
 *  The job is running on the cluster.
 *
 *  Value: "RUNNING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_State_Running;
/**
 *  Job has been received by the service and completed initial setup; it will
 *  soon be submitted to the cluster.
 *
 *  Value: "SETUP_DONE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_State_SetupDone;
/**
 *  The job state is unknown.
 *
 *  Value: "STATE_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_State_StateUnspecified;

// ----------------------------------------------------------------------------
// GTLRDataproc_JobStatus.substate

/**
 *  The Job has been received and is awaiting execution (it may be waiting for a
 *  condition to be met). See the "details" field for the reason for the
 *  delay.Applies to RUNNING state.
 *
 *  Value: "QUEUED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_Substate_Queued;
/**
 *  The agent-reported status is out of date, which may be caused by a loss of
 *  communication between the agent and Dataproc. If the agent does not send a
 *  timely update, the job will fail.Applies to RUNNING state.
 *
 *  Value: "STALE_STATUS"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_Substate_StaleStatus;
/**
 *  The Job is submitted to the agent.Applies to RUNNING state.
 *
 *  Value: "SUBMITTED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_Substate_Submitted;
/**
 *  The job substate is unknown.
 *
 *  Value: "UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_JobStatus_Substate_Unspecified;

// ----------------------------------------------------------------------------
// GTLRDataproc_LoggingConfig_DriverLogLevels.driverLogLevel

/**
 *  Use ALL level for log4j.
 *
 *  Value: "ALL"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_LoggingConfig_DriverLogLevels_DriverLogLevel_All;
/**
 *  Use DEBUG level for log4j.
 *
 *  Value: "DEBUG"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_LoggingConfig_DriverLogLevels_DriverLogLevel_Debug;
/**
 *  Use ERROR level for log4j.
 *
 *  Value: "ERROR"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_LoggingConfig_DriverLogLevels_DriverLogLevel_Error;
/**
 *  Use FATAL level for log4j.
 *
 *  Value: "FATAL"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_LoggingConfig_DriverLogLevels_DriverLogLevel_Fatal;
/**
 *  Use INFO level for log4j.
 *
 *  Value: "INFO"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_LoggingConfig_DriverLogLevels_DriverLogLevel_Info;
/**
 *  Level is unspecified. Use default level for log4j.
 *
 *  Value: "LEVEL_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_LoggingConfig_DriverLogLevels_DriverLogLevel_LevelUnspecified;
/**
 *  Turn off log4j.
 *
 *  Value: "OFF"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_LoggingConfig_DriverLogLevels_DriverLogLevel_Off;
/**
 *  Use TRACE level for log4j.
 *
 *  Value: "TRACE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_LoggingConfig_DriverLogLevels_DriverLogLevel_Trace;
/**
 *  Use WARN level for log4j.
 *
 *  Value: "WARN"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_LoggingConfig_DriverLogLevels_DriverLogLevel_Warn;

// ----------------------------------------------------------------------------
// GTLRDataproc_Metric.metricSource

/**
 *  HDFS metric source.
 *
 *  Value: "HDFS"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Metric_MetricSource_Hdfs;
/**
 *  Hiveserver2 metric source.
 *
 *  Value: "HIVESERVER2"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Metric_MetricSource_Hiveserver2;
/**
 *  Required unspecified metric source.
 *
 *  Value: "METRIC_SOURCE_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Metric_MetricSource_MetricSourceUnspecified;
/**
 *  Default monitoring agent metrics. If this source is enabled, Dataproc
 *  enables the monitoring agent in Compute Engine, and collects default
 *  monitoring agent metrics, which are published with an agent.googleapis.com
 *  prefix.
 *
 *  Value: "MONITORING_AGENT_DEFAULTS"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Metric_MetricSource_MonitoringAgentDefaults;
/**
 *  Spark metric source.
 *
 *  Value: "SPARK"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Metric_MetricSource_Spark;
/**
 *  Spark History Server metric source.
 *
 *  Value: "SPARK_HISTORY_SERVER"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Metric_MetricSource_SparkHistoryServer;
/**
 *  YARN metric source.
 *
 *  Value: "YARN"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_Metric_MetricSource_Yarn;

// ----------------------------------------------------------------------------
// GTLRDataproc_NodePool.repairAction

/**
 *  delete the specified list of nodes.
 *
 *  Value: "DELETE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_NodePool_RepairAction_Delete;
/**
 *  No action will be taken by default.
 *
 *  Value: "REPAIR_ACTION_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_NodePool_RepairAction_RepairActionUnspecified;

// ----------------------------------------------------------------------------
// GTLRDataproc_ReservationAffinity.consumeReservationType

/**
 *  Consume any reservation available.
 *
 *  Value: "ANY_RESERVATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ReservationAffinity_ConsumeReservationType_AnyReservation;
/**
 *  Do not consume from any allocated capacity.
 *
 *  Value: "NO_RESERVATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ReservationAffinity_ConsumeReservationType_NoReservation;
/**
 *  Must consume from a specific reservation. Must specify key value fields for
 *  specifying the reservations.
 *
 *  Value: "SPECIFIC_RESERVATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ReservationAffinity_ConsumeReservationType_SpecificReservation;
/** Value: "TYPE_UNSPECIFIED" */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_ReservationAffinity_ConsumeReservationType_TypeUnspecified;

// ----------------------------------------------------------------------------
// GTLRDataproc_SessionOperationMetadata.operationType

/**
 *  Create Session operation type.
 *
 *  Value: "CREATE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SessionOperationMetadata_OperationType_Create;
/**
 *  Delete Session operation type.
 *
 *  Value: "DELETE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SessionOperationMetadata_OperationType_Delete;
/**
 *  Session operation type is unknown.
 *
 *  Value: "SESSION_OPERATION_TYPE_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SessionOperationMetadata_OperationType_SessionOperationTypeUnspecified;
/**
 *  Terminate Session operation type.
 *
 *  Value: "TERMINATE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SessionOperationMetadata_OperationType_Terminate;

// ----------------------------------------------------------------------------
// GTLRDataproc_SoftwareConfig.optionalComponents

/**
 *  The Anaconda python distribution. The Anaconda component is not supported in
 *  the Dataproc 2.0 image. The 2.0 image is pre-installed with Miniconda.
 *
 *  Value: "ANACONDA"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SoftwareConfig_OptionalComponents_Anaconda;
/**
 *  Unspecified component. Specifying this will cause Cluster creation to fail.
 *
 *  Value: "COMPONENT_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SoftwareConfig_OptionalComponents_ComponentUnspecified;
/**
 *  Docker
 *
 *  Value: "DOCKER"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SoftwareConfig_OptionalComponents_Docker;
/**
 *  The Druid query engine. (alpha)
 *
 *  Value: "DRUID"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SoftwareConfig_OptionalComponents_Druid;
/**
 *  Flink
 *
 *  Value: "FLINK"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SoftwareConfig_OptionalComponents_Flink;
/**
 *  HBase. (beta)
 *
 *  Value: "HBASE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SoftwareConfig_OptionalComponents_Hbase;
/**
 *  The Hive Web HCatalog (the REST service for accessing HCatalog).
 *
 *  Value: "HIVE_WEBHCAT"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SoftwareConfig_OptionalComponents_HiveWebhcat;
/**
 *  The Jupyter Notebook.
 *
 *  Value: "JUPYTER"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SoftwareConfig_OptionalComponents_Jupyter;
/**
 *  The Presto query engine.
 *
 *  Value: "PRESTO"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SoftwareConfig_OptionalComponents_Presto;
/**
 *  The Ranger service.
 *
 *  Value: "RANGER"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SoftwareConfig_OptionalComponents_Ranger;
/**
 *  The Solr service.
 *
 *  Value: "SOLR"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SoftwareConfig_OptionalComponents_Solr;
/**
 *  The Zeppelin notebook.
 *
 *  Value: "ZEPPELIN"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SoftwareConfig_OptionalComponents_Zeppelin;
/**
 *  The Zookeeper service.
 *
 *  Value: "ZOOKEEPER"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_SoftwareConfig_OptionalComponents_Zookeeper;

// ----------------------------------------------------------------------------
// GTLRDataproc_StateHistory.state

/**
 *  The batch cancellation was successful.
 *
 *  Value: "CANCELLED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_StateHistory_State_Cancelled;
/**
 *  The batch is cancelling.
 *
 *  Value: "CANCELLING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_StateHistory_State_Cancelling;
/**
 *  The batch is no longer running due to an error.
 *
 *  Value: "FAILED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_StateHistory_State_Failed;
/**
 *  The batch is created before running.
 *
 *  Value: "PENDING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_StateHistory_State_Pending;
/**
 *  The batch is running.
 *
 *  Value: "RUNNING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_StateHistory_State_Running;
/**
 *  The batch state is unknown.
 *
 *  Value: "STATE_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_StateHistory_State_StateUnspecified;
/**
 *  The batch completed successfully.
 *
 *  Value: "SUCCEEDED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_StateHistory_State_Succeeded;

// ----------------------------------------------------------------------------
// GTLRDataproc_WorkflowMetadata.state

/**
 *  The operation is done; either cancelled or completed.
 *
 *  Value: "DONE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_WorkflowMetadata_State_Done;
/**
 *  The operation has been created.
 *
 *  Value: "PENDING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_WorkflowMetadata_State_Pending;
/**
 *  The operation is running.
 *
 *  Value: "RUNNING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_WorkflowMetadata_State_Running;
/**
 *  Unused.
 *
 *  Value: "UNKNOWN"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_WorkflowMetadata_State_Unknown;

// ----------------------------------------------------------------------------
// GTLRDataproc_WorkflowNode.state

/**
 *  The node is awaiting prerequisite node to finish.
 *
 *  Value: "BLOCKED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_WorkflowNode_State_Blocked;
/**
 *  The node completed successfully.
 *
 *  Value: "COMPLETED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_WorkflowNode_State_Completed;
/**
 *  The node failed. A node can be marked FAILED because its ancestor or peer
 *  failed.
 *
 *  Value: "FAILED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_WorkflowNode_State_Failed;
/**
 *  State is unspecified.
 *
 *  Value: "NODE_STATE_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_WorkflowNode_State_NodeStateUnspecified;
/**
 *  The node is runnable but not running.
 *
 *  Value: "RUNNABLE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_WorkflowNode_State_Runnable;
/**
 *  The node is running.
 *
 *  Value: "RUNNING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_WorkflowNode_State_Running;

// ----------------------------------------------------------------------------
// GTLRDataproc_YarnApplication.state

/**
 *  Status is ACCEPTED.
 *
 *  Value: "ACCEPTED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_YarnApplication_State_Accepted;
/**
 *  Status is FAILED.
 *
 *  Value: "FAILED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_YarnApplication_State_Failed;
/**
 *  Status is FINISHED.
 *
 *  Value: "FINISHED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_YarnApplication_State_Finished;
/**
 *  Status is KILLED.
 *
 *  Value: "KILLED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_YarnApplication_State_Killed;
/**
 *  Status is NEW.
 *
 *  Value: "NEW"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_YarnApplication_State_New;
/**
 *  Status is NEW_SAVING.
 *
 *  Value: "NEW_SAVING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_YarnApplication_State_NewSaving;
/**
 *  Status is RUNNING.
 *
 *  Value: "RUNNING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_YarnApplication_State_Running;
/**
 *  Status is unspecified.
 *
 *  Value: "STATE_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_YarnApplication_State_StateUnspecified;
/**
 *  Status is SUBMITTED.
 *
 *  Value: "SUBMITTED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataproc_YarnApplication_State_Submitted;

/**
 *  Specifies the type and number of accelerator cards attached to the instances
 *  of an instance. See GPUs on Compute Engine
 *  (https://cloud.google.com/compute/docs/gpus/).
 */
@interface GTLRDataproc_AcceleratorConfig : GTLRObject

/**
 *  The number of the accelerator cards of this type exposed to this instance.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *acceleratorCount;

/**
 *  Full URL, partial URI, or short name of the accelerator type resource to
 *  expose to this instance. See Compute Engine AcceleratorTypes
 *  (https://cloud.google.com/compute/docs/reference/beta/acceleratorTypes).Examples:
 *  https://www.googleapis.com/compute/beta/projects/[project_id]/zones/us-east1-a/acceleratorTypes/nvidia-tesla-k80
 *  projects/[project_id]/zones/us-east1-a/acceleratorTypes/nvidia-tesla-k80
 *  nvidia-tesla-k80Auto Zone Exception: If you are using the Dataproc Auto Zone
 *  Placement
 *  (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
 *  feature, you must use the short name of the accelerator type resource, for
 *  example, nvidia-tesla-k80.
 */
@property(nonatomic, copy, nullable) NSString *acceleratorTypeUri;

@end


/**
 *  Autoscaling Policy config associated with the cluster.
 */
@interface GTLRDataproc_AutoscalingConfig : GTLRObject

/**
 *  Optional. The autoscaling policy used by the cluster.Only resource names
 *  including projectid and location (region) are valid. Examples:
 *  https://www.googleapis.com/compute/v1/projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id]
 *  projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id]Note
 *  that the policy must be in the same project and Dataproc region.
 */
@property(nonatomic, copy, nullable) NSString *policyUri;

@end


/**
 *  Describes an autoscaling policy for Dataproc cluster autoscaler.
 */
@interface GTLRDataproc_AutoscalingPolicy : GTLRObject

@property(nonatomic, strong, nullable) GTLRDataproc_BasicAutoscalingAlgorithm *basicAlgorithm;

/**
 *  Required. The policy id.The id must contain only letters (a-z, A-Z), numbers
 *  (0-9), underscores (_), and hyphens (-). Cannot begin or end with underscore
 *  or hyphen. Must consist of between 3 and 50 characters.
 *
 *  identifier property maps to 'id' in JSON (to avoid Objective C's 'id').
 */
@property(nonatomic, copy, nullable) NSString *identifier;

/**
 *  Optional. The labels to associate with this autoscaling policy. Label keys
 *  must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if
 *  present, must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be
 *  associated with an autoscaling policy.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_AutoscalingPolicy_Labels *labels;

/**
 *  Output only. The "resource name" of the autoscaling policy, as described in
 *  https://cloud.google.com/apis/design/resource_names. For
 *  projects.regions.autoscalingPolicies, the resource name of the policy has
 *  the following format:
 *  projects/{project_id}/regions/{region}/autoscalingPolicies/{policy_id} For
 *  projects.locations.autoscalingPolicies, the resource name of the policy has
 *  the following format:
 *  projects/{project_id}/locations/{location}/autoscalingPolicies/{policy_id}
 */
@property(nonatomic, copy, nullable) NSString *name;

/**
 *  Optional. Describes how the autoscaler will operate for secondary workers.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_InstanceGroupAutoscalingPolicyConfig *secondaryWorkerConfig;

/**
 *  Required. Describes how the autoscaler will operate for primary workers.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_InstanceGroupAutoscalingPolicyConfig *workerConfig;

@end


/**
 *  Optional. The labels to associate with this autoscaling policy. Label keys
 *  must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if
 *  present, must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be
 *  associated with an autoscaling policy.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_AutoscalingPolicy_Labels : GTLRObject
@end


/**
 *  Auxiliary services configuration for a Cluster.
 */
@interface GTLRDataproc_AuxiliaryServicesConfig : GTLRObject

/** Optional. The Hive Metastore configuration for this workload. */
@property(nonatomic, strong, nullable) GTLRDataproc_MetastoreConfig *metastoreConfig;

/** Optional. The Spark History Server configuration for the workload. */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkHistoryServerConfig *sparkHistoryServerConfig;

@end


/**
 *  Basic algorithm for autoscaling.
 */
@interface GTLRDataproc_BasicAutoscalingAlgorithm : GTLRObject

/**
 *  Optional. Duration between scaling events. A scaling period starts after the
 *  update operation from the previous event has completed.Bounds: 2m, 1d.
 *  Default: 2m.
 */
@property(nonatomic, strong, nullable) GTLRDuration *cooldownPeriod;

/** Optional. Spark Standalone autoscaling configuration */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkStandaloneAutoscalingConfig *sparkStandaloneConfig;

/** Optional. YARN autoscaling configuration. */
@property(nonatomic, strong, nullable) GTLRDataproc_BasicYarnAutoscalingConfig *yarnConfig;

@end


/**
 *  Basic autoscaling configurations for YARN.
 */
@interface GTLRDataproc_BasicYarnAutoscalingConfig : GTLRObject

/**
 *  Required. Timeout for YARN graceful decommissioning of Node Managers.
 *  Specifies the duration to wait for jobs to complete before forcefully
 *  removing workers (and potentially interrupting jobs). Only applicable to
 *  downscaling operations.Bounds: 0s, 1d.
 */
@property(nonatomic, strong, nullable) GTLRDuration *gracefulDecommissionTimeout;

/**
 *  Required. Fraction of average YARN pending memory in the last cooldown
 *  period for which to remove workers. A scale-down factor of 1 will result in
 *  scaling down so that there is no available memory remaining after the update
 *  (more aggressive scaling). A scale-down factor of 0 disables removing
 *  workers, which can be beneficial for autoscaling a single job. See How
 *  autoscaling works
 *  (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/autoscaling#how_autoscaling_works)
 *  for more information.Bounds: 0.0, 1.0.
 *
 *  Uses NSNumber of doubleValue.
 */
@property(nonatomic, strong, nullable) NSNumber *scaleDownFactor;

/**
 *  Optional. Minimum scale-down threshold as a fraction of total cluster size
 *  before scaling occurs. For example, in a 20-worker cluster, a threshold of
 *  0.1 means the autoscaler must recommend at least a 2 worker scale-down for
 *  the cluster to scale. A threshold of 0 means the autoscaler will scale down
 *  on any recommended change.Bounds: 0.0, 1.0. Default: 0.0.
 *
 *  Uses NSNumber of doubleValue.
 */
@property(nonatomic, strong, nullable) NSNumber *scaleDownMinWorkerFraction;

/**
 *  Required. Fraction of average YARN pending memory in the last cooldown
 *  period for which to add workers. A scale-up factor of 1.0 will result in
 *  scaling up so that there is no pending memory remaining after the update
 *  (more aggressive scaling). A scale-up factor closer to 0 will result in a
 *  smaller magnitude of scaling up (less aggressive scaling). See How
 *  autoscaling works
 *  (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/autoscaling#how_autoscaling_works)
 *  for more information.Bounds: 0.0, 1.0.
 *
 *  Uses NSNumber of doubleValue.
 */
@property(nonatomic, strong, nullable) NSNumber *scaleUpFactor;

/**
 *  Optional. Minimum scale-up threshold as a fraction of total cluster size
 *  before scaling occurs. For example, in a 20-worker cluster, a threshold of
 *  0.1 means the autoscaler must recommend at least a 2-worker scale-up for the
 *  cluster to scale. A threshold of 0 means the autoscaler will scale up on any
 *  recommended change.Bounds: 0.0, 1.0. Default: 0.0.
 *
 *  Uses NSNumber of doubleValue.
 */
@property(nonatomic, strong, nullable) NSNumber *scaleUpMinWorkerFraction;

@end


/**
 *  A representation of a batch workload in the service.
 */
@interface GTLRDataproc_Batch : GTLRObject

/** Output only. The time when the batch was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/** Output only. The email address of the user who created the batch. */
@property(nonatomic, copy, nullable) NSString *creator;

/** Optional. Environment configuration for the batch execution. */
@property(nonatomic, strong, nullable) GTLRDataproc_EnvironmentConfig *environmentConfig;

/**
 *  Optional. The labels to associate with this batch. Label keys must contain 1
 *  to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if
 *  present, must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be
 *  associated with a batch.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_Batch_Labels *labels;

/** Output only. The resource name of the batch. */
@property(nonatomic, copy, nullable) NSString *name;

/**
 *  Output only. The resource name of the operation associated with this batch.
 */
@property(nonatomic, copy, nullable) NSString *operation;

/** Optional. PySpark batch config. */
@property(nonatomic, strong, nullable) GTLRDataproc_PySparkBatch *pysparkBatch;

/** Optional. Runtime configuration for the batch execution. */
@property(nonatomic, strong, nullable) GTLRDataproc_RuntimeConfig *runtimeConfig;

/** Output only. Runtime information about batch execution. */
@property(nonatomic, strong, nullable) GTLRDataproc_RuntimeInfo *runtimeInfo;

/** Optional. Spark batch config. */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkBatch *sparkBatch;

/** Optional. SparkR batch config. */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkRBatch *sparkRBatch;

/** Optional. SparkSql batch config. */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkSqlBatch *sparkSqlBatch;

/**
 *  Output only. The state of the batch.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_Batch_State_Cancelled The batch cancellation was
 *        successful. (Value: "CANCELLED")
 *    @arg @c kGTLRDataproc_Batch_State_Cancelling The batch is cancelling.
 *        (Value: "CANCELLING")
 *    @arg @c kGTLRDataproc_Batch_State_Failed The batch is no longer running
 *        due to an error. (Value: "FAILED")
 *    @arg @c kGTLRDataproc_Batch_State_Pending The batch is created before
 *        running. (Value: "PENDING")
 *    @arg @c kGTLRDataproc_Batch_State_Running The batch is running. (Value:
 *        "RUNNING")
 *    @arg @c kGTLRDataproc_Batch_State_StateUnspecified The batch state is
 *        unknown. (Value: "STATE_UNSPECIFIED")
 *    @arg @c kGTLRDataproc_Batch_State_Succeeded The batch completed
 *        successfully. (Value: "SUCCEEDED")
 */
@property(nonatomic, copy, nullable) NSString *state;

/** Output only. Historical state information for the batch. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_StateHistory *> *stateHistory;

/**
 *  Output only. Batch state details, such as a failure description if the state
 *  is FAILED.
 */
@property(nonatomic, copy, nullable) NSString *stateMessage;

/** Output only. The time when the batch entered a current state. */
@property(nonatomic, strong, nullable) GTLRDateTime *stateTime;

/**
 *  Output only. A batch UUID (Unique Universal Identifier). The service
 *  generates this value when it creates the batch.
 */
@property(nonatomic, copy, nullable) NSString *uuid;

@end


/**
 *  Optional. The labels to associate with this batch. Label keys must contain 1
 *  to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if
 *  present, must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be
 *  associated with a batch.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_Batch_Labels : GTLRObject
@end


/**
 *  Metadata describing the Batch operation.
 */
@interface GTLRDataproc_BatchOperationMetadata : GTLRObject

/** Name of the batch for the operation. */
@property(nonatomic, copy, nullable) NSString *batch;

/** Batch UUID for the operation. */
@property(nonatomic, copy, nullable) NSString *batchUuid;

/** The time when the operation was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Short description of the operation.
 *
 *  Remapped to 'descriptionProperty' to avoid NSObject's 'description'.
 */
@property(nonatomic, copy, nullable) NSString *descriptionProperty;

/** The time when the operation finished. */
@property(nonatomic, strong, nullable) GTLRDateTime *doneTime;

/** Labels associated with the operation. */
@property(nonatomic, strong, nullable) GTLRDataproc_BatchOperationMetadata_Labels *labels;

/**
 *  The operation type.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_BatchOperationMetadata_OperationType_Batch Batch
 *        operation type. (Value: "BATCH")
 *    @arg @c kGTLRDataproc_BatchOperationMetadata_OperationType_BatchOperationTypeUnspecified
 *        Batch operation type is unknown. (Value:
 *        "BATCH_OPERATION_TYPE_UNSPECIFIED")
 */
@property(nonatomic, copy, nullable) NSString *operationType;

/** Warnings encountered during operation execution. */
@property(nonatomic, strong, nullable) NSArray<NSString *> *warnings;

@end


/**
 *  Labels associated with the operation.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_BatchOperationMetadata_Labels : GTLRObject
@end


/**
 *  Associates members, or principals, with a role.
 */
@interface GTLRDataproc_Binding : GTLRObject

/**
 *  The condition that is associated with this binding.If the condition
 *  evaluates to true, then this binding applies to the current request.If the
 *  condition evaluates to false, then this binding does not apply to the
 *  current request. However, a different role binding might grant the same role
 *  to one or more of the principals in this binding.To learn which resources
 *  support conditions in their IAM policies, see the IAM documentation
 *  (https://cloud.google.com/iam/help/conditions/resource-policies).
 */
@property(nonatomic, strong, nullable) GTLRDataproc_Expr *condition;

/**
 *  Specifies the principals requesting access for a Google Cloud resource.
 *  members can have the following values: allUsers: A special identifier that
 *  represents anyone who is on the internet; with or without a Google account.
 *  allAuthenticatedUsers: A special identifier that represents anyone who is
 *  authenticated with a Google account or a service account. user:{emailid}: An
 *  email address that represents a specific Google account. For example,
 *  alice\@example.com . serviceAccount:{emailid}: An email address that
 *  represents a Google service account. For example,
 *  my-other-app\@appspot.gserviceaccount.com.
 *  serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]: An
 *  identifier for a Kubernetes service account
 *  (https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts).
 *  For example, my-project.svc.id.goog[my-namespace/my-kubernetes-sa].
 *  group:{emailid}: An email address that represents a Google group. For
 *  example, admins\@example.com. deleted:user:{emailid}?uid={uniqueid}: An
 *  email address (plus unique identifier) representing a user that has been
 *  recently deleted. For example, alice\@example.com?uid=123456789012345678901.
 *  If the user is recovered, this value reverts to user:{emailid} and the
 *  recovered user retains the role in the binding.
 *  deleted:serviceAccount:{emailid}?uid={uniqueid}: An email address (plus
 *  unique identifier) representing a service account that has been recently
 *  deleted. For example,
 *  my-other-app\@appspot.gserviceaccount.com?uid=123456789012345678901. If the
 *  service account is undeleted, this value reverts to serviceAccount:{emailid}
 *  and the undeleted service account retains the role in the binding.
 *  deleted:group:{emailid}?uid={uniqueid}: An email address (plus unique
 *  identifier) representing a Google group that has been recently deleted. For
 *  example, admins\@example.com?uid=123456789012345678901. If the group is
 *  recovered, this value reverts to group:{emailid} and the recovered group
 *  retains the role in the binding. domain:{domain}: The G Suite domain
 *  (primary) that represents all the users of that domain. For example,
 *  google.com or example.com.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *members;

/**
 *  Role that is assigned to the list of members, or principals. For example,
 *  roles/viewer, roles/editor, or roles/owner.
 */
@property(nonatomic, copy, nullable) NSString *role;

@end


/**
 *  A request to cancel a job.
 */
@interface GTLRDataproc_CancelJobRequest : GTLRObject
@end


/**
 *  Describes the identifying information, config, and status of a Dataproc
 *  cluster
 */
@interface GTLRDataproc_Cluster : GTLRObject

/**
 *  Required. The cluster name, which must be unique within a project. The name
 *  must start with a lowercase letter, and can contain up to 51 lowercase
 *  letters, numbers, and hyphens. It cannot end with a hyphen. The name of a
 *  deleted cluster can be reused.
 */
@property(nonatomic, copy, nullable) NSString *clusterName;

/**
 *  Output only. A cluster UUID (Unique Universal Identifier). Dataproc
 *  generates this value when it creates the cluster.
 */
@property(nonatomic, copy, nullable) NSString *clusterUuid;

/**
 *  Optional. The cluster config for a cluster of Compute Engine Instances. Note
 *  that Dataproc may set default values, and values may change when clusters
 *  are updated.Exactly one of ClusterConfig or VirtualClusterConfig must be
 *  specified.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_ClusterConfig *config;

/**
 *  Optional. The labels to associate with this cluster. Label keys must contain
 *  1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if
 *  present, must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be
 *  associated with a cluster.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_Cluster_Labels *labels;

/**
 *  Output only. Contains cluster daemon metrics such as HDFS and YARN
 *  stats.Beta Feature: This report is available for testing purposes only. It
 *  may be changed before final release.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_ClusterMetrics *metrics;

/**
 *  Required. The Google Cloud Platform project ID that the cluster belongs to.
 */
@property(nonatomic, copy, nullable) NSString *projectId;

/** Output only. Cluster status. */
@property(nonatomic, strong, nullable) GTLRDataproc_ClusterStatus *status;

/** Output only. The previous cluster status. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_ClusterStatus *> *statusHistory;

/**
 *  Optional. The virtual cluster config is used when creating a Dataproc
 *  cluster that does not directly control the underlying compute resources, for
 *  example, when creating a Dataproc-on-GKE cluster
 *  (https://cloud.google.com/dataproc/docs/guides/dpgke/dataproc-gke). Dataproc
 *  may set default values, and values may change when clusters are updated.
 *  Exactly one of config or virtual_cluster_config must be specified.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_VirtualClusterConfig *virtualClusterConfig;

@end


/**
 *  Optional. The labels to associate with this cluster. Label keys must contain
 *  1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if
 *  present, must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be
 *  associated with a cluster.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_Cluster_Labels : GTLRObject
@end


/**
 *  The cluster config.
 */
@interface GTLRDataproc_ClusterConfig : GTLRObject

/**
 *  Optional. Autoscaling config for the policy associated with the cluster.
 *  Cluster does not autoscale if this field is unset.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_AutoscalingConfig *autoscalingConfig;

/**
 *  Optional. A Cloud Storage bucket used to stage job dependencies, config
 *  files, and job driver console output. If you do not specify a staging
 *  bucket, Cloud Dataproc will determine a Cloud Storage location (US, ASIA, or
 *  EU) for your cluster's staging bucket according to the Compute Engine zone
 *  where your cluster is deployed, and then create and manage this
 *  project-level, per-location bucket (see Dataproc staging and temp buckets
 *  (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)).
 *  This field requires a Cloud Storage bucket name, not a gs://... URI to a
 *  Cloud Storage bucket.
 */
@property(nonatomic, copy, nullable) NSString *configBucket;

/** Optional. The config for Dataproc metrics. */
@property(nonatomic, strong, nullable) GTLRDataproc_MetricConfig *dataprocMetricConfig;

/** Optional. Encryption settings for the cluster. */
@property(nonatomic, strong, nullable) GTLRDataproc_EncryptionConfig *encryptionConfig;

/** Optional. Port/endpoint configuration for this cluster */
@property(nonatomic, strong, nullable) GTLRDataproc_EndpointConfig *endpointConfig;

/**
 *  Optional. The shared Compute Engine config settings for all instances in a
 *  cluster.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_GceClusterConfig *gceClusterConfig;

/**
 *  Optional. BETA. The Kubernetes Engine config for Dataproc clusters deployed
 *  to The Kubernetes Engine config for Dataproc clusters deployed to
 *  Kubernetes. These config settings are mutually exclusive with Compute
 *  Engine-based options, such as gce_cluster_config, master_config,
 *  worker_config, secondary_worker_config, and autoscaling_config.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_GkeClusterConfig *gkeClusterConfig;

/**
 *  Optional. Commands to execute on each node after config is completed. By
 *  default, executables are run on master and all worker nodes. You can test a
 *  node's role metadata to run an executable on a master or worker node, as
 *  shown below using curl (you can also use wget): ROLE=$(curl -H
 *  Metadata-Flavor:Google
 *  http://metadata/computeMetadata/v1/instance/attributes/dataproc-role) if [[
 *  "${ROLE}" == 'Master' ]]; then ... master specific actions ... else ...
 *  worker specific actions ... fi
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_NodeInitializationAction *> *initializationActions;

/** Optional. Lifecycle setting for the cluster. */
@property(nonatomic, strong, nullable) GTLRDataproc_LifecycleConfig *lifecycleConfig;

/**
 *  Optional. The Compute Engine config settings for the cluster's master
 *  instance.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_InstanceGroupConfig *masterConfig;

/** Optional. Metastore configuration. */
@property(nonatomic, strong, nullable) GTLRDataproc_MetastoreConfig *metastoreConfig;

/**
 *  Optional. The Compute Engine config settings for a cluster's secondary
 *  worker instances
 */
@property(nonatomic, strong, nullable) GTLRDataproc_InstanceGroupConfig *secondaryWorkerConfig;

/** Optional. Security settings for the cluster. */
@property(nonatomic, strong, nullable) GTLRDataproc_SecurityConfig *securityConfig;

/** Optional. The config settings for cluster software. */
@property(nonatomic, strong, nullable) GTLRDataproc_SoftwareConfig *softwareConfig;

/**
 *  Optional. A Cloud Storage bucket used to store ephemeral cluster and jobs
 *  data, such as Spark and MapReduce history files. If you do not specify a
 *  temp bucket, Dataproc will determine a Cloud Storage location (US, ASIA, or
 *  EU) for your cluster's temp bucket according to the Compute Engine zone
 *  where your cluster is deployed, and then create and manage this
 *  project-level, per-location bucket. The default bucket has a TTL of 90 days,
 *  but you can use any TTL (or none) if you specify a bucket (see Dataproc
 *  staging and temp buckets
 *  (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)).
 *  This field requires a Cloud Storage bucket name, not a gs://... URI to a
 *  Cloud Storage bucket.
 */
@property(nonatomic, copy, nullable) NSString *tempBucket;

/**
 *  Optional. The Compute Engine config settings for the cluster's worker
 *  instances.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_InstanceGroupConfig *workerConfig;

@end


/**
 *  Contains cluster daemon metrics, such as HDFS and YARN stats.Beta Feature:
 *  This report is available for testing purposes only. It may be changed before
 *  final release.
 */
@interface GTLRDataproc_ClusterMetrics : GTLRObject

/** The HDFS metrics. */
@property(nonatomic, strong, nullable) GTLRDataproc_ClusterMetrics_HdfsMetrics *hdfsMetrics;

/** YARN metrics. */
@property(nonatomic, strong, nullable) GTLRDataproc_ClusterMetrics_YarnMetrics *yarnMetrics;

@end


/**
 *  The HDFS metrics.
 *
 *  @note This class is documented as having more properties of NSNumber (Uses
 *        NSNumber of longLongValue.). Use @c -additionalJSONKeys and @c
 *        -additionalPropertyForName: to get the list of properties and then
 *        fetch them; or @c -additionalProperties to fetch them all at once.
 */
@interface GTLRDataproc_ClusterMetrics_HdfsMetrics : GTLRObject
@end


/**
 *  YARN metrics.
 *
 *  @note This class is documented as having more properties of NSNumber (Uses
 *        NSNumber of longLongValue.). Use @c -additionalJSONKeys and @c
 *        -additionalPropertyForName: to get the list of properties and then
 *        fetch them; or @c -additionalProperties to fetch them all at once.
 */
@interface GTLRDataproc_ClusterMetrics_YarnMetrics : GTLRObject
@end


/**
 *  The cluster operation triggered by a workflow.
 */
@interface GTLRDataproc_ClusterOperation : GTLRObject

/**
 *  Output only. Indicates the operation is done.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *done;

/** Output only. Error, if operation failed. */
@property(nonatomic, copy, nullable) NSString *error;

/** Output only. The id of the cluster operation. */
@property(nonatomic, copy, nullable) NSString *operationId;

@end


/**
 *  Metadata describing the operation.
 */
@interface GTLRDataproc_ClusterOperationMetadata : GTLRObject

/** Output only. Child operation ids */
@property(nonatomic, strong, nullable) NSArray<NSString *> *childOperationIds;

/** Output only. Name of the cluster for the operation. */
@property(nonatomic, copy, nullable) NSString *clusterName;

/** Output only. Cluster UUID for the operation. */
@property(nonatomic, copy, nullable) NSString *clusterUuid;

/**
 *  Output only. Short description of operation.
 *
 *  Remapped to 'descriptionProperty' to avoid NSObject's 'description'.
 */
@property(nonatomic, copy, nullable) NSString *descriptionProperty;

/** Output only. Labels associated with the operation */
@property(nonatomic, strong, nullable) GTLRDataproc_ClusterOperationMetadata_Labels *labels;

/** Output only. The operation type. */
@property(nonatomic, copy, nullable) NSString *operationType;

/** Output only. Current operation status. */
@property(nonatomic, strong, nullable) GTLRDataproc_ClusterOperationStatus *status;

/** Output only. The previous operation status. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_ClusterOperationStatus *> *statusHistory;

/** Output only. Errors encountered during operation execution. */
@property(nonatomic, strong, nullable) NSArray<NSString *> *warnings;

@end


/**
 *  Output only. Labels associated with the operation
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_ClusterOperationMetadata_Labels : GTLRObject
@end


/**
 *  The status of the operation.
 */
@interface GTLRDataproc_ClusterOperationStatus : GTLRObject

/** Output only. A message containing any operation metadata details. */
@property(nonatomic, copy, nullable) NSString *details;

/** Output only. A message containing the detailed operation state. */
@property(nonatomic, copy, nullable) NSString *innerState;

/**
 *  Output only. A message containing the operation state.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_ClusterOperationStatus_State_Done The operation is
 *        done; either cancelled or completed. (Value: "DONE")
 *    @arg @c kGTLRDataproc_ClusterOperationStatus_State_Pending The operation
 *        has been created. (Value: "PENDING")
 *    @arg @c kGTLRDataproc_ClusterOperationStatus_State_Running The operation
 *        is running. (Value: "RUNNING")
 *    @arg @c kGTLRDataproc_ClusterOperationStatus_State_Unknown Unused. (Value:
 *        "UNKNOWN")
 */
@property(nonatomic, copy, nullable) NSString *state;

/** Output only. The time this state was entered. */
@property(nonatomic, strong, nullable) GTLRDateTime *stateStartTime;

@end


/**
 *  A selector that chooses target cluster for jobs based on metadata.
 */
@interface GTLRDataproc_ClusterSelector : GTLRObject

/** Required. The cluster labels. Cluster must have all labels to match. */
@property(nonatomic, strong, nullable) GTLRDataproc_ClusterSelector_ClusterLabels *clusterLabels;

/**
 *  Optional. The zone where workflow process executes. This parameter does not
 *  affect the selection of the cluster.If unspecified, the zone of the first
 *  cluster matching the selector is used.
 *
 *  Remapped to 'zoneProperty' to avoid NSObject's 'zone'.
 */
@property(nonatomic, copy, nullable) NSString *zoneProperty;

@end


/**
 *  Required. The cluster labels. Cluster must have all labels to match.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_ClusterSelector_ClusterLabels : GTLRObject
@end


/**
 *  The status of a cluster and its instances.
 */
@interface GTLRDataproc_ClusterStatus : GTLRObject

/** Optional. Output only. Details of cluster's state. */
@property(nonatomic, copy, nullable) NSString *detail;

/**
 *  Output only. The cluster's state.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_ClusterStatus_State_Creating The cluster is being
 *        created and set up. It is not ready for use. (Value: "CREATING")
 *    @arg @c kGTLRDataproc_ClusterStatus_State_Deleting The cluster is being
 *        deleted. It cannot be used. (Value: "DELETING")
 *    @arg @c kGTLRDataproc_ClusterStatus_State_Error The cluster encountered an
 *        error. It is not ready for use. (Value: "ERROR")
 *    @arg @c kGTLRDataproc_ClusterStatus_State_ErrorDueToUpdate The cluster has
 *        encountered an error while being updated. Jobs can be submitted to the
 *        cluster, but the cluster cannot be updated. (Value:
 *        "ERROR_DUE_TO_UPDATE")
 *    @arg @c kGTLRDataproc_ClusterStatus_State_Repairing The cluster is being
 *        repaired. It is not ready for use. (Value: "REPAIRING")
 *    @arg @c kGTLRDataproc_ClusterStatus_State_Running The cluster is currently
 *        running and healthy. It is ready for use.Note: The cluster state
 *        changes from "creating" to "running" status after the master node(s),
 *        first two primary worker nodes (and the last primary worker node if
 *        primary workers > 2) are running. (Value: "RUNNING")
 *    @arg @c kGTLRDataproc_ClusterStatus_State_Starting The cluster is being
 *        started. It is not ready for use. (Value: "STARTING")
 *    @arg @c kGTLRDataproc_ClusterStatus_State_Stopped The cluster is currently
 *        stopped. It is not ready for use. (Value: "STOPPED")
 *    @arg @c kGTLRDataproc_ClusterStatus_State_Stopping The cluster is being
 *        stopped. It cannot be used. (Value: "STOPPING")
 *    @arg @c kGTLRDataproc_ClusterStatus_State_Unknown The cluster state is
 *        unknown. (Value: "UNKNOWN")
 *    @arg @c kGTLRDataproc_ClusterStatus_State_Updating The cluster is being
 *        updated. It continues to accept and process jobs. (Value: "UPDATING")
 */
@property(nonatomic, copy, nullable) NSString *state;

/**
 *  Output only. Time when this state was entered (see JSON representation of
 *  Timestamp
 *  (https://developers.google.com/protocol-buffers/docs/proto3#json)).
 */
@property(nonatomic, strong, nullable) GTLRDateTime *stateStartTime;

/**
 *  Output only. Additional state information that includes status reported by
 *  the agent.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_ClusterStatus_Substate_StaleStatus The
 *        agent-reported status is out of date (may occur if Dataproc loses
 *        communication with Agent).Applies to RUNNING state. (Value:
 *        "STALE_STATUS")
 *    @arg @c kGTLRDataproc_ClusterStatus_Substate_Unhealthy The cluster is
 *        known to be in an unhealthy state (for example, critical daemons are
 *        not running or HDFS capacity is exhausted).Applies to RUNNING state.
 *        (Value: "UNHEALTHY")
 *    @arg @c kGTLRDataproc_ClusterStatus_Substate_Unspecified The cluster
 *        substate is unknown. (Value: "UNSPECIFIED")
 */
@property(nonatomic, copy, nullable) NSString *substate;

@end


/**
 *  Confidential Instance Config for clusters using Confidential VMs
 *  (https://cloud.google.com/compute/confidential-vm/docs)
 */
@interface GTLRDataproc_ConfidentialInstanceConfig : GTLRObject

/**
 *  Optional. Defines whether the instance should have confidential compute
 *  enabled.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *enableConfidentialCompute;

@end


/**
 *  A request to collect cluster diagnostic information.
 */
@interface GTLRDataproc_DiagnoseClusterRequest : GTLRObject
@end


/**
 *  The location of diagnostic output.
 */
@interface GTLRDataproc_DiagnoseClusterResults : GTLRObject

/**
 *  Output only. The Cloud Storage URI of the diagnostic output. The output
 *  report is a plain text file with a summary of collected diagnostics.
 */
@property(nonatomic, copy, nullable) NSString *outputUri;

@end


/**
 *  Specifies the config of disk options for a group of VM instances.
 */
@interface GTLRDataproc_DiskConfig : GTLRObject

/**
 *  Optional. Size in GB of the boot disk (default is 500GB).
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *bootDiskSizeGb;

/**
 *  Optional. Type of the boot disk (default is "pd-standard"). Valid values:
 *  "pd-balanced" (Persistent Disk Balanced Solid State Drive), "pd-ssd"
 *  (Persistent Disk Solid State Drive), or "pd-standard" (Persistent Disk Hard
 *  Disk Drive). See Disk types
 *  (https://cloud.google.com/compute/docs/disks#disk-types).
 */
@property(nonatomic, copy, nullable) NSString *bootDiskType;

/**
 *  Optional. Interface type of local SSDs (default is "scsi"). Valid values:
 *  "scsi" (Small Computer System Interface), "nvme" (Non-Volatile Memory
 *  Express). See local SSD performance
 *  (https://cloud.google.com/compute/docs/disks/local-ssd#performance).
 */
@property(nonatomic, copy, nullable) NSString *localSsdInterface;

/**
 *  Optional. Number of attached SSDs, from 0 to 8 (default is 0). If SSDs are
 *  not attached, the boot disk is used to store runtime logs and HDFS
 *  (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data. If one or
 *  more SSDs are attached, this runtime bulk data is spread across them, and
 *  the boot disk contains only basic config and installed binaries.Note: Local
 *  SSD options may vary by machine type and number of vCPUs selected.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *numLocalSsds;

@end


/**
 *  A generic empty message that you can re-use to avoid defining duplicated
 *  empty messages in your APIs. A typical example is to use it as the request
 *  or the response type of an API method. For instance: service Foo { rpc
 *  Bar(google.protobuf.Empty) returns (google.protobuf.Empty); }
 */
@interface GTLRDataproc_Empty : GTLRObject
@end


/**
 *  Encryption settings for the cluster.
 */
@interface GTLRDataproc_EncryptionConfig : GTLRObject

/**
 *  Optional. The Cloud KMS key name to use for PD disk encryption for all
 *  instances in the cluster.
 */
@property(nonatomic, copy, nullable) NSString *gcePdKmsKeyName;

@end


/**
 *  Endpoint config for this cluster
 */
@interface GTLRDataproc_EndpointConfig : GTLRObject

/**
 *  Optional. If true, enable http access to specific ports on the cluster from
 *  external sources. Defaults to false.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *enableHttpPortAccess;

/**
 *  Output only. The map of port descriptions to URLs. Will only be populated if
 *  enable_http_port_access is true.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_EndpointConfig_HttpPorts *httpPorts;

@end


/**
 *  Output only. The map of port descriptions to URLs. Will only be populated if
 *  enable_http_port_access is true.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_EndpointConfig_HttpPorts : GTLRObject
@end


/**
 *  Environment configuration for a workload.
 */
@interface GTLRDataproc_EnvironmentConfig : GTLRObject

/** Optional. Execution configuration for a workload. */
@property(nonatomic, strong, nullable) GTLRDataproc_ExecutionConfig *executionConfig;

/** Optional. Peripherals configuration that workload has access to. */
@property(nonatomic, strong, nullable) GTLRDataproc_PeripheralsConfig *peripheralsConfig;

@end


/**
 *  Execution configuration for a workload.
 */
@interface GTLRDataproc_ExecutionConfig : GTLRObject

/**
 *  Optional. The duration to keep the underlying cluster alive while idling
 *  Passing this threshold will cause the cluster to be terminated. Minimum
 *  value is 30 minutes; maximum value is 14 days (see JSON representation of
 *  Duration (https://developers.google.com/protocol-buffers/docs/proto3#json)).
 */
@property(nonatomic, strong, nullable) GTLRDuration *idleTtl;

/** Optional. The Cloud KMS key to use for encryption. */
@property(nonatomic, copy, nullable) NSString *kmsKey;

/** Optional. Tags used for network traffic control. */
@property(nonatomic, strong, nullable) NSArray<NSString *> *networkTags;

/** Optional. Network URI to connect workload to. */
@property(nonatomic, copy, nullable) NSString *networkUri;

/** Optional. Service account that used to execute workload. */
@property(nonatomic, copy, nullable) NSString *serviceAccount;

/** Optional. Subnetwork URI to connect workload to. */
@property(nonatomic, copy, nullable) NSString *subnetworkUri;

@end


/**
 *  Represents a textual expression in the Common Expression Language (CEL)
 *  syntax. CEL is a C-like expression language. The syntax and semantics of CEL
 *  are documented at https://github.com/google/cel-spec.Example (Comparison):
 *  title: "Summary size limit" description: "Determines if a summary is less
 *  than 100 chars" expression: "document.summary.size() < 100" Example
 *  (Equality): title: "Requestor is owner" description: "Determines if
 *  requestor is the document owner" expression: "document.owner ==
 *  request.auth.claims.email" Example (Logic): title: "Public documents"
 *  description: "Determine whether the document should be publicly visible"
 *  expression: "document.type != 'private' && document.type != 'internal'"
 *  Example (Data Manipulation): title: "Notification string" description:
 *  "Create a notification string with a timestamp." expression: "'New message
 *  received at ' + string(document.create_time)" The exact variables and
 *  functions that may be referenced within an expression are determined by the
 *  service that evaluates it. See the service documentation for additional
 *  information.
 */
@interface GTLRDataproc_Expr : GTLRObject

/**
 *  Optional. Description of the expression. This is a longer text which
 *  describes the expression, e.g. when hovered over it in a UI.
 *
 *  Remapped to 'descriptionProperty' to avoid NSObject's 'description'.
 */
@property(nonatomic, copy, nullable) NSString *descriptionProperty;

/**
 *  Textual representation of an expression in Common Expression Language
 *  syntax.
 */
@property(nonatomic, copy, nullable) NSString *expression;

/**
 *  Optional. String indicating the location of the expression for error
 *  reporting, e.g. a file name and a position in the file.
 */
@property(nonatomic, copy, nullable) NSString *location;

/**
 *  Optional. Title for the expression, i.e. a short string describing its
 *  purpose. This can be used e.g. in UIs which allow to enter the expression.
 */
@property(nonatomic, copy, nullable) NSString *title;

@end


/**
 *  Common config settings for resources of Compute Engine cluster instances,
 *  applicable to all instances in the cluster.
 */
@interface GTLRDataproc_GceClusterConfig : GTLRObject

/**
 *  Optional. Confidential Instance Config for clusters using Confidential VMs
 *  (https://cloud.google.com/compute/confidential-vm/docs).
 */
@property(nonatomic, strong, nullable) GTLRDataproc_ConfidentialInstanceConfig *confidentialInstanceConfig;

/**
 *  Optional. If true, all instances in the cluster will only have internal IP
 *  addresses. By default, clusters are not restricted to internal IP addresses,
 *  and will have ephemeral external IP addresses assigned to each instance.
 *  This internal_ip_only restriction can only be enabled for subnetwork enabled
 *  networks, and all off-cluster dependencies must be configured to be
 *  accessible without external IP addresses.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *internalIpOnly;

/**
 *  The Compute Engine metadata entries to add to all instances (see Project and
 *  instance metadata
 *  (https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
 */
@property(nonatomic, strong, nullable) GTLRDataproc_GceClusterConfig_Metadata *metadata;

/**
 *  Optional. The Compute Engine network to be used for machine communications.
 *  Cannot be specified with subnetwork_uri. If neither network_uri nor
 *  subnetwork_uri is specified, the "default" network of the project is used,
 *  if it exists. Cannot be a "Custom Subnet Network" (see Using Subnetworks
 *  (https://cloud.google.com/compute/docs/subnetworks) for more information).A
 *  full URL, partial URI, or short name are valid. Examples:
 *  https://www.googleapis.com/compute/v1/projects/[project_id]/regions/global/default
 *  projects/[project_id]/regions/global/default default
 */
@property(nonatomic, copy, nullable) NSString *networkUri;

/** Optional. Node Group Affinity for sole-tenant clusters. */
@property(nonatomic, strong, nullable) GTLRDataproc_NodeGroupAffinity *nodeGroupAffinity;

/**
 *  Optional. The type of IPv6 access for a cluster.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_GceClusterConfig_PrivateIpv6GoogleAccess_Bidirectional
 *        Enables bidirectional private IPv6 access between Google Services and
 *        the Dataproc cluster. (Value: "BIDIRECTIONAL")
 *    @arg @c kGTLRDataproc_GceClusterConfig_PrivateIpv6GoogleAccess_InheritFromSubnetwork
 *        Private access to and from Google Services configuration inherited
 *        from the subnetwork configuration. This is the default Compute Engine
 *        behavior. (Value: "INHERIT_FROM_SUBNETWORK")
 *    @arg @c kGTLRDataproc_GceClusterConfig_PrivateIpv6GoogleAccess_Outbound
 *        Enables outbound private IPv6 access to Google Services from the
 *        Dataproc cluster. (Value: "OUTBOUND")
 *    @arg @c kGTLRDataproc_GceClusterConfig_PrivateIpv6GoogleAccess_PrivateIpv6GoogleAccessUnspecified
 *        If unspecified, Compute Engine default behavior will apply, which is
 *        the same as INHERIT_FROM_SUBNETWORK. (Value:
 *        "PRIVATE_IPV6_GOOGLE_ACCESS_UNSPECIFIED")
 */
@property(nonatomic, copy, nullable) NSString *privateIpv6GoogleAccess;

/** Optional. Reservation Affinity for consuming Zonal reservation. */
@property(nonatomic, strong, nullable) GTLRDataproc_ReservationAffinity *reservationAffinity;

/**
 *  Optional. The Dataproc service account
 *  (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/service-accounts#service_accounts_in_dataproc)
 *  (also see VM Data Plane identity
 *  (https://cloud.google.com/dataproc/docs/concepts/iam/dataproc-principals#vm_service_account_data_plane_identity))
 *  used by Dataproc cluster VM instances to access Google Cloud Platform
 *  services.If not specified, the Compute Engine default service account
 *  (https://cloud.google.com/compute/docs/access/service-accounts#default_service_account)
 *  is used.
 */
@property(nonatomic, copy, nullable) NSString *serviceAccount;

/**
 *  Optional. The URIs of service account scopes to be included in Compute
 *  Engine instances. The following base set of scopes is always included:
 *  https://www.googleapis.com/auth/cloud.useraccounts.readonly
 *  https://www.googleapis.com/auth/devstorage.read_write
 *  https://www.googleapis.com/auth/logging.writeIf no scopes are specified, the
 *  following defaults are also provided:
 *  https://www.googleapis.com/auth/bigquery
 *  https://www.googleapis.com/auth/bigtable.admin.table
 *  https://www.googleapis.com/auth/bigtable.data
 *  https://www.googleapis.com/auth/devstorage.full_control
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *serviceAccountScopes;

/**
 *  Optional. Shielded Instance Config for clusters using Compute Engine
 *  Shielded VMs (https://cloud.google.com/security/shielded-cloud/shielded-vm).
 */
@property(nonatomic, strong, nullable) GTLRDataproc_ShieldedInstanceConfig *shieldedInstanceConfig;

/**
 *  Optional. The Compute Engine subnetwork to be used for machine
 *  communications. Cannot be specified with network_uri.A full URL, partial
 *  URI, or short name are valid. Examples:
 *  https://www.googleapis.com/compute/v1/projects/[project_id]/regions/us-east1/subnetworks/sub0
 *  projects/[project_id]/regions/us-east1/subnetworks/sub0 sub0
 */
@property(nonatomic, copy, nullable) NSString *subnetworkUri;

/**
 *  The Compute Engine tags to add to all instances (see Tagging instances
 *  (https://cloud.google.com/compute/docs/label-or-tag-resources#tags)).
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *tags;

/**
 *  Optional. The zone where the Compute Engine cluster will be located. On a
 *  create request, it is required in the "global" region. If omitted in a
 *  non-global Dataproc region, the service will pick a zone in the
 *  corresponding Compute Engine region. On a get request, zone will always be
 *  present.A full URL, partial URI, or short name are valid. Examples:
 *  https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone]
 *  projects/[project_id]/zones/[zone] us-central1-f
 */
@property(nonatomic, copy, nullable) NSString *zoneUri;

@end


/**
 *  The Compute Engine metadata entries to add to all instances (see Project and
 *  instance metadata
 *  (https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_GceClusterConfig_Metadata : GTLRObject
@end


/**
 *  Request message for GetIamPolicy method.
 */
@interface GTLRDataproc_GetIamPolicyRequest : GTLRObject

/**
 *  OPTIONAL: A GetPolicyOptions object for specifying options to GetIamPolicy.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_GetPolicyOptions *options;

@end


/**
 *  Encapsulates settings provided to GetIamPolicy.
 */
@interface GTLRDataproc_GetPolicyOptions : GTLRObject

/**
 *  Optional. The maximum policy version that will be used to format the
 *  policy.Valid values are 0, 1, and 3. Requests specifying an invalid value
 *  will be rejected.Requests for policies with any conditional role bindings
 *  must specify version 3. Policies with no conditional role bindings may
 *  specify any valid value or leave the field unset.The policy in the response
 *  might use the policy version that you specified, or it might use a lower
 *  policy version. For example, if you specify version 3, but the policy has no
 *  conditional role bindings, the response uses version 1.To learn which
 *  resources support conditions in their IAM policies, see the IAM
 *  documentation
 *  (https://cloud.google.com/iam/help/conditions/resource-policies).
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *requestedPolicyVersion;

@end


/**
 *  The cluster's GKE config.
 */
@interface GTLRDataproc_GkeClusterConfig : GTLRObject

/**
 *  Optional. A target GKE cluster to deploy to. It must be in the same project
 *  and region as the Dataproc cluster (the GKE cluster can be zonal or
 *  regional). Format:
 *  'projects/{project}/locations/{location}/clusters/{cluster_id}'
 */
@property(nonatomic, copy, nullable) NSString *gkeClusterTarget;

/**
 *  Optional. Deprecated. Use gkeClusterTarget. Used only for the deprecated
 *  beta. A target for the deployment.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_NamespacedGkeDeploymentTarget *namespacedGkeDeploymentTarget;

/**
 *  Optional. GKE node pools where workloads will be scheduled. At least one
 *  node pool must be assigned the DEFAULT GkeNodePoolTarget.Role. If a
 *  GkeNodePoolTarget is not specified, Dataproc constructs a DEFAULT
 *  GkeNodePoolTarget. Each role can be given to only one GkeNodePoolTarget. All
 *  node pools must have the same location settings.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_GkeNodePoolTarget *> *nodePoolTarget;

@end


/**
 *  Parameters that describe cluster nodes.
 */
@interface GTLRDataproc_GkeNodeConfig : GTLRObject

/**
 *  Optional. A list of hardware accelerators
 *  (https://cloud.google.com/compute/docs/gpus) to attach to each node.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_GkeNodePoolAcceleratorConfig *> *accelerators;

/**
 *  Optional. The Customer Managed Encryption Key (CMEK)
 *  (https://cloud.google.com/kubernetes-engine/docs/how-to/using-cmek) used to
 *  encrypt the boot disk attached to each node in the node pool. Specify the
 *  key using the following format: projects/KEY_PROJECT_ID/locations/LOCATION
 *  /keyRings/RING_NAME/cryptoKeys/KEY_NAME.
 */
@property(nonatomic, copy, nullable) NSString *bootDiskKmsKey;

/**
 *  Optional. The number of local SSD disks to attach to the node, which is
 *  limited by the maximum number of disks allowable per zone (see Adding Local
 *  SSDs (https://cloud.google.com/compute/docs/disks/local-ssd)).
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *localSsdCount;

/**
 *  Optional. The name of a Compute Engine machine type
 *  (https://cloud.google.com/compute/docs/machine-types).
 */
@property(nonatomic, copy, nullable) NSString *machineType;

/**
 *  Optional. Minimum CPU platform
 *  (https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
 *  to be used by this instance. The instance may be scheduled on the specified
 *  or a newer CPU platform. Specify the friendly names of CPU platforms, such
 *  as "Intel Haswell"` or Intel Sandy Bridge".
 */
@property(nonatomic, copy, nullable) NSString *minCpuPlatform;

/**
 *  Optional. Whether the nodes are created as preemptible VM instances
 *  (https://cloud.google.com/compute/docs/instances/preemptible). Preemptible
 *  nodes cannot be used in a node pool with the CONTROLLER role or in the
 *  DEFAULT node pool if the CONTROLLER role is not assigned (the DEFAULT node
 *  pool will assume the CONTROLLER role).
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *preemptible;

/**
 *  Optional. Spot flag for enabling Spot VM, which is a rebrand of the existing
 *  preemptible flag.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *spot;

@end


/**
 *  A GkeNodeConfigAcceleratorConfig represents a Hardware Accelerator request
 *  for a node pool.
 */
@interface GTLRDataproc_GkeNodePoolAcceleratorConfig : GTLRObject

/**
 *  The number of accelerator cards exposed to an instance.
 *
 *  Uses NSNumber of longLongValue.
 */
@property(nonatomic, strong, nullable) NSNumber *acceleratorCount;

/** The accelerator type resource namename (see GPUs on Compute Engine). */
@property(nonatomic, copy, nullable) NSString *acceleratorType;

/**
 *  Size of partitions to create on the GPU. Valid values are described in the
 *  NVIDIA mig user guide
 *  (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
 */
@property(nonatomic, copy, nullable) NSString *gpuPartitionSize;

@end


/**
 *  GkeNodePoolAutoscaling contains information the cluster autoscaler needs to
 *  adjust the size of the node pool to the current cluster usage.
 */
@interface GTLRDataproc_GkeNodePoolAutoscalingConfig : GTLRObject

/**
 *  The maximum number of nodes in the node pool. Must be >= min_node_count, and
 *  must be > 0. Note: Quota must be sufficient to scale up the cluster.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *maxNodeCount;

/**
 *  The minimum number of nodes in the node pool. Must be >= 0 and <=
 *  max_node_count.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *minNodeCount;

@end


/**
 *  The configuration of a GKE node pool used by a Dataproc-on-GKE cluster
 *  (https://cloud.google.com/dataproc/docs/concepts/jobs/dataproc-gke#create-a-dataproc-on-gke-cluster).
 */
@interface GTLRDataproc_GkeNodePoolConfig : GTLRObject

/**
 *  Optional. The autoscaler configuration for this node pool. The autoscaler is
 *  enabled only when a valid configuration is present.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_GkeNodePoolAutoscalingConfig *autoscaling;

/** Optional. The node pool configuration. */
@property(nonatomic, strong, nullable) GTLRDataproc_GkeNodeConfig *config;

/**
 *  Optional. The list of Compute Engine zones
 *  (https://cloud.google.com/compute/docs/zones#available) where node pool
 *  nodes associated with a Dataproc on GKE virtual cluster will be
 *  located.Note: All node pools associated with a virtual cluster must be
 *  located in the same region as the virtual cluster, and they must be located
 *  in the same zone within that region.If a location is not specified during
 *  node pool creation, Dataproc on GKE will choose the zone.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *locations;

@end


/**
 *  GKE node pools that Dataproc workloads run on.
 */
@interface GTLRDataproc_GkeNodePoolTarget : GTLRObject

/**
 *  Required. The target GKE node pool. Format:
 *  'projects/{project}/locations/{location}/clusters/{cluster}/nodePools/{node_pool}'
 */
@property(nonatomic, copy, nullable) NSString *nodePool;

/**
 *  Input only. The configuration for the GKE node pool.If specified, Dataproc
 *  attempts to create a node pool with the specified shape. If one with the
 *  same name already exists, it is verified against all specified fields. If a
 *  field differs, the virtual cluster creation will fail.If omitted, any node
 *  pool with the specified name is used. If a node pool with the specified name
 *  does not exist, Dataproc create a node pool with default values.This is an
 *  input only field. It will not be returned by the API.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_GkeNodePoolConfig *nodePoolConfig;

/** Required. The roles associated with the GKE node pool. */
@property(nonatomic, strong, nullable) NSArray<NSString *> *roles;

@end


/**
 *  A Dataproc job for running Apache Hadoop MapReduce
 *  (https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html)
 *  jobs on Apache Hadoop YARN
 *  (https://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/YARN.html).
 */
@interface GTLRDataproc_HadoopJob : GTLRObject

/**
 *  Optional. HCFS URIs of archives to be extracted in the working directory of
 *  Hadoop drivers and tasks. Supported file types: .jar, .tar, .tar.gz, .tgz,
 *  or .zip.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *archiveUris;

/**
 *  Optional. The arguments to pass to the driver. Do not include arguments,
 *  such as -libjars or -Dfoo=bar, that can be set as job properties, since a
 *  collision may occur that causes an incorrect job submission.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *args;

/**
 *  Optional. HCFS (Hadoop Compatible Filesystem) URIs of files to be copied to
 *  the working directory of Hadoop drivers and distributed tasks. Useful for
 *  naively parallel tasks.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *fileUris;

/**
 *  Optional. Jar file URIs to add to the CLASSPATHs of the Hadoop driver and
 *  tasks.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *jarFileUris;

/** Optional. The runtime log config for job execution. */
@property(nonatomic, strong, nullable) GTLRDataproc_LoggingConfig *loggingConfig;

/**
 *  The name of the driver's main class. The jar file containing the class must
 *  be in the default CLASSPATH or specified in jar_file_uris.
 */
@property(nonatomic, copy, nullable) NSString *mainClass;

/**
 *  The HCFS URI of the jar file containing the main class. Examples:
 *  'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar'
 *  'hdfs:/tmp/test-samples/custom-wordcount.jar'
 *  'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'
 */
@property(nonatomic, copy, nullable) NSString *mainJarFileUri;

/**
 *  Optional. A mapping of property names to values, used to configure Hadoop.
 *  Properties that conflict with values set by the Dataproc API may be
 *  overwritten. Can include properties set in /etc/hadoop/conf/ *-site and
 *  classes in user code.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_HadoopJob_Properties *properties;

@end


/**
 *  Optional. A mapping of property names to values, used to configure Hadoop.
 *  Properties that conflict with values set by the Dataproc API may be
 *  overwritten. Can include properties set in /etc/hadoop/conf/ *-site and
 *  classes in user code.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_HadoopJob_Properties : GTLRObject
@end


/**
 *  A Dataproc job for running Apache Hive (https://hive.apache.org/) queries on
 *  YARN.
 */
@interface GTLRDataproc_HiveJob : GTLRObject

/**
 *  Optional. Whether to continue executing queries if a query fails. The
 *  default value is false. Setting to true can be useful when executing
 *  independent parallel queries.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *continueOnFailure;

/**
 *  Optional. HCFS URIs of jar files to add to the CLASSPATH of the Hive server
 *  and Hadoop MapReduce (MR) tasks. Can contain Hive SerDes and UDFs.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *jarFileUris;

/**
 *  Optional. A mapping of property names and values, used to configure Hive.
 *  Properties that conflict with values set by the Dataproc API may be
 *  overwritten. Can include properties set in /etc/hadoop/conf/ *-site.xml,
 *  /etc/hive/conf/hive-site.xml, and classes in user code.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_HiveJob_Properties *properties;

/** The HCFS URI of the script that contains Hive queries. */
@property(nonatomic, copy, nullable) NSString *queryFileUri;

/** A list of queries. */
@property(nonatomic, strong, nullable) GTLRDataproc_QueryList *queryList;

/**
 *  Optional. Mapping of query variable names to values (equivalent to the Hive
 *  command: SET name="value";).
 */
@property(nonatomic, strong, nullable) GTLRDataproc_HiveJob_ScriptVariables *scriptVariables;

@end


/**
 *  Optional. A mapping of property names and values, used to configure Hive.
 *  Properties that conflict with values set by the Dataproc API may be
 *  overwritten. Can include properties set in /etc/hadoop/conf/ *-site.xml,
 *  /etc/hive/conf/hive-site.xml, and classes in user code.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_HiveJob_Properties : GTLRObject
@end


/**
 *  Optional. Mapping of query variable names to values (equivalent to the Hive
 *  command: SET name="value";).
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_HiveJob_ScriptVariables : GTLRObject
@end


/**
 *  Identity related configuration, including service account based secure
 *  multi-tenancy user mappings.
 */
@interface GTLRDataproc_IdentityConfig : GTLRObject

/** Required. Map of user to service account. */
@property(nonatomic, strong, nullable) GTLRDataproc_IdentityConfig_UserServiceAccountMapping *userServiceAccountMapping;

@end


/**
 *  Required. Map of user to service account.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_IdentityConfig_UserServiceAccountMapping : GTLRObject
@end


/**
 *  A request to inject credentials into a cluster.
 */
@interface GTLRDataproc_InjectCredentialsRequest : GTLRObject

/** Required. The cluster UUID. */
@property(nonatomic, copy, nullable) NSString *clusterUuid;

/**
 *  Required. The encrypted credentials being injected in to the cluster.The
 *  client is responsible for encrypting the credentials in a way that is
 *  supported by the cluster.A wrapped value is used here so that the actual
 *  contents of the encrypted credentials are not written to audit logs.
 */
@property(nonatomic, copy, nullable) NSString *credentialsCiphertext;

@end


/**
 *  Configuration for the size bounds of an instance group, including its
 *  proportional size to other groups.
 */
@interface GTLRDataproc_InstanceGroupAutoscalingPolicyConfig : GTLRObject

/**
 *  Required. Maximum number of instances for this group. Required for primary
 *  workers. Note that by default, clusters will not use secondary workers.
 *  Required for secondary workers if the minimum secondary instances is
 *  set.Primary workers - Bounds: [min_instances, ). Secondary workers - Bounds:
 *  [min_instances, ). Default: 0.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *maxInstances;

/**
 *  Optional. Minimum number of instances for this group.Primary workers -
 *  Bounds: 2, max_instances. Default: 2. Secondary workers - Bounds: 0,
 *  max_instances. Default: 0.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *minInstances;

/**
 *  Optional. Weight for the instance group, which is used to determine the
 *  fraction of total workers in the cluster from this instance group. For
 *  example, if primary workers have weight 2, and secondary workers have weight
 *  1, the cluster will have approximately 2 primary workers for each secondary
 *  worker.The cluster may not reach the specified balance if constrained by
 *  min/max bounds or other autoscaling settings. For example, if max_instances
 *  for secondary workers is 0, then only primary workers will be added. The
 *  cluster can also be out of balance when created.If weight is not set on any
 *  instance group, the cluster will default to equal weight for all groups: the
 *  cluster will attempt to maintain an equal number of workers in each group
 *  within the configured size bounds for each group. If weight is set for one
 *  group only, the cluster will default to zero weight on the unset group. For
 *  example if weight is set only on primary workers, the cluster will use
 *  primary workers only and no secondary workers.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *weight;

@end


/**
 *  The config settings for Compute Engine resources in an instance group, such
 *  as a master or worker group.
 */
@interface GTLRDataproc_InstanceGroupConfig : GTLRObject

/**
 *  Optional. The Compute Engine accelerator configuration for these instances.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_AcceleratorConfig *> *accelerators;

/** Optional. Disk option config settings. */
@property(nonatomic, strong, nullable) GTLRDataproc_DiskConfig *diskConfig;

/**
 *  Optional. The Compute Engine image resource used for cluster instances.The
 *  URI can represent an image or image family.Image examples:
 *  https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/[image-id]
 *  projects/[project_id]/global/images/[image-id] image-idImage family
 *  examples. Dataproc will use the most recent image from the family:
 *  https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/family/[custom-image-family-name]
 *  projects/[project_id]/global/images/family/[custom-image-family-name]If the
 *  URI is unspecified, it will be inferred from SoftwareConfig.image_version or
 *  the system default.
 */
@property(nonatomic, copy, nullable) NSString *imageUri;

/**
 *  Output only. The list of instance names. Dataproc derives the names from
 *  cluster_name, num_instances, and the instance group.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *instanceNames;

/** Output only. List of references to Compute Engine instances. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_InstanceReference *> *instanceReferences;

/**
 *  Output only. Specifies that this instance group contains preemptible
 *  instances.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *isPreemptible;

/**
 *  Optional. The Compute Engine machine type used for cluster instances.A full
 *  URL, partial URI, or short name are valid. Examples:
 *  https://www.googleapis.com/compute/v1/projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2
 *  projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2
 *  n1-standard-2Auto Zone Exception: If you are using the Dataproc Auto Zone
 *  Placement
 *  (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
 *  feature, you must use the short name of the machine type resource, for
 *  example, n1-standard-2.
 */
@property(nonatomic, copy, nullable) NSString *machineTypeUri;

/**
 *  Output only. The config for Compute Engine Instance Group Manager that
 *  manages this group. This is only used for preemptible instance groups.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_ManagedGroupConfig *managedGroupConfig;

/**
 *  Optional. Specifies the minimum cpu platform for the Instance Group. See
 *  Dataproc -> Minimum CPU Platform
 *  (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
 */
@property(nonatomic, copy, nullable) NSString *minCpuPlatform;

/**
 *  Optional. The number of VM instances in the instance group. For HA cluster
 *  master_config groups, must be set to 3. For standard cluster master_config
 *  groups, must be set to 1.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *numInstances;

/**
 *  Optional. Specifies the preemptibility of the instance group.The default
 *  value for master and worker groups is NON_PREEMPTIBLE. This default cannot
 *  be changed.The default value for secondary instances is PREEMPTIBLE.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_InstanceGroupConfig_Preemptibility_NonPreemptible
 *        Instances are non-preemptible.This option is allowed for all instance
 *        groups and is the only valid value for Master and Worker instance
 *        groups. (Value: "NON_PREEMPTIBLE")
 *    @arg @c kGTLRDataproc_InstanceGroupConfig_Preemptibility_PreemptibilityUnspecified
 *        Preemptibility is unspecified, the system will choose the appropriate
 *        setting for each instance group. (Value: "PREEMPTIBILITY_UNSPECIFIED")
 *    @arg @c kGTLRDataproc_InstanceGroupConfig_Preemptibility_Preemptible
 *        Instances are preemptible.This option is allowed only for secondary
 *        worker groups. (Value: "PREEMPTIBLE")
 */
@property(nonatomic, copy, nullable) NSString *preemptibility;

@end


/**
 *  A reference to a Compute Engine instance.
 */
@interface GTLRDataproc_InstanceReference : GTLRObject

/** The unique identifier of the Compute Engine instance. */
@property(nonatomic, copy, nullable) NSString *instanceId;

/** The user-friendly name of the Compute Engine instance. */
@property(nonatomic, copy, nullable) NSString *instanceName;

/** The public ECIES key used for sharing data with this instance. */
@property(nonatomic, copy, nullable) NSString *publicEciesKey;

/** The public RSA key used for sharing data with this instance. */
@property(nonatomic, copy, nullable) NSString *publicKey;

@end


/**
 *  A request to instantiate a workflow template.
 */
@interface GTLRDataproc_InstantiateWorkflowTemplateRequest : GTLRObject

/**
 *  Optional. Map from parameter names to values that should be used for those
 *  parameters. Values may not exceed 1000 characters.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_InstantiateWorkflowTemplateRequest_Parameters *parameters;

/**
 *  Optional. A tag that prevents multiple concurrent workflow instances with
 *  the same tag from running. This mitigates risk of concurrent instances
 *  started due to retries.It is recommended to always set this value to a UUID
 *  (https://en.wikipedia.org/wiki/Universally_unique_identifier).The tag must
 *  contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens
 *  (-). The maximum length is 40 characters.
 */
@property(nonatomic, copy, nullable) NSString *requestId;

/**
 *  Optional. The version of workflow template to instantiate. If specified, the
 *  workflow will be instantiated only if the current version of the workflow
 *  template has the supplied version.This option cannot be used to instantiate
 *  a previous version of workflow template.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *version;

@end


/**
 *  Optional. Map from parameter names to values that should be used for those
 *  parameters. Values may not exceed 1000 characters.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_InstantiateWorkflowTemplateRequest_Parameters : GTLRObject
@end


/**
 *  A Dataproc job resource.
 */
@interface GTLRDataproc_Job : GTLRObject

/**
 *  Output only. Indicates whether the job is completed. If the value is false,
 *  the job is still in progress. If true, the job is completed, and
 *  status.state field will indicate if it was successful, failed, or cancelled.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *done;

/**
 *  Output only. If present, the location of miscellaneous control files which
 *  may be used as part of job setup and handling. If not present, control files
 *  may be placed in the same location as driver_output_uri.
 */
@property(nonatomic, copy, nullable) NSString *driverControlFilesUri;

/**
 *  Output only. A URI pointing to the location of the stdout of the job's
 *  driver program.
 */
@property(nonatomic, copy, nullable) NSString *driverOutputResourceUri;

/** Optional. Job is a Hadoop job. */
@property(nonatomic, strong, nullable) GTLRDataproc_HadoopJob *hadoopJob;

/** Optional. Job is a Hive job. */
@property(nonatomic, strong, nullable) GTLRDataproc_HiveJob *hiveJob;

/**
 *  Output only. A UUID that uniquely identifies a job within the project over
 *  time. This is in contrast to a user-settable reference.job_id that may be
 *  reused over time.
 */
@property(nonatomic, copy, nullable) NSString *jobUuid;

/**
 *  Optional. The labels to associate with this job. Label keys must contain 1
 *  to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if
 *  present, must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be
 *  associated with a job.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_Job_Labels *labels;

/** Optional. Job is a Pig job. */
@property(nonatomic, strong, nullable) GTLRDataproc_PigJob *pigJob;

/**
 *  Required. Job information, including how, when, and where to run the job.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_JobPlacement *placement;

/** Optional. Job is a Presto job. */
@property(nonatomic, strong, nullable) GTLRDataproc_PrestoJob *prestoJob;

/** Optional. Job is a PySpark job. */
@property(nonatomic, strong, nullable) GTLRDataproc_PySparkJob *pysparkJob;

/**
 *  Optional. The fully qualified reference to the job, which can be used to
 *  obtain the equivalent REST path of the job resource. If this property is not
 *  specified when a job is created, the server generates a job_id.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_JobReference *reference;

/** Optional. Job scheduling configuration. */
@property(nonatomic, strong, nullable) GTLRDataproc_JobScheduling *scheduling;

/** Optional. Job is a Spark job. */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkJob *sparkJob;

/** Optional. Job is a SparkR job. */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkRJob *sparkRJob;

/** Optional. Job is a SparkSql job. */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkSqlJob *sparkSqlJob;

/**
 *  Output only. The job status. Additional application-specific status
 *  information may be contained in the type_job and yarn_applications fields.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_JobStatus *status;

/** Output only. The previous job status. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_JobStatus *> *statusHistory;

/**
 *  Output only. The collection of YARN applications spun up by this job.Beta
 *  Feature: This report is available for testing purposes only. It may be
 *  changed before final release.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_YarnApplication *> *yarnApplications;

@end


/**
 *  Optional. The labels to associate with this job. Label keys must contain 1
 *  to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if
 *  present, must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be
 *  associated with a job.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_Job_Labels : GTLRObject
@end


/**
 *  Job Operation metadata.
 */
@interface GTLRDataproc_JobMetadata : GTLRObject

/** Output only. The job id. */
@property(nonatomic, copy, nullable) NSString *jobId;

/** Output only. Operation type. */
@property(nonatomic, copy, nullable) NSString *operationType;

/** Output only. Job submission time. */
@property(nonatomic, strong, nullable) GTLRDateTime *startTime;

/** Output only. Most recent job status. */
@property(nonatomic, strong, nullable) GTLRDataproc_JobStatus *status;

@end


/**
 *  Dataproc job config.
 */
@interface GTLRDataproc_JobPlacement : GTLRObject

/**
 *  Optional. Cluster labels to identify a cluster where the job will be
 *  submitted.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_JobPlacement_ClusterLabels *clusterLabels;

/** Required. The name of the cluster where the job will be submitted. */
@property(nonatomic, copy, nullable) NSString *clusterName;

/**
 *  Output only. A cluster UUID generated by the Dataproc service when the job
 *  is submitted.
 */
@property(nonatomic, copy, nullable) NSString *clusterUuid;

@end


/**
 *  Optional. Cluster labels to identify a cluster where the job will be
 *  submitted.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_JobPlacement_ClusterLabels : GTLRObject
@end


/**
 *  Encapsulates the full scoping used to reference a job.
 */
@interface GTLRDataproc_JobReference : GTLRObject

/**
 *  Optional. The job ID, which must be unique within the project.The ID must
 *  contain only letters (a-z, A-Z), numbers (0-9), underscores (_), or hyphens
 *  (-). The maximum length is 100 characters.If not specified by the caller,
 *  the job ID will be provided by the server.
 */
@property(nonatomic, copy, nullable) NSString *jobId;

/**
 *  Optional. The ID of the Google Cloud Platform project that the job belongs
 *  to. If specified, must match the request project ID.
 */
@property(nonatomic, copy, nullable) NSString *projectId;

@end


/**
 *  Job scheduling options.
 */
@interface GTLRDataproc_JobScheduling : GTLRObject

/**
 *  Optional. Maximum number of times per hour a driver may be restarted as a
 *  result of driver exiting with non-zero code before job is reported failed.A
 *  job may be reported as thrashing if driver exits with non-zero code 4 times
 *  within 10 minute window.Maximum value is 10.Note: Currently, this
 *  restartable job option is not supported in Dataproc workflow template
 *  (https://cloud.google.com/dataproc/docs/concepts/workflows/using-workflows#adding_jobs_to_a_template)
 *  jobs.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *maxFailuresPerHour;

/**
 *  Optional. Maximum number of times in total a driver may be restarted as a
 *  result of driver exiting with non-zero code before job is reported failed.
 *  Maximum value is 240.Note: Currently, this restartable job option is not
 *  supported in Dataproc workflow template
 *  (https://cloud.google.com/dataproc/docs/concepts/workflows/using-workflows#adding_jobs_to_a_template)
 *  jobs.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *maxFailuresTotal;

@end


/**
 *  Dataproc job status.
 */
@interface GTLRDataproc_JobStatus : GTLRObject

/**
 *  Optional. Output only. Job state details, such as an error description if
 *  the state is ERROR.
 */
@property(nonatomic, copy, nullable) NSString *details;

/**
 *  Output only. A state message specifying the overall job state.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_JobStatus_State_AttemptFailure Job attempt has
 *        failed. The detail field contains failure details for this
 *        attempt.Applies to restartable jobs only. (Value: "ATTEMPT_FAILURE")
 *    @arg @c kGTLRDataproc_JobStatus_State_Cancelled The job cancellation was
 *        successful. (Value: "CANCELLED")
 *    @arg @c kGTLRDataproc_JobStatus_State_CancelPending A CancelJob request
 *        has been received, but is pending. (Value: "CANCEL_PENDING")
 *    @arg @c kGTLRDataproc_JobStatus_State_CancelStarted Transient in-flight
 *        resources have been canceled, and the request to cancel the running
 *        job has been issued to the cluster. (Value: "CANCEL_STARTED")
 *    @arg @c kGTLRDataproc_JobStatus_State_Done The job has completed
 *        successfully. (Value: "DONE")
 *    @arg @c kGTLRDataproc_JobStatus_State_Error The job has completed, but
 *        encountered an error. (Value: "ERROR")
 *    @arg @c kGTLRDataproc_JobStatus_State_Pending The job is pending; it has
 *        been submitted, but is not yet running. (Value: "PENDING")
 *    @arg @c kGTLRDataproc_JobStatus_State_Running The job is running on the
 *        cluster. (Value: "RUNNING")
 *    @arg @c kGTLRDataproc_JobStatus_State_SetupDone Job has been received by
 *        the service and completed initial setup; it will soon be submitted to
 *        the cluster. (Value: "SETUP_DONE")
 *    @arg @c kGTLRDataproc_JobStatus_State_StateUnspecified The job state is
 *        unknown. (Value: "STATE_UNSPECIFIED")
 */
@property(nonatomic, copy, nullable) NSString *state;

/** Output only. The time when this state was entered. */
@property(nonatomic, strong, nullable) GTLRDateTime *stateStartTime;

/**
 *  Output only. Additional state information, which includes status reported by
 *  the agent.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_JobStatus_Substate_Queued The Job has been received
 *        and is awaiting execution (it may be waiting for a condition to be
 *        met). See the "details" field for the reason for the delay.Applies to
 *        RUNNING state. (Value: "QUEUED")
 *    @arg @c kGTLRDataproc_JobStatus_Substate_StaleStatus The agent-reported
 *        status is out of date, which may be caused by a loss of communication
 *        between the agent and Dataproc. If the agent does not send a timely
 *        update, the job will fail.Applies to RUNNING state. (Value:
 *        "STALE_STATUS")
 *    @arg @c kGTLRDataproc_JobStatus_Substate_Submitted The Job is submitted to
 *        the agent.Applies to RUNNING state. (Value: "SUBMITTED")
 *    @arg @c kGTLRDataproc_JobStatus_Substate_Unspecified The job substate is
 *        unknown. (Value: "UNSPECIFIED")
 */
@property(nonatomic, copy, nullable) NSString *substate;

@end


/**
 *  Specifies Kerberos related configuration.
 */
@interface GTLRDataproc_KerberosConfig : GTLRObject

/**
 *  Optional. The admin server (IP or hostname) for the remote trusted realm in
 *  a cross realm trust relationship.
 */
@property(nonatomic, copy, nullable) NSString *crossRealmTrustAdminServer;

/**
 *  Optional. The KDC (IP or hostname) for the remote trusted realm in a cross
 *  realm trust relationship.
 */
@property(nonatomic, copy, nullable) NSString *crossRealmTrustKdc;

/**
 *  Optional. The remote realm the Dataproc on-cluster KDC will trust, should
 *  the user enable cross realm trust.
 */
@property(nonatomic, copy, nullable) NSString *crossRealmTrustRealm;

/**
 *  Optional. The Cloud Storage URI of a KMS encrypted file containing the
 *  shared password between the on-cluster Kerberos realm and the remote trusted
 *  realm, in a cross realm trust relationship.
 */
@property(nonatomic, copy, nullable) NSString *crossRealmTrustSharedPasswordUri;

/**
 *  Optional. Flag to indicate whether to Kerberize the cluster (default:
 *  false). Set this field to true to enable Kerberos on a cluster.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *enableKerberos;

/**
 *  Optional. The Cloud Storage URI of a KMS encrypted file containing the
 *  master key of the KDC database.
 */
@property(nonatomic, copy, nullable) NSString *kdcDbKeyUri;

/**
 *  Optional. The Cloud Storage URI of a KMS encrypted file containing the
 *  password to the user provided key. For the self-signed certificate, this
 *  password is generated by Dataproc.
 */
@property(nonatomic, copy, nullable) NSString *keyPasswordUri;

/**
 *  Optional. The Cloud Storage URI of a KMS encrypted file containing the
 *  password to the user provided keystore. For the self-signed certificate,
 *  this password is generated by Dataproc.
 */
@property(nonatomic, copy, nullable) NSString *keystorePasswordUri;

/**
 *  Optional. The Cloud Storage URI of the keystore file used for SSL
 *  encryption. If not provided, Dataproc will provide a self-signed
 *  certificate.
 */
@property(nonatomic, copy, nullable) NSString *keystoreUri;

/**
 *  Optional. The uri of the KMS key used to encrypt various sensitive files.
 */
@property(nonatomic, copy, nullable) NSString *kmsKeyUri;

/**
 *  Optional. The name of the on-cluster Kerberos realm. If not specified, the
 *  uppercased domain of hostnames will be the realm.
 */
@property(nonatomic, copy, nullable) NSString *realm;

/**
 *  Optional. The Cloud Storage URI of a KMS encrypted file containing the root
 *  principal password.
 */
@property(nonatomic, copy, nullable) NSString *rootPrincipalPasswordUri;

/**
 *  Optional. The lifetime of the ticket granting ticket, in hours. If not
 *  specified, or user specifies 0, then default value 10 will be used.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *tgtLifetimeHours;

/**
 *  Optional. The Cloud Storage URI of a KMS encrypted file containing the
 *  password to the user provided truststore. For the self-signed certificate,
 *  this password is generated by Dataproc.
 */
@property(nonatomic, copy, nullable) NSString *truststorePasswordUri;

/**
 *  Optional. The Cloud Storage URI of the truststore file used for SSL
 *  encryption. If not provided, Dataproc will provide a self-signed
 *  certificate.
 */
@property(nonatomic, copy, nullable) NSString *truststoreUri;

@end


/**
 *  The configuration for running the Dataproc cluster on Kubernetes.
 */
@interface GTLRDataproc_KubernetesClusterConfig : GTLRObject

/** Required. The configuration for running the Dataproc cluster on GKE. */
@property(nonatomic, strong, nullable) GTLRDataproc_GkeClusterConfig *gkeClusterConfig;

/**
 *  Optional. A namespace within the Kubernetes cluster to deploy into. If this
 *  namespace does not exist, it is created. If it exists, Dataproc verifies
 *  that another Dataproc VirtualCluster is not installed into it. If not
 *  specified, the name of the Dataproc Cluster is used.
 */
@property(nonatomic, copy, nullable) NSString *kubernetesNamespace;

/**
 *  Optional. The software configuration for this Dataproc cluster running on
 *  Kubernetes.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_KubernetesSoftwareConfig *kubernetesSoftwareConfig;

@end


/**
 *  The software configuration for this Dataproc cluster running on Kubernetes.
 */
@interface GTLRDataproc_KubernetesSoftwareConfig : GTLRObject

/**
 *  The components that should be installed in this Dataproc cluster. The key
 *  must be a string from the KubernetesComponent enumeration. The value is the
 *  version of the software to be installed. At least one entry must be
 *  specified.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_KubernetesSoftwareConfig_ComponentVersion *componentVersion;

/**
 *  The properties to set on daemon config files.Property keys are specified in
 *  prefix:property format, for example spark:spark.kubernetes.container.image.
 *  The following are supported prefixes and their mappings: spark:
 *  spark-defaults.confFor more information, see Cluster properties
 *  (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
 */
@property(nonatomic, strong, nullable) GTLRDataproc_KubernetesSoftwareConfig_Properties *properties;

@end


/**
 *  The components that should be installed in this Dataproc cluster. The key
 *  must be a string from the KubernetesComponent enumeration. The value is the
 *  version of the software to be installed. At least one entry must be
 *  specified.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_KubernetesSoftwareConfig_ComponentVersion : GTLRObject
@end


/**
 *  The properties to set on daemon config files.Property keys are specified in
 *  prefix:property format, for example spark:spark.kubernetes.container.image.
 *  The following are supported prefixes and their mappings: spark:
 *  spark-defaults.confFor more information, see Cluster properties
 *  (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_KubernetesSoftwareConfig_Properties : GTLRObject
@end


/**
 *  Specifies the cluster auto-delete schedule configuration.
 */
@interface GTLRDataproc_LifecycleConfig : GTLRObject

/**
 *  Optional. The time when cluster will be auto-deleted (see JSON
 *  representation of Timestamp
 *  (https://developers.google.com/protocol-buffers/docs/proto3#json)).
 */
@property(nonatomic, strong, nullable) GTLRDateTime *autoDeleteTime;

/**
 *  Optional. The lifetime duration of cluster. The cluster will be auto-deleted
 *  at the end of this period. Minimum value is 10 minutes; maximum value is 14
 *  days (see JSON representation of Duration
 *  (https://developers.google.com/protocol-buffers/docs/proto3#json)).
 */
@property(nonatomic, strong, nullable) GTLRDuration *autoDeleteTtl;

/**
 *  Optional. The duration to keep the cluster alive while idling (when no jobs
 *  are running). Passing this threshold will cause the cluster to be deleted.
 *  Minimum value is 5 minutes; maximum value is 14 days (see JSON
 *  representation of Duration
 *  (https://developers.google.com/protocol-buffers/docs/proto3#json)).
 */
@property(nonatomic, strong, nullable) GTLRDuration *idleDeleteTtl;

/**
 *  Output only. The time when cluster became idle (most recent job finished)
 *  and became eligible for deletion due to idleness (see JSON representation of
 *  Timestamp
 *  (https://developers.google.com/protocol-buffers/docs/proto3#json)).
 */
@property(nonatomic, strong, nullable) GTLRDateTime *idleStartTime;

@end


/**
 *  A response to a request to list autoscaling policies in a project.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "policies" property. If returned as the result of a query, it
 *        should support automatic pagination (when @c shouldFetchNextPages is
 *        enabled).
 */
@interface GTLRDataproc_ListAutoscalingPoliciesResponse : GTLRCollectionObject

/**
 *  Output only. This token is included in the response if there are more
 *  results to fetch.
 */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

/**
 *  Output only. Autoscaling policies list.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_AutoscalingPolicy *> *policies;

@end


/**
 *  A list of batch workloads.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "batches" property. If returned as the result of a query, it
 *        should support automatic pagination (when @c shouldFetchNextPages is
 *        enabled).
 */
@interface GTLRDataproc_ListBatchesResponse : GTLRCollectionObject

/**
 *  The batches from the specified collection.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_Batch *> *batches;

/**
 *  A token, which can be sent as page_token to retrieve the next page. If this
 *  field is omitted, there are no subsequent pages.
 */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  The list of all clusters in a project.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "clusters" property. If returned as the result of a query, it
 *        should support automatic pagination (when @c shouldFetchNextPages is
 *        enabled).
 */
@interface GTLRDataproc_ListClustersResponse : GTLRCollectionObject

/**
 *  Output only. The clusters in the project.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_Cluster *> *clusters;

/**
 *  Output only. This token is included in the response if there are more
 *  results to fetch. To fetch additional results, provide this value as the
 *  page_token in a subsequent ListClustersRequest.
 */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  A list of jobs in a project.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "jobs" property. If returned as the result of a query, it should
 *        support automatic pagination (when @c shouldFetchNextPages is
 *        enabled).
 */
@interface GTLRDataproc_ListJobsResponse : GTLRCollectionObject

/**
 *  Output only. Jobs list.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_Job *> *jobs;

/**
 *  Optional. This token is included in the response if there are more results
 *  to fetch. To fetch additional results, provide this value as the page_token
 *  in a subsequent ListJobsRequest.
 */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  The response message for Operations.ListOperations.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "operations" property. If returned as the result of a query, it
 *        should support automatic pagination (when @c shouldFetchNextPages is
 *        enabled).
 */
@interface GTLRDataproc_ListOperationsResponse : GTLRCollectionObject

/** The standard List next-page token. */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

/**
 *  A list of operations that matches the specified filter in the request.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_Operation *> *operations;

@end


/**
 *  A response to a request to list workflow templates in a project.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "templates" property. If returned as the result of a query, it
 *        should support automatic pagination (when @c shouldFetchNextPages is
 *        enabled).
 */
@interface GTLRDataproc_ListWorkflowTemplatesResponse : GTLRCollectionObject

/**
 *  Output only. This token is included in the response if there are more
 *  results to fetch. To fetch additional results, provide this value as the
 *  page_token in a subsequent ListWorkflowTemplatesRequest.
 */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

/**
 *  Output only. WorkflowTemplates list.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_WorkflowTemplate *> *templates;

@end


/**
 *  The runtime logging config of the job.
 */
@interface GTLRDataproc_LoggingConfig : GTLRObject

/**
 *  The per-package log levels for the driver. This may include "root" package
 *  name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO',
 *  'org.apache = DEBUG'
 */
@property(nonatomic, strong, nullable) GTLRDataproc_LoggingConfig_DriverLogLevels *driverLogLevels;

@end


/**
 *  The per-package log levels for the driver. This may include "root" package
 *  name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO',
 *  'org.apache = DEBUG'
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_LoggingConfig_DriverLogLevels : GTLRObject
@end


/**
 *  Cluster that is managed by the workflow.
 */
@interface GTLRDataproc_ManagedCluster : GTLRObject

/**
 *  Required. The cluster name prefix. A unique cluster name will be formed by
 *  appending a random suffix.The name must contain only lower-case letters
 *  (a-z), numbers (0-9), and hyphens (-). Must begin with a letter. Cannot
 *  begin or end with hyphen. Must consist of between 2 and 35 characters.
 */
@property(nonatomic, copy, nullable) NSString *clusterName;

/** Required. The cluster configuration. */
@property(nonatomic, strong, nullable) GTLRDataproc_ClusterConfig *config;

/**
 *  Optional. The labels to associate with this cluster.Label keys must be
 *  between 1 and 63 characters long, and must conform to the following PCRE
 *  regular expression: \\p{Ll}\\p{Lo}{0,62}Label values must be between 1 and
 *  63 characters long, and must conform to the following PCRE regular
 *  expression: \\p{Ll}\\p{Lo}\\p{N}_-{0,63}No more than 32 labels can be
 *  associated with a given cluster.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_ManagedCluster_Labels *labels;

@end


/**
 *  Optional. The labels to associate with this cluster.Label keys must be
 *  between 1 and 63 characters long, and must conform to the following PCRE
 *  regular expression: \\p{Ll}\\p{Lo}{0,62}Label values must be between 1 and
 *  63 characters long, and must conform to the following PCRE regular
 *  expression: \\p{Ll}\\p{Lo}\\p{N}_-{0,63}No more than 32 labels can be
 *  associated with a given cluster.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_ManagedCluster_Labels : GTLRObject
@end


/**
 *  Specifies the resources used to actively manage an instance group.
 */
@interface GTLRDataproc_ManagedGroupConfig : GTLRObject

/** Output only. The name of the Instance Group Manager for this group. */
@property(nonatomic, copy, nullable) NSString *instanceGroupManagerName;

/**
 *  Output only. The name of the Instance Template used for the Managed Instance
 *  Group.
 */
@property(nonatomic, copy, nullable) NSString *instanceTemplateName;

@end


/**
 *  Specifies a Metastore configuration.
 */
@interface GTLRDataproc_MetastoreConfig : GTLRObject

/**
 *  Required. Resource name of an existing Dataproc Metastore service.Example:
 *  projects/[project_id]/locations/[dataproc_region]/services/[service-name]
 */
@property(nonatomic, copy, nullable) NSString *dataprocMetastoreService;

@end


/**
 *  A Dataproc OSS metric.
 */
@interface GTLRDataproc_Metric : GTLRObject

/**
 *  Optional. Specify one or more available OSS metrics
 *  (https://cloud.google.com/dataproc/docs/guides/monitoring#available_oss_metrics)
 *  to collect for the metric course (for the SPARK metric source, any Spark
 *  metric (https://spark.apache.org/docs/latest/monitoring.html#metrics) can be
 *  specified).Provide metrics in the following format: METRIC_SOURCE:
 *  INSTANCE:GROUP:METRIC Use camelcase as appropriate.Examples:
 *  yarn:ResourceManager:QueueMetrics:AppsCompleted
 *  spark:driver:DAGScheduler:job.allJobs
 *  sparkHistoryServer:JVM:Memory:NonHeapMemoryUsage.committed
 *  hiveserver2:JVM:Memory:NonHeapMemoryUsage.used Notes: Only the specified
 *  overridden metrics will be collected for the metric source. For example, if
 *  one or more spark:executive metrics are listed as metric overrides, other
 *  SPARK metrics will not be collected. The collection of the default metrics
 *  for other OSS metric sources is unaffected. For example, if both SPARK andd
 *  YARN metric sources are enabled, and overrides are provided for Spark
 *  metrics only, all default YARN metrics will be collected.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *metricOverrides;

/**
 *  Required. Default metrics are collected unless metricOverrides are specified
 *  for the metric source (see Available OSS metrics
 *  (https://cloud.google.com/dataproc/docs/guides/monitoring#available_oss_metrics)
 *  for more information).
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_Metric_MetricSource_Hdfs HDFS metric source. (Value:
 *        "HDFS")
 *    @arg @c kGTLRDataproc_Metric_MetricSource_Hiveserver2 Hiveserver2 metric
 *        source. (Value: "HIVESERVER2")
 *    @arg @c kGTLRDataproc_Metric_MetricSource_MetricSourceUnspecified Required
 *        unspecified metric source. (Value: "METRIC_SOURCE_UNSPECIFIED")
 *    @arg @c kGTLRDataproc_Metric_MetricSource_MonitoringAgentDefaults Default
 *        monitoring agent metrics. If this source is enabled, Dataproc enables
 *        the monitoring agent in Compute Engine, and collects default
 *        monitoring agent metrics, which are published with an
 *        agent.googleapis.com prefix. (Value: "MONITORING_AGENT_DEFAULTS")
 *    @arg @c kGTLRDataproc_Metric_MetricSource_Spark Spark metric source.
 *        (Value: "SPARK")
 *    @arg @c kGTLRDataproc_Metric_MetricSource_SparkHistoryServer Spark History
 *        Server metric source. (Value: "SPARK_HISTORY_SERVER")
 *    @arg @c kGTLRDataproc_Metric_MetricSource_Yarn YARN metric source. (Value:
 *        "YARN")
 */
@property(nonatomic, copy, nullable) NSString *metricSource;

@end


/**
 *  Dataproc metric config.
 */
@interface GTLRDataproc_MetricConfig : GTLRObject

/** Required. Metrics sources to enable. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_Metric *> *metrics;

@end


/**
 *  Deprecated. Used only for the deprecated beta. A full, namespace-isolated
 *  deployment target for an existing GKE cluster.
 */
@interface GTLRDataproc_NamespacedGkeDeploymentTarget : GTLRObject

/** Optional. A namespace within the GKE cluster to deploy into. */
@property(nonatomic, copy, nullable) NSString *clusterNamespace;

/**
 *  Optional. The target GKE cluster to deploy to. Format:
 *  'projects/{project}/locations/{location}/clusters/{cluster_id}'
 */
@property(nonatomic, copy, nullable) NSString *targetGkeCluster;

@end


/**
 *  Node Group Affinity for clusters using sole-tenant node groups.
 */
@interface GTLRDataproc_NodeGroupAffinity : GTLRObject

/**
 *  Required. The URI of a sole-tenant node group resource
 *  (https://cloud.google.com/compute/docs/reference/rest/v1/nodeGroups) that
 *  the cluster will be created on.A full URL, partial URI, or node group name
 *  are valid. Examples:
 *  https://www.googleapis.com/compute/v1/projects/[project_id]/zones/us-central1-a/nodeGroups/node-group-1
 *  projects/[project_id]/zones/us-central1-a/nodeGroups/node-group-1
 *  node-group-1
 */
@property(nonatomic, copy, nullable) NSString *nodeGroupUri;

@end


/**
 *  Specifies an executable to run on a fully configured node and a timeout
 *  period for executable completion.
 */
@interface GTLRDataproc_NodeInitializationAction : GTLRObject

/** Required. Cloud Storage URI of executable file. */
@property(nonatomic, copy, nullable) NSString *executableFile;

/**
 *  Optional. Amount of time executable has to complete. Default is 10 minutes
 *  (see JSON representation of Duration
 *  (https://developers.google.com/protocol-buffers/docs/proto3#json)).Cluster
 *  creation fails with an explanatory error message (the name of the executable
 *  that caused the error and the exceeded timeout period) if the executable is
 *  not completed at end of the timeout period.
 */
@property(nonatomic, strong, nullable) GTLRDuration *executionTimeout;

@end


/**
 *  indicating a list of workers of same type
 */
@interface GTLRDataproc_NodePool : GTLRObject

/**
 *  Required. A unique id of the node pool. Primary and Secondary workers can be
 *  specified using special reserved ids PRIMARY_WORKER_POOL and
 *  SECONDARY_WORKER_POOL respectively. Aux node pools can be referenced using
 *  corresponding pool id.
 *
 *  identifier property maps to 'id' in JSON (to avoid Objective C's 'id').
 */
@property(nonatomic, copy, nullable) NSString *identifier;

/**
 *  Name of instances to be repaired. These instances must belong to specified
 *  node pool.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *instanceNames;

/**
 *  Required. Repair action to take on specified resources of the node pool.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_NodePool_RepairAction_Delete delete the specified
 *        list of nodes. (Value: "DELETE")
 *    @arg @c kGTLRDataproc_NodePool_RepairAction_RepairActionUnspecified No
 *        action will be taken by default. (Value: "REPAIR_ACTION_UNSPECIFIED")
 */
@property(nonatomic, copy, nullable) NSString *repairAction;

@end


/**
 *  This resource represents a long-running operation that is the result of a
 *  network API call.
 */
@interface GTLRDataproc_Operation : GTLRObject

/**
 *  If the value is false, it means the operation is still in progress. If true,
 *  the operation is completed, and either error or response is available.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *done;

/** The error result of the operation in case of failure or cancellation. */
@property(nonatomic, strong, nullable) GTLRDataproc_Status *error;

/**
 *  Service-specific metadata associated with the operation. It typically
 *  contains progress information and common metadata such as create time. Some
 *  services might not provide such metadata. Any method that returns a
 *  long-running operation should document the metadata type, if any.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_Operation_Metadata *metadata;

/**
 *  The server-assigned name, which is only unique within the same service that
 *  originally returns it. If you use the default HTTP mapping, the name should
 *  be a resource name ending with operations/{unique_id}.
 */
@property(nonatomic, copy, nullable) NSString *name;

/**
 *  The normal response of the operation in case of success. If the original
 *  method returns no data on success, such as Delete, the response is
 *  google.protobuf.Empty. If the original method is standard Get/Create/Update,
 *  the response should be the resource. For other methods, the response should
 *  have the type XxxResponse, where Xxx is the original method name. For
 *  example, if the original method name is TakeSnapshot(), the inferred
 *  response type is TakeSnapshotResponse.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_Operation_Response *response;

@end


/**
 *  Service-specific metadata associated with the operation. It typically
 *  contains progress information and common metadata such as create time. Some
 *  services might not provide such metadata. Any method that returns a
 *  long-running operation should document the metadata type, if any.
 *
 *  @note This class is documented as having more properties of any valid JSON
 *        type. Use @c -additionalJSONKeys and @c -additionalPropertyForName: to
 *        get the list of properties and then fetch them; or @c
 *        -additionalProperties to fetch them all at once.
 */
@interface GTLRDataproc_Operation_Metadata : GTLRObject
@end


/**
 *  The normal response of the operation in case of success. If the original
 *  method returns no data on success, such as Delete, the response is
 *  google.protobuf.Empty. If the original method is standard Get/Create/Update,
 *  the response should be the resource. For other methods, the response should
 *  have the type XxxResponse, where Xxx is the original method name. For
 *  example, if the original method name is TakeSnapshot(), the inferred
 *  response type is TakeSnapshotResponse.
 *
 *  @note This class is documented as having more properties of any valid JSON
 *        type. Use @c -additionalJSONKeys and @c -additionalPropertyForName: to
 *        get the list of properties and then fetch them; or @c
 *        -additionalProperties to fetch them all at once.
 */
@interface GTLRDataproc_Operation_Response : GTLRObject
@end


/**
 *  A job executed by the workflow.
 */
@interface GTLRDataproc_OrderedJob : GTLRObject

/** Optional. Job is a Hadoop job. */
@property(nonatomic, strong, nullable) GTLRDataproc_HadoopJob *hadoopJob;

/** Optional. Job is a Hive job. */
@property(nonatomic, strong, nullable) GTLRDataproc_HiveJob *hiveJob;

/**
 *  Optional. The labels to associate with this job.Label keys must be between 1
 *  and 63 characters long, and must conform to the following regular
 *  expression: \\p{Ll}\\p{Lo}{0,62}Label values must be between 1 and 63
 *  characters long, and must conform to the following regular expression:
 *  \\p{Ll}\\p{Lo}\\p{N}_-{0,63}No more than 32 labels can be associated with a
 *  given job.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_OrderedJob_Labels *labels;

/** Optional. Job is a Pig job. */
@property(nonatomic, strong, nullable) GTLRDataproc_PigJob *pigJob;

/**
 *  Optional. The optional list of prerequisite job step_ids. If not specified,
 *  the job will start at the beginning of workflow.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *prerequisiteStepIds;

/** Optional. Job is a Presto job. */
@property(nonatomic, strong, nullable) GTLRDataproc_PrestoJob *prestoJob;

/** Optional. Job is a PySpark job. */
@property(nonatomic, strong, nullable) GTLRDataproc_PySparkJob *pysparkJob;

/** Optional. Job scheduling configuration. */
@property(nonatomic, strong, nullable) GTLRDataproc_JobScheduling *scheduling;

/** Optional. Job is a Spark job. */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkJob *sparkJob;

/** Optional. Job is a SparkR job. */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkRJob *sparkRJob;

/** Optional. Job is a SparkSql job. */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkSqlJob *sparkSqlJob;

/**
 *  Required. The step id. The id must be unique among all jobs within the
 *  template.The step id is used as prefix for job id, as job
 *  goog-dataproc-workflow-step-id label, and in prerequisiteStepIds field from
 *  other steps.The id must contain only letters (a-z, A-Z), numbers (0-9),
 *  underscores (_), and hyphens (-). Cannot begin or end with underscore or
 *  hyphen. Must consist of between 3 and 50 characters.
 */
@property(nonatomic, copy, nullable) NSString *stepId;

@end


/**
 *  Optional. The labels to associate with this job.Label keys must be between 1
 *  and 63 characters long, and must conform to the following regular
 *  expression: \\p{Ll}\\p{Lo}{0,62}Label values must be between 1 and 63
 *  characters long, and must conform to the following regular expression:
 *  \\p{Ll}\\p{Lo}\\p{N}_-{0,63}No more than 32 labels can be associated with a
 *  given job.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_OrderedJob_Labels : GTLRObject
@end


/**
 *  Configuration for parameter validation.
 */
@interface GTLRDataproc_ParameterValidation : GTLRObject

/** Validation based on regular expressions. */
@property(nonatomic, strong, nullable) GTLRDataproc_RegexValidation *regex;

/** Validation based on a list of allowed values. */
@property(nonatomic, strong, nullable) GTLRDataproc_ValueValidation *values;

@end


/**
 *  Auxiliary services configuration for a workload.
 */
@interface GTLRDataproc_PeripheralsConfig : GTLRObject

/**
 *  Optional. Resource name of an existing Dataproc Metastore service.Example:
 *  projects/[project_id]/locations/[region]/services/[service_id]
 */
@property(nonatomic, copy, nullable) NSString *metastoreService;

/** Optional. The Spark History Server configuration for the workload. */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkHistoryServerConfig *sparkHistoryServerConfig;

@end


/**
 *  A Dataproc job for running Apache Pig (https://pig.apache.org/) queries on
 *  YARN.
 */
@interface GTLRDataproc_PigJob : GTLRObject

/**
 *  Optional. Whether to continue executing queries if a query fails. The
 *  default value is false. Setting to true can be useful when executing
 *  independent parallel queries.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *continueOnFailure;

/**
 *  Optional. HCFS URIs of jar files to add to the CLASSPATH of the Pig Client
 *  and Hadoop MapReduce (MR) tasks. Can contain Pig UDFs.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *jarFileUris;

/** Optional. The runtime log config for job execution. */
@property(nonatomic, strong, nullable) GTLRDataproc_LoggingConfig *loggingConfig;

/**
 *  Optional. A mapping of property names to values, used to configure Pig.
 *  Properties that conflict with values set by the Dataproc API may be
 *  overwritten. Can include properties set in /etc/hadoop/conf/ *-site.xml,
 *  /etc/pig/conf/pig.properties, and classes in user code.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_PigJob_Properties *properties;

/** The HCFS URI of the script that contains the Pig queries. */
@property(nonatomic, copy, nullable) NSString *queryFileUri;

/** A list of queries. */
@property(nonatomic, strong, nullable) GTLRDataproc_QueryList *queryList;

/**
 *  Optional. Mapping of query variable names to values (equivalent to the Pig
 *  command: name=[value]).
 */
@property(nonatomic, strong, nullable) GTLRDataproc_PigJob_ScriptVariables *scriptVariables;

@end


/**
 *  Optional. A mapping of property names to values, used to configure Pig.
 *  Properties that conflict with values set by the Dataproc API may be
 *  overwritten. Can include properties set in /etc/hadoop/conf/ *-site.xml,
 *  /etc/pig/conf/pig.properties, and classes in user code.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_PigJob_Properties : GTLRObject
@end


/**
 *  Optional. Mapping of query variable names to values (equivalent to the Pig
 *  command: name=[value]).
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_PigJob_ScriptVariables : GTLRObject
@end


/**
 *  An Identity and Access Management (IAM) policy, which specifies access
 *  controls for Google Cloud resources.A Policy is a collection of bindings. A
 *  binding binds one or more members, or principals, to a single role.
 *  Principals can be user accounts, service accounts, Google groups, and
 *  domains (such as G Suite). A role is a named list of permissions; each role
 *  can be an IAM predefined role or a user-created custom role.For some types
 *  of Google Cloud resources, a binding can also specify a condition, which is
 *  a logical expression that allows access to a resource only if the expression
 *  evaluates to true. A condition can add constraints based on attributes of
 *  the request, the resource, or both. To learn which resources support
 *  conditions in their IAM policies, see the IAM documentation
 *  (https://cloud.google.com/iam/help/conditions/resource-policies).JSON
 *  example: { "bindings": [ { "role":
 *  "roles/resourcemanager.organizationAdmin", "members": [
 *  "user:mike\@example.com", "group:admins\@example.com", "domain:google.com",
 *  "serviceAccount:my-project-id\@appspot.gserviceaccount.com" ] }, { "role":
 *  "roles/resourcemanager.organizationViewer", "members": [
 *  "user:eve\@example.com" ], "condition": { "title": "expirable access",
 *  "description": "Does not grant access after Sep 2020", "expression":
 *  "request.time < timestamp('2020-10-01T00:00:00.000Z')", } } ], "etag":
 *  "BwWWja0YfJA=", "version": 3 } YAML example: bindings: - members: -
 *  user:mike\@example.com - group:admins\@example.com - domain:google.com -
 *  serviceAccount:my-project-id\@appspot.gserviceaccount.com role:
 *  roles/resourcemanager.organizationAdmin - members: - user:eve\@example.com
 *  role: roles/resourcemanager.organizationViewer condition: title: expirable
 *  access description: Does not grant access after Sep 2020 expression:
 *  request.time < timestamp('2020-10-01T00:00:00.000Z') etag: BwWWja0YfJA=
 *  version: 3 For a description of IAM and its features, see the IAM
 *  documentation (https://cloud.google.com/iam/docs/).
 */
@interface GTLRDataproc_Policy : GTLRObject

/**
 *  Associates a list of members, or principals, with a role. Optionally, may
 *  specify a condition that determines how and when the bindings are applied.
 *  Each of the bindings must contain at least one principal.The bindings in a
 *  Policy can refer to up to 1,500 principals; up to 250 of these principals
 *  can be Google groups. Each occurrence of a principal counts towards these
 *  limits. For example, if the bindings grant 50 different roles to
 *  user:alice\@example.com, and not to any other principal, then you can add
 *  another 1,450 principals to the bindings in the Policy.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_Binding *> *bindings;

/**
 *  etag is used for optimistic concurrency control as a way to help prevent
 *  simultaneous updates of a policy from overwriting each other. It is strongly
 *  suggested that systems make use of the etag in the read-modify-write cycle
 *  to perform policy updates in order to avoid race conditions: An etag is
 *  returned in the response to getIamPolicy, and systems are expected to put
 *  that etag in the request to setIamPolicy to ensure that their change will be
 *  applied to the same version of the policy.Important: If you use IAM
 *  Conditions, you must include the etag field whenever you call setIamPolicy.
 *  If you omit this field, then IAM allows you to overwrite a version 3 policy
 *  with a version 1 policy, and all of the conditions in the version 3 policy
 *  are lost.
 *
 *  Contains encoded binary data; GTLRBase64 can encode/decode (probably
 *  web-safe format).
 */
@property(nonatomic, copy, nullable) NSString *ETag;

/**
 *  Specifies the format of the policy.Valid values are 0, 1, and 3. Requests
 *  that specify an invalid value are rejected.Any operation that affects
 *  conditional role bindings must specify version 3. This requirement applies
 *  to the following operations: Getting a policy that includes a conditional
 *  role binding Adding a conditional role binding to a policy Changing a
 *  conditional role binding in a policy Removing any role binding, with or
 *  without a condition, from a policy that includes conditionsImportant: If you
 *  use IAM Conditions, you must include the etag field whenever you call
 *  setIamPolicy. If you omit this field, then IAM allows you to overwrite a
 *  version 3 policy with a version 1 policy, and all of the conditions in the
 *  version 3 policy are lost.If a policy does not include any conditions,
 *  operations on that policy may specify any valid version or leave the field
 *  unset.To learn which resources support conditions in their IAM policies, see
 *  the IAM documentation
 *  (https://cloud.google.com/iam/help/conditions/resource-policies).
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *version;

@end


/**
 *  A Dataproc job for running Presto (https://prestosql.io/) queries.
 *  IMPORTANT: The Dataproc Presto Optional Component
 *  (https://cloud.google.com/dataproc/docs/concepts/components/presto) must be
 *  enabled when the cluster is created to submit a Presto job to the cluster.
 */
@interface GTLRDataproc_PrestoJob : GTLRObject

/** Optional. Presto client tags to attach to this query */
@property(nonatomic, strong, nullable) NSArray<NSString *> *clientTags;

/**
 *  Optional. Whether to continue executing queries if a query fails. The
 *  default value is false. Setting to true can be useful when executing
 *  independent parallel queries.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *continueOnFailure;

/** Optional. The runtime log config for job execution. */
@property(nonatomic, strong, nullable) GTLRDataproc_LoggingConfig *loggingConfig;

/**
 *  Optional. The format in which query output will be displayed. See the Presto
 *  documentation for supported output formats
 */
@property(nonatomic, copy, nullable) NSString *outputFormat;

/**
 *  Optional. A mapping of property names to values. Used to set Presto session
 *  properties (https://prestodb.io/docs/current/sql/set-session.html)
 *  Equivalent to using the --session flag in the Presto CLI
 */
@property(nonatomic, strong, nullable) GTLRDataproc_PrestoJob_Properties *properties;

/** The HCFS URI of the script that contains SQL queries. */
@property(nonatomic, copy, nullable) NSString *queryFileUri;

/** A list of queries. */
@property(nonatomic, strong, nullable) GTLRDataproc_QueryList *queryList;

@end


/**
 *  Optional. A mapping of property names to values. Used to set Presto session
 *  properties (https://prestodb.io/docs/current/sql/set-session.html)
 *  Equivalent to using the --session flag in the Presto CLI
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_PrestoJob_Properties : GTLRObject
@end


/**
 *  A configuration for running an Apache PySpark
 *  (https://spark.apache.org/docs/latest/api/python/getting_started/quickstart.html)
 *  batch workload.
 */
@interface GTLRDataproc_PySparkBatch : GTLRObject

/**
 *  Optional. HCFS URIs of archives to be extracted into the working directory
 *  of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *archiveUris;

/**
 *  Optional. The arguments to pass to the driver. Do not include arguments that
 *  can be set as batch properties, such as --conf, since a collision can occur
 *  that causes an incorrect batch submission.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *args;

/**
 *  Optional. HCFS URIs of files to be placed in the working directory of each
 *  executor.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *fileUris;

/**
 *  Optional. HCFS URIs of jar files to add to the classpath of the Spark driver
 *  and tasks.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *jarFileUris;

/**
 *  Required. The HCFS URI of the main Python file to use as the Spark driver.
 *  Must be a .py file.
 */
@property(nonatomic, copy, nullable) NSString *mainPythonFileUri;

/**
 *  Optional. HCFS file URIs of Python files to pass to the PySpark framework.
 *  Supported file types: .py, .egg, and .zip.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *pythonFileUris;

@end


/**
 *  A Dataproc job for running Apache PySpark
 *  (https://spark.apache.org/docs/0.9.0/python-programming-guide.html)
 *  applications on YARN.
 */
@interface GTLRDataproc_PySparkJob : GTLRObject

/**
 *  Optional. HCFS URIs of archives to be extracted into the working directory
 *  of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *archiveUris;

/**
 *  Optional. The arguments to pass to the driver. Do not include arguments,
 *  such as --conf, that can be set as job properties, since a collision may
 *  occur that causes an incorrect job submission.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *args;

/**
 *  Optional. HCFS URIs of files to be placed in the working directory of each
 *  executor. Useful for naively parallel tasks.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *fileUris;

/**
 *  Optional. HCFS URIs of jar files to add to the CLASSPATHs of the Python
 *  driver and tasks.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *jarFileUris;

/** Optional. The runtime log config for job execution. */
@property(nonatomic, strong, nullable) GTLRDataproc_LoggingConfig *loggingConfig;

/**
 *  Required. The HCFS URI of the main Python file to use as the driver. Must be
 *  a .py file.
 */
@property(nonatomic, copy, nullable) NSString *mainPythonFileUri;

/**
 *  Optional. A mapping of property names to values, used to configure PySpark.
 *  Properties that conflict with values set by the Dataproc API may be
 *  overwritten. Can include properties set in
 *  /etc/spark/conf/spark-defaults.conf and classes in user code.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_PySparkJob_Properties *properties;

/**
 *  Optional. HCFS file URIs of Python files to pass to the PySpark framework.
 *  Supported file types: .py, .egg, and .zip.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *pythonFileUris;

@end


/**
 *  Optional. A mapping of property names to values, used to configure PySpark.
 *  Properties that conflict with values set by the Dataproc API may be
 *  overwritten. Can include properties set in
 *  /etc/spark/conf/spark-defaults.conf and classes in user code.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_PySparkJob_Properties : GTLRObject
@end


/**
 *  A list of queries to run on a cluster.
 */
@interface GTLRDataproc_QueryList : GTLRObject

/**
 *  Required. The queries to execute. You do not need to end a query expression
 *  with a semicolon. Multiple queries can be specified in one string by
 *  separating each with a semicolon. Here is an example of a Dataproc API
 *  snippet that uses a QueryList to specify a HiveJob: "hiveJob": {
 *  "queryList": { "queries": [ "query1", "query2", "query3;query4", ] } }
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *queries;

@end


/**
 *  Validation based on regular expressions.
 */
@interface GTLRDataproc_RegexValidation : GTLRObject

/**
 *  Required. RE2 regular expressions used to validate the parameter's value.
 *  The value must match the regex in its entirety (substring matches are not
 *  sufficient).
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *regexes;

@end


/**
 *  A request to repair a cluster.
 */
@interface GTLRDataproc_RepairClusterRequest : GTLRObject

/**
 *  Optional. Specifying the cluster_uuid means the RPC will fail (with error
 *  NOT_FOUND) if a cluster with the specified UUID does not exist.
 */
@property(nonatomic, copy, nullable) NSString *clusterUuid;

/**
 *  Optional. Timeout for graceful YARN decomissioning. Graceful decommissioning
 *  facilitates the removal of cluster nodes without interrupting jobs in
 *  progress. The timeout specifies the amount of time to wait for jobs finish
 *  before forcefully removing nodes. The default timeout is 0 for forceful
 *  decommissioning, and the maximum timeout period is 1 day. (see JSON
 *  MappingDuration
 *  (https://developers.google.com/protocol-buffers/docs/proto3#json)).graceful_decommission_timeout
 *  is supported in Dataproc image versions 1.2+.
 */
@property(nonatomic, strong, nullable) GTLRDuration *gracefulDecommissionTimeout;

/**
 *  Optional. Node pools and corresponding repair action to be taken. All node
 *  pools should be unique in this request. i.e. Multiple entries for the same
 *  node pool id are not allowed.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_NodePool *> *nodePools;

/**
 *  Optional. operation id of the parent operation sending the repair request
 */
@property(nonatomic, copy, nullable) NSString *parentOperationId;

/**
 *  Optional. A unique ID used to identify the request. If the server receives
 *  two RepairClusterRequests with the same ID, the second request is ignored,
 *  and the first google.longrunning.Operation created and stored in the backend
 *  is returned.Recommendation: Set this value to a UUID
 *  (https://en.wikipedia.org/wiki/Universally_unique_identifier).The ID must
 *  contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens
 *  (-). The maximum length is 40 characters.
 */
@property(nonatomic, copy, nullable) NSString *requestId;

@end


/**
 *  Reservation Affinity for consuming Zonal reservation.
 */
@interface GTLRDataproc_ReservationAffinity : GTLRObject

/**
 *  Optional. Type of reservation to consume
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_ReservationAffinity_ConsumeReservationType_AnyReservation
 *        Consume any reservation available. (Value: "ANY_RESERVATION")
 *    @arg @c kGTLRDataproc_ReservationAffinity_ConsumeReservationType_NoReservation
 *        Do not consume from any allocated capacity. (Value: "NO_RESERVATION")
 *    @arg @c kGTLRDataproc_ReservationAffinity_ConsumeReservationType_SpecificReservation
 *        Must consume from a specific reservation. Must specify key value
 *        fields for specifying the reservations. (Value:
 *        "SPECIFIC_RESERVATION")
 *    @arg @c kGTLRDataproc_ReservationAffinity_ConsumeReservationType_TypeUnspecified
 *        Value "TYPE_UNSPECIFIED"
 */
@property(nonatomic, copy, nullable) NSString *consumeReservationType;

/** Optional. Corresponds to the label key of reservation resource. */
@property(nonatomic, copy, nullable) NSString *key;

/** Optional. Corresponds to the label values of reservation resource. */
@property(nonatomic, strong, nullable) NSArray<NSString *> *values;

@end


/**
 *  Runtime configuration for a workload.
 */
@interface GTLRDataproc_RuntimeConfig : GTLRObject

/**
 *  Optional. Optional custom container image for the job runtime environment.
 *  If not specified, a default container image will be used.
 */
@property(nonatomic, copy, nullable) NSString *containerImage;

/**
 *  Optional. A mapping of property names to values, which are used to configure
 *  workload execution.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_RuntimeConfig_Properties *properties;

/** Optional. Version of the batch runtime. */
@property(nonatomic, copy, nullable) NSString *version;

@end


/**
 *  Optional. A mapping of property names to values, which are used to configure
 *  workload execution.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_RuntimeConfig_Properties : GTLRObject
@end


/**
 *  Runtime information about workload execution.
 */
@interface GTLRDataproc_RuntimeInfo : GTLRObject

/** Output only. A URI pointing to the location of the diagnostics tarball. */
@property(nonatomic, copy, nullable) NSString *diagnosticOutputUri;

/**
 *  Output only. Map of remote access endpoints (such as web interfaces and
 *  APIs) to their URIs.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_RuntimeInfo_Endpoints *endpoints;

/**
 *  Output only. A URI pointing to the location of the stdout and stderr of the
 *  workload.
 */
@property(nonatomic, copy, nullable) NSString *outputUri;

@end


/**
 *  Output only. Map of remote access endpoints (such as web interfaces and
 *  APIs) to their URIs.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_RuntimeInfo_Endpoints : GTLRObject
@end


/**
 *  Security related configuration, including encryption, Kerberos, etc.
 */
@interface GTLRDataproc_SecurityConfig : GTLRObject

/**
 *  Optional. Identity related configuration, including service account based
 *  secure multi-tenancy user mappings.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_IdentityConfig *identityConfig;

/** Optional. Kerberos related configuration. */
@property(nonatomic, strong, nullable) GTLRDataproc_KerberosConfig *kerberosConfig;

@end


/**
 *  Metadata describing the Session operation.
 */
@interface GTLRDataproc_SessionOperationMetadata : GTLRObject

/** The time when the operation was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Short description of the operation.
 *
 *  Remapped to 'descriptionProperty' to avoid NSObject's 'description'.
 */
@property(nonatomic, copy, nullable) NSString *descriptionProperty;

/** The time when the operation was finished. */
@property(nonatomic, strong, nullable) GTLRDateTime *doneTime;

/** Labels associated with the operation. */
@property(nonatomic, strong, nullable) GTLRDataproc_SessionOperationMetadata_Labels *labels;

/**
 *  The operation type.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_SessionOperationMetadata_OperationType_Create Create
 *        Session operation type. (Value: "CREATE")
 *    @arg @c kGTLRDataproc_SessionOperationMetadata_OperationType_Delete Delete
 *        Session operation type. (Value: "DELETE")
 *    @arg @c kGTLRDataproc_SessionOperationMetadata_OperationType_SessionOperationTypeUnspecified
 *        Session operation type is unknown. (Value:
 *        "SESSION_OPERATION_TYPE_UNSPECIFIED")
 *    @arg @c kGTLRDataproc_SessionOperationMetadata_OperationType_Terminate
 *        Terminate Session operation type. (Value: "TERMINATE")
 */
@property(nonatomic, copy, nullable) NSString *operationType;

/** Name of the session for the operation. */
@property(nonatomic, copy, nullable) NSString *session;

/** Session UUID for the operation. */
@property(nonatomic, copy, nullable) NSString *sessionUuid;

/** Warnings encountered during operation execution. */
@property(nonatomic, strong, nullable) NSArray<NSString *> *warnings;

@end


/**
 *  Labels associated with the operation.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_SessionOperationMetadata_Labels : GTLRObject
@end


/**
 *  Request message for SetIamPolicy method.
 */
@interface GTLRDataproc_SetIamPolicyRequest : GTLRObject

/**
 *  REQUIRED: The complete policy to be applied to the resource. The size of the
 *  policy is limited to a few 10s of KB. An empty policy is a valid policy but
 *  certain Google Cloud services (such as Projects) might reject them.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_Policy *policy;

@end


/**
 *  Shielded Instance Config for clusters using Compute Engine Shielded VMs
 *  (https://cloud.google.com/security/shielded-cloud/shielded-vm).
 */
@interface GTLRDataproc_ShieldedInstanceConfig : GTLRObject

/**
 *  Optional. Defines whether instances have integrity monitoring enabled.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *enableIntegrityMonitoring;

/**
 *  Optional. Defines whether instances have Secure Boot enabled.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *enableSecureBoot;

/**
 *  Optional. Defines whether instances have the vTPM enabled.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *enableVtpm;

@end


/**
 *  Specifies the selection and config of software inside the cluster.
 */
@interface GTLRDataproc_SoftwareConfig : GTLRObject

/**
 *  Optional. The version of software inside the cluster. It must be one of the
 *  supported Dataproc Versions
 *  (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#supported_dataproc_versions),
 *  such as "1.2" (including a subminor version, such as "1.2.29"), or the
 *  "preview" version
 *  (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#other_versions).
 *  If unspecified, it defaults to the latest Debian version.
 */
@property(nonatomic, copy, nullable) NSString *imageVersion;

/** Optional. The set of components to activate on the cluster. */
@property(nonatomic, strong, nullable) NSArray<NSString *> *optionalComponents;

/**
 *  Optional. The properties to set on daemon config files.Property keys are
 *  specified in prefix:property format, for example core:hadoop.tmp.dir. The
 *  following are supported prefixes and their mappings: capacity-scheduler:
 *  capacity-scheduler.xml core: core-site.xml distcp: distcp-default.xml hdfs:
 *  hdfs-site.xml hive: hive-site.xml mapred: mapred-site.xml pig:
 *  pig.properties spark: spark-defaults.conf yarn: yarn-site.xmlFor more
 *  information, see Cluster properties
 *  (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
 */
@property(nonatomic, strong, nullable) GTLRDataproc_SoftwareConfig_Properties *properties;

@end


/**
 *  Optional. The properties to set on daemon config files.Property keys are
 *  specified in prefix:property format, for example core:hadoop.tmp.dir. The
 *  following are supported prefixes and their mappings: capacity-scheduler:
 *  capacity-scheduler.xml core: core-site.xml distcp: distcp-default.xml hdfs:
 *  hdfs-site.xml hive: hive-site.xml mapred: mapred-site.xml pig:
 *  pig.properties spark: spark-defaults.conf yarn: yarn-site.xmlFor more
 *  information, see Cluster properties
 *  (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_SoftwareConfig_Properties : GTLRObject
@end


/**
 *  A configuration for running an Apache Spark (https://spark.apache.org/)
 *  batch workload.
 */
@interface GTLRDataproc_SparkBatch : GTLRObject

/**
 *  Optional. HCFS URIs of archives to be extracted into the working directory
 *  of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *archiveUris;

/**
 *  Optional. The arguments to pass to the driver. Do not include arguments that
 *  can be set as batch properties, such as --conf, since a collision can occur
 *  that causes an incorrect batch submission.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *args;

/**
 *  Optional. HCFS URIs of files to be placed in the working directory of each
 *  executor.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *fileUris;

/**
 *  Optional. HCFS URIs of jar files to add to the classpath of the Spark driver
 *  and tasks.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *jarFileUris;

/**
 *  Optional. The name of the driver main class. The jar file that contains the
 *  class must be in the classpath or specified in jar_file_uris.
 */
@property(nonatomic, copy, nullable) NSString *mainClass;

/** Optional. The HCFS URI of the jar file that contains the main class. */
@property(nonatomic, copy, nullable) NSString *mainJarFileUri;

@end


/**
 *  Spark History Server configuration for the workload.
 */
@interface GTLRDataproc_SparkHistoryServerConfig : GTLRObject

/**
 *  Optional. Resource name of an existing Dataproc Cluster to act as a Spark
 *  History Server for the workload.Example:
 *  projects/[project_id]/regions/[region]/clusters/[cluster_name]
 */
@property(nonatomic, copy, nullable) NSString *dataprocCluster;

@end


/**
 *  A Dataproc job for running Apache Spark (https://spark.apache.org/)
 *  applications on YARN.
 */
@interface GTLRDataproc_SparkJob : GTLRObject

/**
 *  Optional. HCFS URIs of archives to be extracted into the working directory
 *  of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *archiveUris;

/**
 *  Optional. The arguments to pass to the driver. Do not include arguments,
 *  such as --conf, that can be set as job properties, since a collision may
 *  occur that causes an incorrect job submission.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *args;

/**
 *  Optional. HCFS URIs of files to be placed in the working directory of each
 *  executor. Useful for naively parallel tasks.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *fileUris;

/**
 *  Optional. HCFS URIs of jar files to add to the CLASSPATHs of the Spark
 *  driver and tasks.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *jarFileUris;

/** Optional. The runtime log config for job execution. */
@property(nonatomic, strong, nullable) GTLRDataproc_LoggingConfig *loggingConfig;

/**
 *  The name of the driver's main class. The jar file that contains the class
 *  must be in the default CLASSPATH or specified in jar_file_uris.
 */
@property(nonatomic, copy, nullable) NSString *mainClass;

/** The HCFS URI of the jar file that contains the main class. */
@property(nonatomic, copy, nullable) NSString *mainJarFileUri;

/**
 *  Optional. A mapping of property names to values, used to configure Spark.
 *  Properties that conflict with values set by the Dataproc API may be
 *  overwritten. Can include properties set in
 *  /etc/spark/conf/spark-defaults.conf and classes in user code.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkJob_Properties *properties;

@end


/**
 *  Optional. A mapping of property names to values, used to configure Spark.
 *  Properties that conflict with values set by the Dataproc API may be
 *  overwritten. Can include properties set in
 *  /etc/spark/conf/spark-defaults.conf and classes in user code.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_SparkJob_Properties : GTLRObject
@end


/**
 *  A configuration for running an Apache SparkR
 *  (https://spark.apache.org/docs/latest/sparkr.html) batch workload.
 */
@interface GTLRDataproc_SparkRBatch : GTLRObject

/**
 *  Optional. HCFS URIs of archives to be extracted into the working directory
 *  of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *archiveUris;

/**
 *  Optional. The arguments to pass to the Spark driver. Do not include
 *  arguments that can be set as batch properties, such as --conf, since a
 *  collision can occur that causes an incorrect batch submission.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *args;

/**
 *  Optional. HCFS URIs of files to be placed in the working directory of each
 *  executor.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *fileUris;

/**
 *  Required. The HCFS URI of the main R file to use as the driver. Must be a .R
 *  or .r file.
 */
@property(nonatomic, copy, nullable) NSString *mainRFileUri;

@end


/**
 *  A Dataproc job for running Apache SparkR
 *  (https://spark.apache.org/docs/latest/sparkr.html) applications on YARN.
 */
@interface GTLRDataproc_SparkRJob : GTLRObject

/**
 *  Optional. HCFS URIs of archives to be extracted into the working directory
 *  of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *archiveUris;

/**
 *  Optional. The arguments to pass to the driver. Do not include arguments,
 *  such as --conf, that can be set as job properties, since a collision may
 *  occur that causes an incorrect job submission.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *args;

/**
 *  Optional. HCFS URIs of files to be placed in the working directory of each
 *  executor. Useful for naively parallel tasks.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *fileUris;

/** Optional. The runtime log config for job execution. */
@property(nonatomic, strong, nullable) GTLRDataproc_LoggingConfig *loggingConfig;

/**
 *  Required. The HCFS URI of the main R file to use as the driver. Must be a .R
 *  file.
 */
@property(nonatomic, copy, nullable) NSString *mainRFileUri;

/**
 *  Optional. A mapping of property names to values, used to configure SparkR.
 *  Properties that conflict with values set by the Dataproc API may be
 *  overwritten. Can include properties set in
 *  /etc/spark/conf/spark-defaults.conf and classes in user code.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkRJob_Properties *properties;

@end


/**
 *  Optional. A mapping of property names to values, used to configure SparkR.
 *  Properties that conflict with values set by the Dataproc API may be
 *  overwritten. Can include properties set in
 *  /etc/spark/conf/spark-defaults.conf and classes in user code.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_SparkRJob_Properties : GTLRObject
@end


/**
 *  A configuration for running Apache Spark SQL (https://spark.apache.org/sql/)
 *  queries as a batch workload.
 */
@interface GTLRDataproc_SparkSqlBatch : GTLRObject

/** Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH. */
@property(nonatomic, strong, nullable) NSArray<NSString *> *jarFileUris;

/**
 *  Required. The HCFS URI of the script that contains Spark SQL queries to
 *  execute.
 */
@property(nonatomic, copy, nullable) NSString *queryFileUri;

/**
 *  Optional. Mapping of query variable names to values (equivalent to the Spark
 *  SQL command: SET name="value";).
 */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkSqlBatch_QueryVariables *queryVariables;

@end


/**
 *  Optional. Mapping of query variable names to values (equivalent to the Spark
 *  SQL command: SET name="value";).
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_SparkSqlBatch_QueryVariables : GTLRObject
@end


/**
 *  A Dataproc job for running Apache Spark SQL (https://spark.apache.org/sql/)
 *  queries.
 */
@interface GTLRDataproc_SparkSqlJob : GTLRObject

/** Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH. */
@property(nonatomic, strong, nullable) NSArray<NSString *> *jarFileUris;

/** Optional. The runtime log config for job execution. */
@property(nonatomic, strong, nullable) GTLRDataproc_LoggingConfig *loggingConfig;

/**
 *  Optional. A mapping of property names to values, used to configure Spark
 *  SQL's SparkConf. Properties that conflict with values set by the Dataproc
 *  API may be overwritten.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkSqlJob_Properties *properties;

/** The HCFS URI of the script that contains SQL queries. */
@property(nonatomic, copy, nullable) NSString *queryFileUri;

/** A list of queries. */
@property(nonatomic, strong, nullable) GTLRDataproc_QueryList *queryList;

/**
 *  Optional. Mapping of query variable names to values (equivalent to the Spark
 *  SQL command: SET name="value";).
 */
@property(nonatomic, strong, nullable) GTLRDataproc_SparkSqlJob_ScriptVariables *scriptVariables;

@end


/**
 *  Optional. A mapping of property names to values, used to configure Spark
 *  SQL's SparkConf. Properties that conflict with values set by the Dataproc
 *  API may be overwritten.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_SparkSqlJob_Properties : GTLRObject
@end


/**
 *  Optional. Mapping of query variable names to values (equivalent to the Spark
 *  SQL command: SET name="value";).
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_SparkSqlJob_ScriptVariables : GTLRObject
@end


/**
 *  Basic autoscaling configurations for Spark Standalone.
 */
@interface GTLRDataproc_SparkStandaloneAutoscalingConfig : GTLRObject

/**
 *  Required. Timeout for Spark graceful decommissioning of spark workers.
 *  Specifies the duration to wait for spark worker to complete spark
 *  decomissioning tasks before forcefully removing workers. Only applicable to
 *  downscaling operations.Bounds: 0s, 1d.
 */
@property(nonatomic, strong, nullable) GTLRDuration *gracefulDecommissionTimeout;

/**
 *  Required. Fraction of required executors to remove from Spark Serverless
 *  clusters. A scale-down factor of 1.0 will result in scaling down so that
 *  there are no more executors for the Spark Job.(more aggressive scaling). A
 *  scale-down factor closer to 0 will result in a smaller magnitude of scaling
 *  donw (less aggressive scaling).Bounds: 0.0, 1.0.
 *
 *  Uses NSNumber of doubleValue.
 */
@property(nonatomic, strong, nullable) NSNumber *scaleDownFactor;

/**
 *  Optional. Minimum scale-down threshold as a fraction of total cluster size
 *  before scaling occurs. For example, in a 20-worker cluster, a threshold of
 *  0.1 means the autoscaler must recommend at least a 2 worker scale-down for
 *  the cluster to scale. A threshold of 0 means the autoscaler will scale down
 *  on any recommended change.Bounds: 0.0, 1.0. Default: 0.0.
 *
 *  Uses NSNumber of doubleValue.
 */
@property(nonatomic, strong, nullable) NSNumber *scaleDownMinWorkerFraction;

/**
 *  Required. Fraction of required workers to add to Spark Standalone clusters.
 *  A scale-up factor of 1.0 will result in scaling up so that there are no more
 *  required workers for the Spark Job (more aggressive scaling). A scale-up
 *  factor closer to 0 will result in a smaller magnitude of scaling up (less
 *  aggressive scaling).Bounds: 0.0, 1.0.
 *
 *  Uses NSNumber of doubleValue.
 */
@property(nonatomic, strong, nullable) NSNumber *scaleUpFactor;

/**
 *  Optional. Minimum scale-up threshold as a fraction of total cluster size
 *  before scaling occurs. For example, in a 20-worker cluster, a threshold of
 *  0.1 means the autoscaler must recommend at least a 2-worker scale-up for the
 *  cluster to scale. A threshold of 0 means the autoscaler will scale up on any
 *  recommended change.Bounds: 0.0, 1.0. Default: 0.0.
 *
 *  Uses NSNumber of doubleValue.
 */
@property(nonatomic, strong, nullable) NSNumber *scaleUpMinWorkerFraction;

@end


/**
 *  A request to start a cluster.
 */
@interface GTLRDataproc_StartClusterRequest : GTLRObject

/**
 *  Optional. Specifying the cluster_uuid means the RPC will fail (with error
 *  NOT_FOUND) if a cluster with the specified UUID does not exist.
 */
@property(nonatomic, copy, nullable) NSString *clusterUuid;

/**
 *  Optional. A unique ID used to identify the request. If the server receives
 *  two StartClusterRequest
 *  (https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#google.cloud.dataproc.v1.StartClusterRequest)s
 *  with the same id, then the second request will be ignored and the first
 *  google.longrunning.Operation created and stored in the backend is
 *  returned.Recommendation: Set this value to a UUID
 *  (https://en.wikipedia.org/wiki/Universally_unique_identifier).The ID must
 *  contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens
 *  (-). The maximum length is 40 characters.
 */
@property(nonatomic, copy, nullable) NSString *requestId;

@end


/**
 *  Historical state information.
 */
@interface GTLRDataproc_StateHistory : GTLRObject

/**
 *  Output only. The state of the batch at this point in history.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_StateHistory_State_Cancelled The batch cancellation
 *        was successful. (Value: "CANCELLED")
 *    @arg @c kGTLRDataproc_StateHistory_State_Cancelling The batch is
 *        cancelling. (Value: "CANCELLING")
 *    @arg @c kGTLRDataproc_StateHistory_State_Failed The batch is no longer
 *        running due to an error. (Value: "FAILED")
 *    @arg @c kGTLRDataproc_StateHistory_State_Pending The batch is created
 *        before running. (Value: "PENDING")
 *    @arg @c kGTLRDataproc_StateHistory_State_Running The batch is running.
 *        (Value: "RUNNING")
 *    @arg @c kGTLRDataproc_StateHistory_State_StateUnspecified The batch state
 *        is unknown. (Value: "STATE_UNSPECIFIED")
 *    @arg @c kGTLRDataproc_StateHistory_State_Succeeded The batch completed
 *        successfully. (Value: "SUCCEEDED")
 */
@property(nonatomic, copy, nullable) NSString *state;

/** Output only. Details about the state at this point in history. */
@property(nonatomic, copy, nullable) NSString *stateMessage;

/** Output only. The time when the batch entered the historical state. */
@property(nonatomic, strong, nullable) GTLRDateTime *stateStartTime;

@end


/**
 *  The Status type defines a logical error model that is suitable for different
 *  programming environments, including REST APIs and RPC APIs. It is used by
 *  gRPC (https://github.com/grpc). Each Status message contains three pieces of
 *  data: error code, error message, and error details.You can find out more
 *  about this error model and how to work with it in the API Design Guide
 *  (https://cloud.google.com/apis/design/errors).
 */
@interface GTLRDataproc_Status : GTLRObject

/**
 *  The status code, which should be an enum value of google.rpc.Code.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *code;

/**
 *  A list of messages that carry the error details. There is a common set of
 *  message types for APIs to use.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_Status_Details_Item *> *details;

/**
 *  A developer-facing error message, which should be in English. Any
 *  user-facing error message should be localized and sent in the
 *  google.rpc.Status.details field, or localized by the client.
 */
@property(nonatomic, copy, nullable) NSString *message;

@end


/**
 *  GTLRDataproc_Status_Details_Item
 *
 *  @note This class is documented as having more properties of any valid JSON
 *        type. Use @c -additionalJSONKeys and @c -additionalPropertyForName: to
 *        get the list of properties and then fetch them; or @c
 *        -additionalProperties to fetch them all at once.
 */
@interface GTLRDataproc_Status_Details_Item : GTLRObject
@end


/**
 *  A request to stop a cluster.
 */
@interface GTLRDataproc_StopClusterRequest : GTLRObject

/**
 *  Optional. Specifying the cluster_uuid means the RPC will fail (with error
 *  NOT_FOUND) if a cluster with the specified UUID does not exist.
 */
@property(nonatomic, copy, nullable) NSString *clusterUuid;

/**
 *  Optional. A unique ID used to identify the request. If the server receives
 *  two StopClusterRequest
 *  (https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#google.cloud.dataproc.v1.StopClusterRequest)s
 *  with the same id, then the second request will be ignored and the first
 *  google.longrunning.Operation created and stored in the backend is
 *  returned.Recommendation: Set this value to a UUID
 *  (https://en.wikipedia.org/wiki/Universally_unique_identifier).The ID must
 *  contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens
 *  (-). The maximum length is 40 characters.
 */
@property(nonatomic, copy, nullable) NSString *requestId;

@end


/**
 *  A request to submit a job.
 */
@interface GTLRDataproc_SubmitJobRequest : GTLRObject

/** Required. The job resource. */
@property(nonatomic, strong, nullable) GTLRDataproc_Job *job;

/**
 *  Optional. A unique id used to identify the request. If the server receives
 *  two SubmitJobRequest
 *  (https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#google.cloud.dataproc.v1.SubmitJobRequest)s
 *  with the same id, then the second request will be ignored and the first Job
 *  created and stored in the backend is returned.It is recommended to always
 *  set this value to a UUID
 *  (https://en.wikipedia.org/wiki/Universally_unique_identifier).The id must
 *  contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens
 *  (-). The maximum length is 40 characters.
 */
@property(nonatomic, copy, nullable) NSString *requestId;

@end


/**
 *  A configurable parameter that replaces one or more fields in the template.
 *  Parameterizable fields: - Labels - File uris - Job properties - Job
 *  arguments - Script variables - Main class (in HadoopJob and SparkJob) - Zone
 *  (in ClusterSelector)
 */
@interface GTLRDataproc_TemplateParameter : GTLRObject

/**
 *  Optional. Brief description of the parameter. Must not exceed 1024
 *  characters.
 *
 *  Remapped to 'descriptionProperty' to avoid NSObject's 'description'.
 */
@property(nonatomic, copy, nullable) NSString *descriptionProperty;

/**
 *  Required. Paths to all fields that the parameter replaces. A field is
 *  allowed to appear in at most one parameter's list of field paths.A field
 *  path is similar in syntax to a google.protobuf.FieldMask. For example, a
 *  field path that references the zone field of a workflow template's cluster
 *  selector would be specified as placement.clusterSelector.zone.Also, field
 *  paths can reference fields using the following syntax: Values in maps can be
 *  referenced by key: labels'key' placement.clusterSelector.clusterLabels'key'
 *  placement.managedCluster.labels'key'
 *  placement.clusterSelector.clusterLabels'key' jobs'step-id'.labels'key' Jobs
 *  in the jobs list can be referenced by step-id:
 *  jobs'step-id'.hadoopJob.mainJarFileUri jobs'step-id'.hiveJob.queryFileUri
 *  jobs'step-id'.pySparkJob.mainPythonFileUri
 *  jobs'step-id'.hadoopJob.jarFileUris0 jobs'step-id'.hadoopJob.archiveUris0
 *  jobs'step-id'.hadoopJob.fileUris0 jobs'step-id'.pySparkJob.pythonFileUris0
 *  Items in repeated fields can be referenced by a zero-based index:
 *  jobs'step-id'.sparkJob.args0 Other examples:
 *  jobs'step-id'.hadoopJob.properties'key' jobs'step-id'.hadoopJob.args0
 *  jobs'step-id'.hiveJob.scriptVariables'key'
 *  jobs'step-id'.hadoopJob.mainJarFileUri placement.clusterSelector.zoneIt may
 *  not be possible to parameterize maps and repeated fields in their entirety
 *  since only individual map values and individual items in repeated fields can
 *  be referenced. For example, the following field paths are invalid:
 *  placement.clusterSelector.clusterLabels jobs'step-id'.sparkJob.args
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *fields;

/**
 *  Required. Parameter name. The parameter name is used as the key, and paired
 *  with the parameter value, which are passed to the template when the template
 *  is instantiated. The name must contain only capital letters (A-Z), numbers
 *  (0-9), and underscores (_), and must not start with a number. The maximum
 *  length is 40 characters.
 */
@property(nonatomic, copy, nullable) NSString *name;

/** Optional. Validation rules to be applied to this parameter's value. */
@property(nonatomic, strong, nullable) GTLRDataproc_ParameterValidation *validation;

@end


/**
 *  Request message for TestIamPermissions method.
 */
@interface GTLRDataproc_TestIamPermissionsRequest : GTLRObject

/**
 *  The set of permissions to check for the resource. Permissions with wildcards
 *  (such as * or storage.*) are not allowed. For more information see IAM
 *  Overview (https://cloud.google.com/iam/docs/overview#permissions).
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *permissions;

@end


/**
 *  Response message for TestIamPermissions method.
 */
@interface GTLRDataproc_TestIamPermissionsResponse : GTLRObject

/**
 *  A subset of TestPermissionsRequest.permissions that the caller is allowed.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *permissions;

@end


/**
 *  Validation based on a list of allowed values.
 */
@interface GTLRDataproc_ValueValidation : GTLRObject

/** Required. List of allowed values for the parameter. */
@property(nonatomic, strong, nullable) NSArray<NSString *> *values;

@end


/**
 *  The Dataproc cluster config for a cluster that does not directly control the
 *  underlying compute resources, such as a Dataproc-on-GKE cluster
 *  (https://cloud.google.com/dataproc/docs/guides/dpgke/dataproc-gke).
 */
@interface GTLRDataproc_VirtualClusterConfig : GTLRObject

/** Optional. Configuration of auxiliary services used by this cluster. */
@property(nonatomic, strong, nullable) GTLRDataproc_AuxiliaryServicesConfig *auxiliaryServicesConfig;

/**
 *  Required. The configuration for running the Dataproc cluster on Kubernetes.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_KubernetesClusterConfig *kubernetesClusterConfig;

/**
 *  Optional. A Cloud Storage bucket used to stage job dependencies, config
 *  files, and job driver console output. If you do not specify a staging
 *  bucket, Cloud Dataproc will determine a Cloud Storage location (US, ASIA, or
 *  EU) for your cluster's staging bucket according to the Compute Engine zone
 *  where your cluster is deployed, and then create and manage this
 *  project-level, per-location bucket (see Dataproc staging and temp buckets
 *  (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)).
 *  This field requires a Cloud Storage bucket name, not a gs://... URI to a
 *  Cloud Storage bucket.
 */
@property(nonatomic, copy, nullable) NSString *stagingBucket;

@end


/**
 *  The workflow graph.
 */
@interface GTLRDataproc_WorkflowGraph : GTLRObject

/** Output only. The workflow nodes. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_WorkflowNode *> *nodes;

@end


/**
 *  A Dataproc workflow template resource.
 */
@interface GTLRDataproc_WorkflowMetadata : GTLRObject

/** Output only. The name of the target cluster. */
@property(nonatomic, copy, nullable) NSString *clusterName;

/** Output only. The UUID of target cluster. */
@property(nonatomic, copy, nullable) NSString *clusterUuid;

/** Output only. The create cluster operation metadata. */
@property(nonatomic, strong, nullable) GTLRDataproc_ClusterOperation *createCluster;

/**
 *  Output only. DAG end time, only set for workflows with dag_timeout when DAG
 *  ends.
 */
@property(nonatomic, strong, nullable) GTLRDateTime *dagEndTime;

/**
 *  Output only. DAG start time, only set for workflows with dag_timeout when
 *  DAG begins.
 */
@property(nonatomic, strong, nullable) GTLRDateTime *dagStartTime;

/**
 *  Output only. The timeout duration for the DAG of jobs, expressed in seconds
 *  (see JSON representation of duration
 *  (https://developers.google.com/protocol-buffers/docs/proto3#json)).
 */
@property(nonatomic, strong, nullable) GTLRDuration *dagTimeout;

/** Output only. The delete cluster operation metadata. */
@property(nonatomic, strong, nullable) GTLRDataproc_ClusterOperation *deleteCluster;

/** Output only. Workflow end time. */
@property(nonatomic, strong, nullable) GTLRDateTime *endTime;

/** Output only. The workflow graph. */
@property(nonatomic, strong, nullable) GTLRDataproc_WorkflowGraph *graph;

/** Map from parameter names to values that were used for those parameters. */
@property(nonatomic, strong, nullable) GTLRDataproc_WorkflowMetadata_Parameters *parameters;

/** Output only. Workflow start time. */
@property(nonatomic, strong, nullable) GTLRDateTime *startTime;

/**
 *  Output only. The workflow state.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_WorkflowMetadata_State_Done The operation is done;
 *        either cancelled or completed. (Value: "DONE")
 *    @arg @c kGTLRDataproc_WorkflowMetadata_State_Pending The operation has
 *        been created. (Value: "PENDING")
 *    @arg @c kGTLRDataproc_WorkflowMetadata_State_Running The operation is
 *        running. (Value: "RUNNING")
 *    @arg @c kGTLRDataproc_WorkflowMetadata_State_Unknown Unused. (Value:
 *        "UNKNOWN")
 */
@property(nonatomic, copy, nullable) NSString *state;

/**
 *  Output only. The resource name of the workflow template as described in
 *  https://cloud.google.com/apis/design/resource_names. For
 *  projects.regions.workflowTemplates, the resource name of the template has
 *  the following format:
 *  projects/{project_id}/regions/{region}/workflowTemplates/{template_id} For
 *  projects.locations.workflowTemplates, the resource name of the template has
 *  the following format:
 *  projects/{project_id}/locations/{location}/workflowTemplates/{template_id}
 *
 *  Remapped to 'templateProperty' to avoid language reserved word 'template'.
 */
@property(nonatomic, copy, nullable) NSString *templateProperty;

/**
 *  Output only. The version of template at the time of workflow instantiation.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *version;

@end


/**
 *  Map from parameter names to values that were used for those parameters.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_WorkflowMetadata_Parameters : GTLRObject
@end


/**
 *  The workflow node.
 */
@interface GTLRDataproc_WorkflowNode : GTLRObject

/** Output only. The error detail. */
@property(nonatomic, copy, nullable) NSString *error;

/** Output only. The job id; populated after the node enters RUNNING state. */
@property(nonatomic, copy, nullable) NSString *jobId;

/** Output only. Node's prerequisite nodes. */
@property(nonatomic, strong, nullable) NSArray<NSString *> *prerequisiteStepIds;

/**
 *  Output only. The node state.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_WorkflowNode_State_Blocked The node is awaiting
 *        prerequisite node to finish. (Value: "BLOCKED")
 *    @arg @c kGTLRDataproc_WorkflowNode_State_Completed The node completed
 *        successfully. (Value: "COMPLETED")
 *    @arg @c kGTLRDataproc_WorkflowNode_State_Failed The node failed. A node
 *        can be marked FAILED because its ancestor or peer failed. (Value:
 *        "FAILED")
 *    @arg @c kGTLRDataproc_WorkflowNode_State_NodeStateUnspecified State is
 *        unspecified. (Value: "NODE_STATE_UNSPECIFIED")
 *    @arg @c kGTLRDataproc_WorkflowNode_State_Runnable The node is runnable but
 *        not running. (Value: "RUNNABLE")
 *    @arg @c kGTLRDataproc_WorkflowNode_State_Running The node is running.
 *        (Value: "RUNNING")
 */
@property(nonatomic, copy, nullable) NSString *state;

/** Output only. The name of the node. */
@property(nonatomic, copy, nullable) NSString *stepId;

@end


/**
 *  A Dataproc workflow template resource.
 */
@interface GTLRDataproc_WorkflowTemplate : GTLRObject

/** Output only. The time template was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Optional. Timeout duration for the DAG of jobs, expressed in seconds (see
 *  JSON representation of duration
 *  (https://developers.google.com/protocol-buffers/docs/proto3#json)). The
 *  timeout duration must be from 10 minutes ("600s") to 24 hours ("86400s").
 *  The timer begins when the first job is submitted. If the workflow is running
 *  at the end of the timeout period, any remaining jobs are cancelled, the
 *  workflow is ended, and if the workflow was running on a managed cluster, the
 *  cluster is deleted.
 */
@property(nonatomic, strong, nullable) GTLRDuration *dagTimeout;

/**
 *  identifier
 *
 *  identifier property maps to 'id' in JSON (to avoid Objective C's 'id').
 */
@property(nonatomic, copy, nullable) NSString *identifier;

/** Required. The Directed Acyclic Graph of Jobs to submit. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_OrderedJob *> *jobs;

/**
 *  Optional. The labels to associate with this template. These labels will be
 *  propagated to all jobs and clusters created by the workflow instance.Label
 *  keys must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt).Label values may be empty, but, if
 *  present, must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt).No more than 32 labels can be
 *  associated with a template.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_WorkflowTemplate_Labels *labels;

/**
 *  Output only. The resource name of the workflow template, as described in
 *  https://cloud.google.com/apis/design/resource_names. For
 *  projects.regions.workflowTemplates, the resource name of the template has
 *  the following format:
 *  projects/{project_id}/regions/{region}/workflowTemplates/{template_id} For
 *  projects.locations.workflowTemplates, the resource name of the template has
 *  the following format:
 *  projects/{project_id}/locations/{location}/workflowTemplates/{template_id}
 */
@property(nonatomic, copy, nullable) NSString *name;

/**
 *  Optional. Template parameters whose values are substituted into the
 *  template. Values for parameters must be provided when the template is
 *  instantiated.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataproc_TemplateParameter *> *parameters;

/** Required. WorkflowTemplate scheduling information. */
@property(nonatomic, strong, nullable) GTLRDataproc_WorkflowTemplatePlacement *placement;

/** Output only. The time template was last updated. */
@property(nonatomic, strong, nullable) GTLRDateTime *updateTime;

/**
 *  Optional. Used to perform a consistent read-modify-write.This field should
 *  be left blank for a CreateWorkflowTemplate request. It is required for an
 *  UpdateWorkflowTemplate request, and must match the current server version. A
 *  typical update template flow would fetch the current template with a
 *  GetWorkflowTemplate request, which will return the current template with the
 *  version field filled in with the current server version. The user updates
 *  other fields in the template, then returns it as part of the
 *  UpdateWorkflowTemplate request.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *version;

@end


/**
 *  Optional. The labels to associate with this template. These labels will be
 *  propagated to all jobs and clusters created by the workflow instance.Label
 *  keys must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt).Label values may be empty, but, if
 *  present, must contain 1 to 63 characters, and must conform to RFC 1035
 *  (https://www.ietf.org/rfc/rfc1035.txt).No more than 32 labels can be
 *  associated with a template.
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataproc_WorkflowTemplate_Labels : GTLRObject
@end


/**
 *  Specifies workflow execution target.Either managed_cluster or
 *  cluster_selector is required.
 */
@interface GTLRDataproc_WorkflowTemplatePlacement : GTLRObject

/**
 *  Optional. A selector that chooses target cluster for jobs based on
 *  metadata.The selector is evaluated at the time each job is submitted.
 */
@property(nonatomic, strong, nullable) GTLRDataproc_ClusterSelector *clusterSelector;

/** A cluster that is managed by the workflow. */
@property(nonatomic, strong, nullable) GTLRDataproc_ManagedCluster *managedCluster;

@end


/**
 *  A YARN application created by a job. Application information is a subset of
 *  org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Beta Feature:
 *  This report is available for testing purposes only. It may be changed before
 *  final release.
 */
@interface GTLRDataproc_YarnApplication : GTLRObject

/** Required. The application name. */
@property(nonatomic, copy, nullable) NSString *name;

/**
 *  Required. The numerical progress of the application, from 1 to 100.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *progress;

/**
 *  Required. The application state.
 *
 *  Likely values:
 *    @arg @c kGTLRDataproc_YarnApplication_State_Accepted Status is ACCEPTED.
 *        (Value: "ACCEPTED")
 *    @arg @c kGTLRDataproc_YarnApplication_State_Failed Status is FAILED.
 *        (Value: "FAILED")
 *    @arg @c kGTLRDataproc_YarnApplication_State_Finished Status is FINISHED.
 *        (Value: "FINISHED")
 *    @arg @c kGTLRDataproc_YarnApplication_State_Killed Status is KILLED.
 *        (Value: "KILLED")
 *    @arg @c kGTLRDataproc_YarnApplication_State_New Status is NEW. (Value:
 *        "NEW")
 *    @arg @c kGTLRDataproc_YarnApplication_State_NewSaving Status is
 *        NEW_SAVING. (Value: "NEW_SAVING")
 *    @arg @c kGTLRDataproc_YarnApplication_State_Running Status is RUNNING.
 *        (Value: "RUNNING")
 *    @arg @c kGTLRDataproc_YarnApplication_State_StateUnspecified Status is
 *        unspecified. (Value: "STATE_UNSPECIFIED")
 *    @arg @c kGTLRDataproc_YarnApplication_State_Submitted Status is SUBMITTED.
 *        (Value: "SUBMITTED")
 */
@property(nonatomic, copy, nullable) NSString *state;

/**
 *  Optional. The HTTP URL of the ApplicationMaster, HistoryServer, or
 *  TimelineServer that provides application-specific information. The URL uses
 *  the internal hostname, and requires a proxy server for resolution and,
 *  possibly, access.
 */
@property(nonatomic, copy, nullable) NSString *trackingUrl;

@end

NS_ASSUME_NONNULL_END

#pragma clang diagnostic pop
