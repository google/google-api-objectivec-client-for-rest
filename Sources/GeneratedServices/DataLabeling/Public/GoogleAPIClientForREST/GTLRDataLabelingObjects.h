// NOTE: This file was generated by the ServiceGenerator.

// ----------------------------------------------------------------------------
// API:
//   Data Labeling API (datalabeling/v1beta1)
// Description:
//   Public API for Google Cloud AI Data Labeling Service.
// Documentation:
//   https://cloud.google.com/data-labeling/docs/

#import <GoogleAPIClientForREST/GTLRObject.h>

#if GTLR_RUNTIME_VERSION != 3000
#error This file was generated by a different version of ServiceGenerator which is incompatible with this GTLR library source.
#endif

@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1GcsDestination;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1GcsFolderDestination;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageBoundingBoxOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageBoundingPolyOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageClassificationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageOrientedBoundingBoxOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImagePolylineOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageSegmentationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelStats;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelStats_ExampleCount;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelTextClassificationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelTextEntityExtractionOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelVideoClassificationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelVideoEventOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelVideoObjectDetectionOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelVideoObjectTrackingOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1OutputConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDatasetMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpecSet;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpecSetConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationValue;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Attempt;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BigQuerySource;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BoundingBoxEvaluationOptions;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BoundingPoly;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BoundingPolyConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ClassificationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ClassificationMetrics;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ConfidenceMetricsEntry;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ConfusionMatrix;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ConfusionMatrixEntry;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1CsvInstruction;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1DataItem;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Dataset;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJobAlertConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJobConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJobConfig_BigqueryImportKeys;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationMetrics;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EventConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Example;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ExampleComparison;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackMessage;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThread;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThreadMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1GcsDestination;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1GcsFolderDestination;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1GcsSource;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageBoundingPolyAnnotation;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationAnnotation;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImagePayload;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImagePolylineAnnotation;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageSegmentationAnnotation;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageSegmentationAnnotation_AnnotationColors;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageBoundingBoxOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageBoundingPolyOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageClassificationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageOrientedBoundingBoxOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImagePolylineOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageSegmentationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelStats;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelStats_ExampleCount;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextClassificationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextEntityExtractionOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoClassificationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoEventOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoObjectDetectionOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoObjectTrackingOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1NormalizedBoundingPoly;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1NormalizedPolyline;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1NormalizedVertex;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectDetectionConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectDetectionMetrics;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectTrackingConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectTrackingFrame;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1OperatorFeedbackMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1OperatorMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1OutputConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1PdfInstruction;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Polyline;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1PolylineConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1PrCurve;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1RequesterFeedbackMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Row;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1SegmentationConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1SentimentConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1SequentialSegment;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextClassificationAnnotation;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextClassificationConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextEntityExtractionAnnotation;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextEntityExtractionConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextPayload;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TimeSegment;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Vertex;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoClassificationAnnotation;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoClassificationConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoEventAnnotation;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoObjectTrackingAnnotation;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoPayload;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoThumbnail;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1GcsDestination;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1GcsFolderDestination;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageBoundingBoxOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageBoundingPolyOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageClassificationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageOrientedBoundingBoxOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImagePolylineOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageSegmentationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelStats;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelStats_ExampleCount;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelTextClassificationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelTextEntityExtractionOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelVideoClassificationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelVideoEventOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelVideoObjectDetectionOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelVideoObjectTrackingOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1OutputConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1GcsDestination;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1GcsFolderDestination;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageBoundingBoxOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageBoundingPolyOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageClassificationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageOrientedBoundingBoxOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImagePolylineOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageSegmentationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelStats;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelStats_ExampleCount;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelTextClassificationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelTextEntityExtractionOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelVideoClassificationOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelVideoEventOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelVideoObjectDetectionOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelVideoObjectTrackingOperationMetadata;
@class GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1OutputConfig;
@class GTLRDataLabeling_GoogleLongrunningOperation;
@class GTLRDataLabeling_GoogleLongrunningOperation_Metadata;
@class GTLRDataLabeling_GoogleLongrunningOperation_Response;
@class GTLRDataLabeling_GoogleRpcStatus;
@class GTLRDataLabeling_GoogleRpcStatus_Details_Item;

// Generated comments include content from the discovery document; avoid them
// causing warnings since clang's checks are some what arbitrary.
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wdocumentation"

NS_ASSUME_NONNULL_BEGIN

// ----------------------------------------------------------------------------
// Constants - For some of the classes' properties below.

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset.annotationSource

/** Value: "ANNOTATION_SOURCE_UNSPECIFIED" */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationSource_AnnotationSourceUnspecified;
/**
 *  Answer is provided by a human contributor.
 *
 *  Value: "OPERATOR"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationSource_Operator;

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset.annotationType

/** Value: "ANNOTATION_TYPE_UNSPECIFIED" */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_AnnotationTypeUnspecified;
/**
 *  General classification. Allowed for continuous evaluation.
 *
 *  Value: "GENERAL_CLASSIFICATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_GeneralClassificationAnnotation;
/**
 *  Bounding box annotations in an image. A form of image object detection.
 *  Allowed for continuous evaluation.
 *
 *  Value: "IMAGE_BOUNDING_BOX_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_ImageBoundingBoxAnnotation;
/**
 *  Bounding poly annotations in an image.
 *
 *  Value: "IMAGE_BOUNDING_POLY_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_ImageBoundingPolyAnnotation;
/**
 *  Classification annotations in an image. Allowed for continuous evaluation.
 *
 *  Value: "IMAGE_CLASSIFICATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_ImageClassificationAnnotation;
/**
 *  Oriented bounding box. The box does not have to be parallel to horizontal
 *  line.
 *
 *  Value: "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_ImageOrientedBoundingBoxAnnotation;
/**
 *  Polyline annotations in an image.
 *
 *  Value: "IMAGE_POLYLINE_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_ImagePolylineAnnotation;
/**
 *  Segmentation annotations in an image.
 *
 *  Value: "IMAGE_SEGMENTATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_ImageSegmentationAnnotation;
/**
 *  Classification for text. Allowed for continuous evaluation.
 *
 *  Value: "TEXT_CLASSIFICATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_TextClassificationAnnotation;
/**
 *  Entity extraction for text.
 *
 *  Value: "TEXT_ENTITY_EXTRACTION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_TextEntityExtractionAnnotation;
/**
 *  Video event annotation.
 *
 *  Value: "VIDEO_EVENT_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_VideoEventAnnotation;
/**
 *  Video object detection annotation.
 *
 *  Value: "VIDEO_OBJECT_DETECTION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_VideoObjectDetectionAnnotation;
/**
 *  Video object tracking annotation.
 *
 *  Value: "VIDEO_OBJECT_TRACKING_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_VideoObjectTrackingAnnotation;
/**
 *  Classification annotations in video shots.
 *
 *  Value: "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_VideoShotsClassificationAnnotation;

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation.annotationSentiment

/** Value: "ANNOTATION_SENTIMENT_UNSPECIFIED" */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation_AnnotationSentiment_AnnotationSentimentUnspecified;
/**
 *  This annotation describes negatively about the data.
 *
 *  Value: "NEGATIVE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation_AnnotationSentiment_Negative;
/**
 *  This label describes positively about the data.
 *
 *  Value: "POSITIVE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation_AnnotationSentiment_Positive;

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation.annotationSource

/** Value: "ANNOTATION_SOURCE_UNSPECIFIED" */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation_AnnotationSource_AnnotationSourceUnspecified;
/**
 *  Answer is provided by a human contributor.
 *
 *  Value: "OPERATOR"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation_AnnotationSource_Operator;

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation.annotationType

/** Value: "ANNOTATION_TYPE_UNSPECIFIED" */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_AnnotationTypeUnspecified;
/**
 *  General classification. Allowed for continuous evaluation.
 *
 *  Value: "GENERAL_CLASSIFICATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_GeneralClassificationAnnotation;
/**
 *  Bounding box annotations in an image. A form of image object detection.
 *  Allowed for continuous evaluation.
 *
 *  Value: "IMAGE_BOUNDING_BOX_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_ImageBoundingBoxAnnotation;
/**
 *  Bounding poly annotations in an image.
 *
 *  Value: "IMAGE_BOUNDING_POLY_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_ImageBoundingPolyAnnotation;
/**
 *  Classification annotations in an image. Allowed for continuous evaluation.
 *
 *  Value: "IMAGE_CLASSIFICATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_ImageClassificationAnnotation;
/**
 *  Oriented bounding box. The box does not have to be parallel to horizontal
 *  line.
 *
 *  Value: "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_ImageOrientedBoundingBoxAnnotation;
/**
 *  Polyline annotations in an image.
 *
 *  Value: "IMAGE_POLYLINE_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_ImagePolylineAnnotation;
/**
 *  Segmentation annotations in an image.
 *
 *  Value: "IMAGE_SEGMENTATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_ImageSegmentationAnnotation;
/**
 *  Classification for text. Allowed for continuous evaluation.
 *
 *  Value: "TEXT_CLASSIFICATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_TextClassificationAnnotation;
/**
 *  Entity extraction for text.
 *
 *  Value: "TEXT_ENTITY_EXTRACTION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_TextEntityExtractionAnnotation;
/**
 *  Video event annotation.
 *
 *  Value: "VIDEO_EVENT_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_VideoEventAnnotation;
/**
 *  Video object detection annotation.
 *
 *  Value: "VIDEO_OBJECT_DETECTION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_VideoObjectDetectionAnnotation;
/**
 *  Video object tracking annotation.
 *
 *  Value: "VIDEO_OBJECT_TRACKING_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_VideoObjectTrackingAnnotation;
/**
 *  Classification annotations in video shots.
 *
 *  Value: "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_VideoShotsClassificationAnnotation;

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob.state

/**
 *  The job is not sampling prediction input and output into your BigQuery table
 *  and it will not run according to its schedule. You can resume the job.
 *
 *  Value: "PAUSED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob_State_Paused;
/**
 *  The job is currently running. When the job runs, Data Labeling Service does
 *  several things: 1. If you have configured your job to use Data Labeling
 *  Service for ground truth labeling, the service creates a Dataset and a
 *  labeling task for all data sampled since the last time the job ran. Human
 *  labelers provide ground truth labels for your data. Human labeling may take
 *  hours, or even days, depending on how much data has been sampled. The job
 *  remains in the `RUNNING` state during this time, and it can even be running
 *  multiple times in parallel if it gets triggered again (for example 24 hours
 *  later) before the earlier run has completed. When human labelers have
 *  finished labeling the data, the next step occurs. If you have configured
 *  your job to provide your own ground truth labels, Data Labeling Service
 *  still creates a Dataset for newly sampled data, but it expects that you have
 *  already added ground truth labels to the BigQuery table by this time. The
 *  next step occurs immediately. 2. Data Labeling Service creates an Evaluation
 *  by comparing your model version's predictions with the ground truth labels.
 *  If the job remains in this state for a long time, it continues to sample
 *  prediction data into your BigQuery table and will run again at the next
 *  interval, even if it causes the job to run multiple times in parallel.
 *
 *  Value: "RUNNING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob_State_Running;
/**
 *  The job is scheduled to run at the configured interval. You can pause or
 *  delete the job. When the job is in this state, it samples prediction input
 *  and output from your model version into your BigQuery table as predictions
 *  occur.
 *
 *  Value: "SCHEDULED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob_State_Scheduled;
/** Value: "STATE_UNSPECIFIED" */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob_State_StateUnspecified;
/**
 *  The job has this state right before it is deleted.
 *
 *  Value: "STOPPED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob_State_Stopped;

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThreadMetadata.status

/** Value: "FEEDBACK_THREAD_STATUS_UNSPECIFIED" */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThreadMetadata_Status_FeedbackThreadStatusUnspecified;
/**
 *  Feedback thread is created with no reply;
 *
 *  Value: "NEW"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThreadMetadata_Status_New;
/**
 *  Feedback thread is replied at least once;
 *
 *  Value: "REPLIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThreadMetadata_Status_Replied;

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig.answerAggregationType

/**
 *  Majority vote to aggregate answers.
 *
 *  Value: "MAJORITY_VOTE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig_AnswerAggregationType_MajorityVote;
/**
 *  Preserve all answers by crowd compute.
 *
 *  Value: "NO_AGGREGATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig_AnswerAggregationType_NoAggregation;
/** Value: "STRING_AGGREGATION_TYPE_UNSPECIFIED" */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig_AnswerAggregationType_StringAggregationTypeUnspecified;
/**
 *  Unanimous answers will be adopted.
 *
 *  Value: "UNANIMOUS_VOTE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig_AnswerAggregationType_UnanimousVote;

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig.annotationType

/** Value: "ANNOTATION_TYPE_UNSPECIFIED" */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_AnnotationTypeUnspecified;
/**
 *  General classification. Allowed for continuous evaluation.
 *
 *  Value: "GENERAL_CLASSIFICATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_GeneralClassificationAnnotation;
/**
 *  Bounding box annotations in an image. A form of image object detection.
 *  Allowed for continuous evaluation.
 *
 *  Value: "IMAGE_BOUNDING_BOX_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_ImageBoundingBoxAnnotation;
/**
 *  Bounding poly annotations in an image.
 *
 *  Value: "IMAGE_BOUNDING_POLY_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_ImageBoundingPolyAnnotation;
/**
 *  Classification annotations in an image. Allowed for continuous evaluation.
 *
 *  Value: "IMAGE_CLASSIFICATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_ImageClassificationAnnotation;
/**
 *  Oriented bounding box. The box does not have to be parallel to horizontal
 *  line.
 *
 *  Value: "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_ImageOrientedBoundingBoxAnnotation;
/**
 *  Polyline annotations in an image.
 *
 *  Value: "IMAGE_POLYLINE_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_ImagePolylineAnnotation;
/**
 *  Segmentation annotations in an image.
 *
 *  Value: "IMAGE_SEGMENTATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_ImageSegmentationAnnotation;
/**
 *  Classification for text. Allowed for continuous evaluation.
 *
 *  Value: "TEXT_CLASSIFICATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_TextClassificationAnnotation;
/**
 *  Entity extraction for text.
 *
 *  Value: "TEXT_ENTITY_EXTRACTION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_TextEntityExtractionAnnotation;
/**
 *  Video event annotation.
 *
 *  Value: "VIDEO_EVENT_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_VideoEventAnnotation;
/**
 *  Video object detection annotation.
 *
 *  Value: "VIDEO_OBJECT_DETECTION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_VideoObjectDetectionAnnotation;
/**
 *  Video object tracking annotation.
 *
 *  Value: "VIDEO_OBJECT_TRACKING_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_VideoObjectTrackingAnnotation;
/**
 *  Classification annotations in video shots.
 *
 *  Value: "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_VideoShotsClassificationAnnotation;

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig.dataType

/**
 *  Data type is unspecified.
 *
 *  Value: "DATA_TYPE_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_DataType_DataTypeUnspecified;
/**
 *  Allowed for continuous evaluation.
 *
 *  Value: "GENERAL_DATA"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_DataType_GeneralData;
/**
 *  Allowed for continuous evaluation.
 *
 *  Value: "IMAGE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_DataType_Image;
/**
 *  Allowed for continuous evaluation.
 *
 *  Value: "TEXT"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_DataType_Text;
/**
 *  Video data type.
 *
 *  Value: "VIDEO"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_DataType_Video;

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction.dataType

/**
 *  Data type is unspecified.
 *
 *  Value: "DATA_TYPE_UNSPECIFIED"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction_DataType_DataTypeUnspecified;
/**
 *  Allowed for continuous evaluation.
 *
 *  Value: "GENERAL_DATA"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction_DataType_GeneralData;
/**
 *  Allowed for continuous evaluation.
 *
 *  Value: "IMAGE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction_DataType_Image;
/**
 *  Allowed for continuous evaluation.
 *
 *  Value: "TEXT"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction_DataType_Text;
/**
 *  Video data type.
 *
 *  Value: "VIDEO"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction_DataType_Video;

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest.feature

/**
 *  Label image with bounding boxes for labels.
 *
 *  Value: "BOUNDING_BOX"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_BoundingBox;
/**
 *  Label images with bounding poly. A bounding poly is a plane figure that is
 *  bounded by a finite chain of straight line segments closing in a loop.
 *
 *  Value: "BOUNDING_POLY"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_BoundingPoly;
/**
 *  Label whole image with one or more of labels.
 *
 *  Value: "CLASSIFICATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_Classification;
/** Value: "FEATURE_UNSPECIFIED" */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_FeatureUnspecified;
/**
 *  Label oriented bounding box. The box does not have to be parallel to
 *  horizontal line.
 *
 *  Value: "ORIENTED_BOUNDING_BOX"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_OrientedBoundingBox;
/**
 *  Label images with polyline. Polyline is formed by connected line segments
 *  which are not in closed form.
 *
 *  Value: "POLYLINE"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_Polyline;
/**
 *  Label images with segmentation. Segmentation is different from bounding poly
 *  since it is more fine-grained, pixel level annotation.
 *
 *  Value: "SEGMENTATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_Segmentation;

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextRequest.feature

/** Value: "FEATURE_UNSPECIFIED" */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextRequest_Feature_FeatureUnspecified;
/**
 *  Label text content to one of more labels.
 *
 *  Value: "TEXT_CLASSIFICATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextRequest_Feature_TextClassification;
/**
 *  Label entities and their span in text.
 *
 *  Value: "TEXT_ENTITY_EXTRACTION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextRequest_Feature_TextEntityExtraction;

// ----------------------------------------------------------------------------
// GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoRequest.feature

/**
 *  Label whole video or video segment with one or more labels.
 *
 *  Value: "CLASSIFICATION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoRequest_Feature_Classification;
/**
 *  Label the range of video for the specified events.
 *
 *  Value: "EVENT"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoRequest_Feature_Event;
/** Value: "FEATURE_UNSPECIFIED" */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoRequest_Feature_FeatureUnspecified;
/**
 *  Label objects with bounding box on image frames extracted from the video.
 *
 *  Value: "OBJECT_DETECTION"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoRequest_Feature_ObjectDetection;
/**
 *  Label and track objects in video.
 *
 *  Value: "OBJECT_TRACKING"
 */
FOUNDATION_EXTERN NSString * const kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoRequest_Feature_ObjectTracking;

/**
 *  Metadata of a CreateInstruction operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1CreateInstructionMetadata : GTLRObject

/** Timestamp when create instruction request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  The name of the created Instruction.
 *  projects/{project_id}/instructions/{instruction_id}
 */
@property(nonatomic, copy, nullable) NSString *instruction;

/**
 *  Partial failures encountered. E.g. single files that couldn't be read.
 *  Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

@end


/**
 *  Metadata of an ExportData operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1ExportDataOperationMetadata : GTLRObject

/**
 *  Output only. The name of annotated dataset in format "projects/ * /datasets/
 *  * /annotatedDatasets/ *".
 */
@property(nonatomic, copy, nullable) NSString *annotatedDataset;

/** Output only. Timestamp when export dataset request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Output only. The name of dataset to be exported. "projects/ * /datasets/ *"
 */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Partial failures encountered. E.g. single files that couldn't
 *  be read. Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

@end


/**
 *  Response used for ExportDataset longrunning operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1ExportDataOperationResponse : GTLRObject

/**
 *  Output only. The name of annotated dataset in format "projects/ * /datasets/
 *  * /annotatedDatasets/ *".
 */
@property(nonatomic, copy, nullable) NSString *annotatedDataset;

/** Ouptut only. The name of dataset. "projects/ * /datasets/ *" */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Number of examples exported successfully.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *exportCount;

/** Output only. Statistic infos of labels in the exported dataset. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelStats *labelStats;

/** Output only. output_config in the ExportData request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1OutputConfig *outputConfig;

/**
 *  Output only. Total number of examples requested to export
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *totalCount;

@end


/**
 *  Export destination of the data.Only gcs path is allowed in output_uri.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1GcsDestination : GTLRObject

/**
 *  Required. The format of the gcs destination. Only "text/csv" and
 *  "application/json" are supported.
 */
@property(nonatomic, copy, nullable) NSString *mimeType;

/** Required. The output uri of destination file. */
@property(nonatomic, copy, nullable) NSString *outputUri;

@end


/**
 *  Export folder destination of the data.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1GcsFolderDestination : GTLRObject

/** Required. Cloud Storage directory to export data to. */
@property(nonatomic, copy, nullable) NSString *outputFolderUri;

@end


/**
 *  Configuration for how human labeling task should be done.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig : GTLRObject

/**
 *  Optional. A human-readable description for AnnotatedDataset. The description
 *  can be up to 10000 characters long.
 */
@property(nonatomic, copy, nullable) NSString *annotatedDatasetDescription;

/**
 *  Required. A human-readable name for AnnotatedDataset defined by users.
 *  Maximum of 64 characters .
 */
@property(nonatomic, copy, nullable) NSString *annotatedDatasetDisplayName;

/**
 *  Optional. If you want your own labeling contributors to manage and work on
 *  this labeling request, you can set these contributors here. We will give
 *  them access to the question types in crowdcompute. Note that these emails
 *  must be registered in crowdcompute worker UI:
 *  https://crowd-compute.appspot.com/
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *contributorEmails;

/** Required. Instruction resource name. */
@property(nonatomic, copy, nullable) NSString *instruction;

/**
 *  Optional. A human-readable label used to logically group labeling tasks.
 *  This string must match the regular expression `[a-zA-Z\\\\d_-]{0,128}`.
 */
@property(nonatomic, copy, nullable) NSString *labelGroup;

/**
 *  Optional. The Language of this question, as a
 *  [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is
 *  en-US. Only need to set this when task is language related. For example,
 *  French text classification.
 */
@property(nonatomic, copy, nullable) NSString *languageCode;

/**
 *  Optional. Maximum duration for contributors to answer a question. Maximum is
 *  3600 seconds. Default is 3600 seconds.
 */
@property(nonatomic, strong, nullable) GTLRDuration *questionDuration;

/**
 *  Optional. Replication of questions. Each question will be sent to up to this
 *  number of contributors to label. Aggregated answers will be returned.
 *  Default is set to 1. For image related labeling, valid values are 1, 3, 5.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *replicaCount;

/**
 *  Email of the user who started the labeling task and should be notified by
 *  email. If empty no notification will be sent.
 */
@property(nonatomic, copy, nullable) NSString *userEmailAddress;

@end


/**
 *  Metadata of an ImportData operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1ImportDataOperationMetadata : GTLRObject

/** Output only. Timestamp when import dataset request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/** Output only. The name of imported dataset. "projects/ * /datasets/ *" */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Partial failures encountered. E.g. single files that couldn't
 *  be read. Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

@end


/**
 *  Response used for ImportData longrunning operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1ImportDataOperationResponse : GTLRObject

/** Ouptut only. The name of imported dataset. */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Number of examples imported successfully.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *importCount;

/**
 *  Output only. Total number of examples requested to import
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *totalCount;

@end


/**
 *  Details of a LabelImageBoundingBox operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageBoundingBoxOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of LabelImageBoundingPoly operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageBoundingPolyOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Metadata of a LabelImageClassification operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageClassificationOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelImageOrientedBoundingBox operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageOrientedBoundingBoxOperationMetadata : GTLRObject

/** Basic human annotation config. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of LabelImagePolyline operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImagePolylineOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelImageSegmentation operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageSegmentationOperationMetadata : GTLRObject

/** Basic human annotation config. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Metadata of a labeling operation, such as LabelImage or LabelVideo. Next
 *  tag: 23
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelOperationMetadata : GTLRObject

/**
 *  Output only. The name of annotated dataset in format "projects/ * /datasets/
 *  * /annotatedDatasets/ *".
 */
@property(nonatomic, copy, nullable) NSString *annotatedDataset;

/** Output only. Timestamp when labeling request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Output only. The name of dataset to be labeled. "projects/ * /datasets/ *"
 */
@property(nonatomic, copy, nullable) NSString *dataset;

/** Details of label image bounding box operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageBoundingBoxOperationMetadata *imageBoundingBoxDetails;

/** Details of label image bounding poly operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageBoundingPolyOperationMetadata *imageBoundingPolyDetails;

/** Details of label image classification operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageClassificationOperationMetadata *imageClassificationDetails;

/** Details of label image oriented bounding box operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageOrientedBoundingBoxOperationMetadata *imageOrientedBoundingBoxDetails;

/** Details of label image polyline operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImagePolylineOperationMetadata *imagePolylineDetails;

/** Details of label image segmentation operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelImageSegmentationOperationMetadata *imageSegmentationDetails;

/**
 *  Output only. Partial failures encountered. E.g. single files that couldn't
 *  be read. Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

/**
 *  Output only. Progress of label operation. Range: [0, 100].
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *progressPercent;

/** Details of label text classification operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelTextClassificationOperationMetadata *textClassificationDetails;

/** Details of label text entity extraction operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelTextEntityExtractionOperationMetadata *textEntityExtractionDetails;

/** Details of label video classification operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelVideoClassificationOperationMetadata *videoClassificationDetails;

/** Details of label video event operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelVideoEventOperationMetadata *videoEventDetails;

/** Details of label video object detection operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelVideoObjectDetectionOperationMetadata *videoObjectDetectionDetails;

/** Details of label video object tracking operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelVideoObjectTrackingOperationMetadata *videoObjectTrackingDetails;

@end


/**
 *  Statistics about annotation specs.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelStats : GTLRObject

/**
 *  Map of each annotation spec's example count. Key is the annotation spec name
 *  and value is the number of examples for that annotation spec. If the
 *  annotated dataset does not have annotation spec, the map will return a pair
 *  where the key is empty string and value is the total number of annotations.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelStats_ExampleCount *exampleCount;

@end


/**
 *  Map of each annotation spec's example count. Key is the annotation spec name
 *  and value is the number of examples for that annotation spec. If the
 *  annotated dataset does not have annotation spec, the map will return a pair
 *  where the key is empty string and value is the total number of annotations.
 *
 *  @note This class is documented as having more properties of NSNumber (Uses
 *        NSNumber of longLongValue.). Use @c -additionalJSONKeys and @c
 *        -additionalPropertyForName: to get the list of properties and then
 *        fetch them; or @c -additionalProperties to fetch them all at once.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelStats_ExampleCount : GTLRObject
@end


/**
 *  Details of a LabelTextClassification operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelTextClassificationOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelTextEntityExtraction operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelTextEntityExtractionOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoClassification operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelVideoClassificationOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoEvent operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelVideoEventOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoObjectDetection operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelVideoObjectDetectionOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoObjectTracking operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1LabelVideoObjectTrackingOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  The configuration of output data.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1OutputConfig : GTLRObject

/**
 *  Output to a file in Cloud Storage. Should be used for labeling output other
 *  than image segmentation.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1GcsDestination *gcsDestination;

/**
 *  Output to a folder in Cloud Storage. Should be used for image segmentation
 *  or document de-identification labeling outputs.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1alpha1GcsFolderDestination *gcsFolderDestination;

@end


/**
 *  AnnotatedDataset is a set holding annotations for data in a Dataset. Each
 *  labeling task will generate an AnnotatedDataset under the Dataset that the
 *  task is requested for.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset : GTLRObject

/**
 *  Output only. Source of the annotation.
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationSource_AnnotationSourceUnspecified
 *        Value "ANNOTATION_SOURCE_UNSPECIFIED"
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationSource_Operator
 *        Answer is provided by a human contributor. (Value: "OPERATOR")
 */
@property(nonatomic, copy, nullable) NSString *annotationSource;

/**
 *  Output only. Type of the annotation. It is specified when starting labeling
 *  task.
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_AnnotationTypeUnspecified
 *        Value "ANNOTATION_TYPE_UNSPECIFIED"
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_GeneralClassificationAnnotation
 *        General classification. Allowed for continuous evaluation. (Value:
 *        "GENERAL_CLASSIFICATION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_ImageBoundingBoxAnnotation
 *        Bounding box annotations in an image. A form of image object
 *        detection. Allowed for continuous evaluation. (Value:
 *        "IMAGE_BOUNDING_BOX_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_ImageBoundingPolyAnnotation
 *        Bounding poly annotations in an image. (Value:
 *        "IMAGE_BOUNDING_POLY_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_ImageClassificationAnnotation
 *        Classification annotations in an image. Allowed for continuous
 *        evaluation. (Value: "IMAGE_CLASSIFICATION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_ImageOrientedBoundingBoxAnnotation
 *        Oriented bounding box. The box does not have to be parallel to
 *        horizontal line. (Value: "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_ImagePolylineAnnotation
 *        Polyline annotations in an image. (Value: "IMAGE_POLYLINE_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_ImageSegmentationAnnotation
 *        Segmentation annotations in an image. (Value:
 *        "IMAGE_SEGMENTATION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_TextClassificationAnnotation
 *        Classification for text. Allowed for continuous evaluation. (Value:
 *        "TEXT_CLASSIFICATION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_TextEntityExtractionAnnotation
 *        Entity extraction for text. (Value:
 *        "TEXT_ENTITY_EXTRACTION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_VideoEventAnnotation
 *        Video event annotation. (Value: "VIDEO_EVENT_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_VideoObjectDetectionAnnotation
 *        Video object detection annotation. (Value:
 *        "VIDEO_OBJECT_DETECTION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_VideoObjectTrackingAnnotation
 *        Video object tracking annotation. (Value:
 *        "VIDEO_OBJECT_TRACKING_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset_AnnotationType_VideoShotsClassificationAnnotation
 *        Classification annotations in video shots. (Value:
 *        "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION")
 */
@property(nonatomic, copy, nullable) NSString *annotationType;

/**
 *  Output only. The names of any related resources that are blocking changes to
 *  the annotated dataset.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *blockingResources;

/**
 *  Output only. Number of examples that have annotation in the annotated
 *  dataset.
 *
 *  Uses NSNumber of longLongValue.
 */
@property(nonatomic, strong, nullable) NSNumber *completedExampleCount;

/** Output only. Time the AnnotatedDataset was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Output only. The description of the AnnotatedDataset. It is specified in
 *  HumanAnnotationConfig when user starts a labeling task. Maximum of 10000
 *  characters.
 *
 *  Remapped to 'descriptionProperty' to avoid NSObject's 'description'.
 */
@property(nonatomic, copy, nullable) NSString *descriptionProperty;

/**
 *  Output only. The display name of the AnnotatedDataset. It is specified in
 *  HumanAnnotationConfig when user starts a labeling task. Maximum of 64
 *  characters.
 */
@property(nonatomic, copy, nullable) NSString *displayName;

/**
 *  Output only. Number of examples in the annotated dataset.
 *
 *  Uses NSNumber of longLongValue.
 */
@property(nonatomic, strong, nullable) NSNumber *exampleCount;

/** Output only. Per label statistics. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelStats *labelStats;

/** Output only. Additional information about AnnotatedDataset. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDatasetMetadata *metadata;

/**
 *  Output only. AnnotatedDataset resource name in format of:
 *  projects/{project_id}/datasets/{dataset_id}/annotatedDatasets/
 *  {annotated_dataset_id}
 */
@property(nonatomic, copy, nullable) NSString *name;

@end


/**
 *  Metadata on AnnotatedDataset.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDatasetMetadata : GTLRObject

/** Configuration for image bounding box and bounding poly task. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BoundingPolyConfig *boundingPolyConfig;

/** Configuration for video event labeling task. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EventConfig *eventConfig;

/**
 *  HumanAnnotationConfig used when requesting the human labeling task for this
 *  AnnotatedDataset.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *humanAnnotationConfig;

/** Configuration for image classification task. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig *imageClassificationConfig;

/** Configuration for video object detection task. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectDetectionConfig *objectDetectionConfig;

/** Configuration for video object tracking task. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectTrackingConfig *objectTrackingConfig;

/** Configuration for image polyline task. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1PolylineConfig *polylineConfig;

/** Configuration for image segmentation task. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1SegmentationConfig *segmentationConfig;

/** Configuration for text classification task. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextClassificationConfig *textClassificationConfig;

/** Configuration for text entity extraction task. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextEntityExtractionConfig *textEntityExtractionConfig;

/** Configuration for video classification task. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoClassificationConfig *videoClassificationConfig;

@end


/**
 *  Annotation for Example. Each example may have one or more annotations. For
 *  example in image classification problem, each image might have one or more
 *  labels. We call labels binded with this image an Annotation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation : GTLRObject

/**
 *  Output only. Annotation metadata, including information like votes for
 *  labels.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationMetadata *annotationMetadata;

/**
 *  Output only. Sentiment for this annotation.
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation_AnnotationSentiment_AnnotationSentimentUnspecified
 *        Value "ANNOTATION_SENTIMENT_UNSPECIFIED"
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation_AnnotationSentiment_Negative
 *        This annotation describes negatively about the data. (Value:
 *        "NEGATIVE")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation_AnnotationSentiment_Positive
 *        This label describes positively about the data. (Value: "POSITIVE")
 */
@property(nonatomic, copy, nullable) NSString *annotationSentiment;

/**
 *  Output only. The source of the annotation.
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation_AnnotationSource_AnnotationSourceUnspecified
 *        Value "ANNOTATION_SOURCE_UNSPECIFIED"
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation_AnnotationSource_Operator
 *        Answer is provided by a human contributor. (Value: "OPERATOR")
 */
@property(nonatomic, copy, nullable) NSString *annotationSource;

/**
 *  Output only. This is the actual annotation value, e.g classification,
 *  bounding box values are stored here.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationValue *annotationValue;

/**
 *  Output only. Unique name of this annotation, format is:
 *  projects/{project_id}/datasets/{dataset_id}/annotatedDatasets/{annotated_dataset}/examples/{example_id}/annotations/{annotation_id}
 */
@property(nonatomic, copy, nullable) NSString *name;

@end


/**
 *  Additional information associated with the annotation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationMetadata : GTLRObject

/** Metadata related to human labeling. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1OperatorMetadata *operatorMetadata;

@end


/**
 *  Container of information related to one possible annotation that can be used
 *  in a labeling task. For example, an image classification task where images
 *  are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and
 *  an AnnotationSpec for `cat`.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec : GTLRObject

/**
 *  Optional. User-provided description of the annotation specification. The
 *  description can be up to 10,000 characters long.
 *
 *  Remapped to 'descriptionProperty' to avoid NSObject's 'description'.
 */
@property(nonatomic, copy, nullable) NSString *descriptionProperty;

/**
 *  Required. The display name of the AnnotationSpec. Maximum of 64 characters.
 */
@property(nonatomic, copy, nullable) NSString *displayName;

/**
 *  Output only. This is the integer index of the AnnotationSpec. The index for
 *  the whole AnnotationSpecSet is sequential starting from 0. For example, an
 *  AnnotationSpecSet with classes `dog` and `cat`, might contain one
 *  AnnotationSpec with `{ display_name: "dog", index: 0 }` and one
 *  AnnotationSpec with `{ display_name: "cat", index: 1 }`. This is especially
 *  useful for model training as it encodes the string labels into numeric
 *  values.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *index;

@end


/**
 *  An AnnotationSpecSet is a collection of label definitions. For example, in
 *  image classification tasks, you define a set of possible labels for images
 *  as an AnnotationSpecSet. An AnnotationSpecSet is immutable upon creation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpecSet : GTLRObject

/**
 *  Required. The array of AnnotationSpecs that you define when you create the
 *  AnnotationSpecSet. These are the possible labels for the labeling task.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec *> *annotationSpecs;

/**
 *  Output only. The names of any related resources that are blocking changes to
 *  the annotation spec set.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *blockingResources;

/**
 *  Optional. User-provided description of the annotation specification set. The
 *  description can be up to 10,000 characters long.
 *
 *  Remapped to 'descriptionProperty' to avoid NSObject's 'description'.
 */
@property(nonatomic, copy, nullable) NSString *descriptionProperty;

/**
 *  Required. The display name for AnnotationSpecSet that you define when you
 *  create it. Maximum of 64 characters.
 */
@property(nonatomic, copy, nullable) NSString *displayName;

/**
 *  Output only. The AnnotationSpecSet resource name in the following format:
 *  "projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}"
 */
@property(nonatomic, copy, nullable) NSString *name;

@end


/**
 *  Annotation spec set with the setting of allowing multi labels or not.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpecSetConfig : GTLRObject

/**
 *  Optional. If allow_multi_label is true, contributors are able to choose
 *  multiple labels from one annotation spec set.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *allowMultiLabel;

/** Required. Annotation spec set resource name. */
@property(nonatomic, copy, nullable) NSString *annotationSpecSet;

@end


/**
 *  Annotation value for an example.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationValue : GTLRObject

/**
 *  Annotation value for image bounding box, oriented bounding box and polygon
 *  cases.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageBoundingPolyAnnotation *imageBoundingPolyAnnotation;

/** Annotation value for image classification case. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationAnnotation *imageClassificationAnnotation;

/**
 *  Annotation value for image polyline cases. Polyline here is different from
 *  BoundingPoly. It is formed by line segments connected to each other but not
 *  closed form(Bounding Poly). The line segments can cross each other.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImagePolylineAnnotation *imagePolylineAnnotation;

/** Annotation value for image segmentation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageSegmentationAnnotation *imageSegmentationAnnotation;

/** Annotation value for text classification case. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextClassificationAnnotation *textClassificationAnnotation;

/** Annotation value for text entity extraction case. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextEntityExtractionAnnotation *textEntityExtractionAnnotation;

/** Annotation value for video classification case. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoClassificationAnnotation *videoClassificationAnnotation;

/** Annotation value for video event case. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoEventAnnotation *videoEventAnnotation;

/** Annotation value for video object detection and tracking case. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoObjectTrackingAnnotation *videoObjectTrackingAnnotation;

@end


/**
 *  Records a failed evaluation job run.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Attempt : GTLRObject

@property(nonatomic, strong, nullable) GTLRDateTime *attemptTime;

/** Details of errors that occurred. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

@end


/**
 *  The BigQuery location for input data. If used in an EvaluationJob, this is
 *  where the service saves the prediction input and output sampled from the
 *  model version.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BigQuerySource : GTLRObject

/**
 *  Required. BigQuery URI to a table, up to 2,000 characters long. If you
 *  specify the URI of a table that does not exist, Data Labeling Service
 *  creates a table at the URI with the correct schema when you create your
 *  EvaluationJob. If you specify the URI of a table that already exists, it
 *  must have the [correct
 *  schema](/ml-engine/docs/continuous-evaluation/create-job#table-schema).
 *  Provide the table URI in the following format: "bq://{your_project_id}/
 *  {your_dataset_name}/{your_table_name}" [Learn
 *  more](/ml-engine/docs/continuous-evaluation/create-job#table-schema).
 */
@property(nonatomic, copy, nullable) NSString *inputUri;

@end


/**
 *  Options regarding evaluation between bounding boxes.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BoundingBoxEvaluationOptions : GTLRObject

/**
 *  Minimum [intersection-over-union
 *  (IOU)](/vision/automl/object-detection/docs/evaluate#intersection-over-union)
 *  required for 2 bounding boxes to be considered a match. This must be a
 *  number between 0 and 1.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *iouThreshold;

@end


/**
 *  A bounding polygon in the image.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BoundingPoly : GTLRObject

/** The bounding polygon vertices. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Vertex *> *vertices;

@end


/**
 *  Config for image bounding poly (and bounding box) human labeling task.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BoundingPolyConfig : GTLRObject

/** Required. Annotation spec set resource name. */
@property(nonatomic, copy, nullable) NSString *annotationSpecSet;

/** Optional. Instruction message showed on contributors UI. */
@property(nonatomic, copy, nullable) NSString *instructionMessage;

@end


/**
 *  Metadata for classification annotations.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ClassificationMetadata : GTLRObject

/**
 *  Whether the classification task is multi-label or not.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *isMultiLabel;

@end


/**
 *  Metrics calculated for a classification model.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ClassificationMetrics : GTLRObject

/** Confusion matrix of predicted labels vs. ground truth labels. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ConfusionMatrix *confusionMatrix;

/**
 *  Precision-recall curve based on ground truth labels, predicted labels, and
 *  scores for the predicted labels.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1PrCurve *prCurve;

@end


/**
 *  GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ConfidenceMetricsEntry
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ConfidenceMetricsEntry : GTLRObject

/**
 *  Threshold used for this entry. For classification tasks, this is a
 *  classification threshold: a predicted label is categorized as positive or
 *  negative (in the context of this point on the PR curve) based on whether the
 *  label's score meets this threshold. For image object detection (bounding
 *  box) tasks, this is the [intersection-over-union
 *  (IOU)](/vision/automl/object-detection/docs/evaluate#intersection-over-union)
 *  threshold for the context of this point on the PR curve.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *confidenceThreshold;

/**
 *  Harmonic mean of recall and precision.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *f1Score;

/**
 *  The harmonic mean of recall_at1 and precision_at1.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *f1ScoreAt1;

/**
 *  The harmonic mean of recall_at5 and precision_at5.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *f1ScoreAt5;

/**
 *  Precision value.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *precision;

/**
 *  Precision value for entries with label that has highest score.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *precisionAt1;

/**
 *  Precision value for entries with label that has highest 5 scores.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *precisionAt5;

/**
 *  Recall value.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *recall;

/**
 *  Recall value for entries with label that has highest score.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *recallAt1;

/**
 *  Recall value for entries with label that has highest 5 scores.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *recallAt5;

@end


/**
 *  Confusion matrix of the model running the classification. Only applicable
 *  when the metrics entry aggregates multiple labels. Not applicable when the
 *  entry is for a single label.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ConfusionMatrix : GTLRObject

@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Row *> *row;

@end


/**
 *  GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ConfusionMatrixEntry
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ConfusionMatrixEntry : GTLRObject

/** The annotation spec of a predicted label. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec *annotationSpec;

/**
 *  Number of items predicted to have this label. (The ground truth label for
 *  these items is the `Row.annotationSpec` of this entry's parent.)
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *itemCount;

@end


/**
 *  Request message for CreateAnnotationSpecSet.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1CreateAnnotationSpecSetRequest : GTLRObject

/**
 *  Required. Annotation spec set to create. Annotation specs must be included.
 *  Only one annotation spec will be accepted for annotation specs with same
 *  display_name.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpecSet *annotationSpecSet;

@end


/**
 *  Request message for CreateDataset.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1CreateDatasetRequest : GTLRObject

/** Required. The dataset to be created. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Dataset *dataset;

@end


/**
 *  Request message for CreateEvaluationJob.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1CreateEvaluationJobRequest : GTLRObject

/** Required. The evaluation job to create. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob *job;

@end


/**
 *  Metadata of a CreateInstruction operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1CreateInstructionMetadata : GTLRObject

/** Timestamp when create instruction request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  The name of the created Instruction.
 *  projects/{project_id}/instructions/{instruction_id}
 */
@property(nonatomic, copy, nullable) NSString *instruction;

/**
 *  Partial failures encountered. E.g. single files that couldn't be read.
 *  Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

@end


/**
 *  Request message for CreateInstruction.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1CreateInstructionRequest : GTLRObject

/** Required. Instruction of how to perform the labeling task. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction *instruction;

@end


/**
 *  Deprecated: this instruction format is not supported any more. Instruction
 *  from a CSV file.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1CsvInstruction : GTLRObject

/** CSV file for the instruction. Only gcs path is allowed. */
@property(nonatomic, copy, nullable) NSString *gcsFileUri;

@end


/**
 *  DataItem is a piece of data, without annotation. For example, an image.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1DataItem : GTLRObject

/** The image payload, a container of the image bytes/uri. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImagePayload *imagePayload;

/**
 *  Output only. Name of the data item, in format of:
 *  projects/{project_id}/datasets/{dataset_id}/dataItems/{data_item_id}
 */
@property(nonatomic, copy, nullable) NSString *name;

/** The text payload, a container of text content. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextPayload *textPayload;

/** The video payload, a container of the video uri. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoPayload *videoPayload;

@end


/**
 *  Dataset is the resource to hold your data. You can request multiple labeling
 *  tasks for a dataset while each one will generate an AnnotatedDataset.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Dataset : GTLRObject

/**
 *  Output only. The names of any related resources that are blocking changes to
 *  the dataset.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *blockingResources;

/** Output only. Time the dataset is created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Output only. The number of data items in the dataset.
 *
 *  Uses NSNumber of longLongValue.
 */
@property(nonatomic, strong, nullable) NSNumber *dataItemCount;

/**
 *  Optional. User-provided description of the annotation specification set. The
 *  description can be up to 10000 characters long.
 *
 *  Remapped to 'descriptionProperty' to avoid NSObject's 'description'.
 */
@property(nonatomic, copy, nullable) NSString *descriptionProperty;

/** Required. The display name of the dataset. Maximum of 64 characters. */
@property(nonatomic, copy, nullable) NSString *displayName;

/**
 *  Output only. This is populated with the original input configs where
 *  ImportData is called. It is available only after the clients import data to
 *  this dataset.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig *> *inputConfigs;

/**
 *  Last time that the Dataset is migrated to AI Platform V2. If any of the
 *  AnnotatedDataset is migrated, the last_migration_time in Dataset is also
 *  updated.
 */
@property(nonatomic, strong, nullable) GTLRDateTime *lastMigrateTime;

/**
 *  Output only. Dataset resource name, format is:
 *  projects/{project_id}/datasets/{dataset_id}
 */
@property(nonatomic, copy, nullable) NSString *name;

@end


/**
 *  Describes an evaluation between a machine learning model's predictions and
 *  ground truth labels. Created when an EvaluationJob runs successfully.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation : GTLRObject

/**
 *  Output only. Type of task that the model version being evaluated performs,
 *  as defined in the evaluationJobConfig.inputConfig.annotationType field of
 *  the evaluation job that created this evaluation.
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_AnnotationTypeUnspecified
 *        Value "ANNOTATION_TYPE_UNSPECIFIED"
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_GeneralClassificationAnnotation
 *        General classification. Allowed for continuous evaluation. (Value:
 *        "GENERAL_CLASSIFICATION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_ImageBoundingBoxAnnotation
 *        Bounding box annotations in an image. A form of image object
 *        detection. Allowed for continuous evaluation. (Value:
 *        "IMAGE_BOUNDING_BOX_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_ImageBoundingPolyAnnotation
 *        Bounding poly annotations in an image. (Value:
 *        "IMAGE_BOUNDING_POLY_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_ImageClassificationAnnotation
 *        Classification annotations in an image. Allowed for continuous
 *        evaluation. (Value: "IMAGE_CLASSIFICATION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_ImageOrientedBoundingBoxAnnotation
 *        Oriented bounding box. The box does not have to be parallel to
 *        horizontal line. (Value: "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_ImagePolylineAnnotation
 *        Polyline annotations in an image. (Value: "IMAGE_POLYLINE_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_ImageSegmentationAnnotation
 *        Segmentation annotations in an image. (Value:
 *        "IMAGE_SEGMENTATION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_TextClassificationAnnotation
 *        Classification for text. Allowed for continuous evaluation. (Value:
 *        "TEXT_CLASSIFICATION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_TextEntityExtractionAnnotation
 *        Entity extraction for text. (Value:
 *        "TEXT_ENTITY_EXTRACTION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_VideoEventAnnotation
 *        Video event annotation. (Value: "VIDEO_EVENT_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_VideoObjectDetectionAnnotation
 *        Video object detection annotation. (Value:
 *        "VIDEO_OBJECT_DETECTION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_VideoObjectTrackingAnnotation
 *        Video object tracking annotation. (Value:
 *        "VIDEO_OBJECT_TRACKING_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation_AnnotationType_VideoShotsClassificationAnnotation
 *        Classification annotations in video shots. (Value:
 *        "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION")
 */
@property(nonatomic, copy, nullable) NSString *annotationType;

/**
 *  Output only. Options used in the evaluation job that created this
 *  evaluation.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationConfig *config;

/** Output only. Timestamp for when this evaluation was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Output only. The number of items in the ground truth dataset that were used
 *  for this evaluation. Only populated when the evaulation is for certain
 *  AnnotationTypes.
 *
 *  Uses NSNumber of longLongValue.
 */
@property(nonatomic, strong, nullable) NSNumber *evaluatedItemCount;

/**
 *  Output only. Timestamp for when the evaluation job that created this
 *  evaluation ran.
 */
@property(nonatomic, strong, nullable) GTLRDateTime *evaluationJobRunTime;

/** Output only. Metrics comparing predictions to ground truth labels. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationMetrics *evaluationMetrics;

/**
 *  Output only. Resource name of an evaluation. The name has the following
 *  format: "projects/{project_id}/datasets/{dataset_id}/evaluations/
 *  {evaluation_id}'
 */
@property(nonatomic, copy, nullable) NSString *name;

@end


/**
 *  Configuration details used for calculating evaluation metrics and creating
 *  an Evaluation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationConfig : GTLRObject

/**
 *  Only specify this field if the related model performs image object detection
 *  (`IMAGE_BOUNDING_BOX_ANNOTATION`). Describes how to evaluate bounding boxes.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BoundingBoxEvaluationOptions *boundingBoxEvaluationOptions;

@end


/**
 *  Defines an evaluation job that runs periodically to generate Evaluations.
 *  [Creating an evaluation
 *  job](/ml-engine/docs/continuous-evaluation/create-job) is the starting point
 *  for using continuous evaluation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob : GTLRObject

/**
 *  Required. Name of the AnnotationSpecSet describing all the labels that your
 *  machine learning model outputs. You must create this resource before you
 *  create an evaluation job and provide its name in the following format:
 *  "projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}"
 */
@property(nonatomic, copy, nullable) NSString *annotationSpecSet;

/**
 *  Output only. Every time the evaluation job runs and an error occurs, the
 *  failed attempt is appended to this array.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Attempt *> *attempts;

/** Output only. Timestamp of when this evaluation job was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Required. Description of the job. The description can be up to 25,000
 *  characters long.
 *
 *  Remapped to 'descriptionProperty' to avoid NSObject's 'description'.
 */
@property(nonatomic, copy, nullable) NSString *descriptionProperty;

/** Required. Configuration details for the evaluation job. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJobConfig *evaluationJobConfig;

/**
 *  Required. Whether you want Data Labeling Service to provide ground truth
 *  labels for prediction input. If you want the service to assign human
 *  labelers to annotate your data, set this to `true`. If you want to provide
 *  your own ground truth labels in the evaluation job's BigQuery table, set
 *  this to `false`.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *labelMissingGroundTruth;

/**
 *  Required. The [AI Platform Prediction model
 *  version](/ml-engine/docs/prediction-overview) to be evaluated. Prediction
 *  input and output is sampled from this model version. When creating an
 *  evaluation job, specify the model version in the following format:
 *  "projects/{project_id}/models/{model_name}/versions/{version_name}" There
 *  can only be one evaluation job per model version.
 */
@property(nonatomic, copy, nullable) NSString *modelVersion;

/**
 *  Output only. After you create a job, Data Labeling Service assigns a name to
 *  the job with the following format: "projects/{project_id}/evaluationJobs/
 *  {evaluation_job_id}"
 */
@property(nonatomic, copy, nullable) NSString *name;

/**
 *  Required. Describes the interval at which the job runs. This interval must
 *  be at least 1 day, and it is rounded to the nearest day. For example, if you
 *  specify a 50-hour interval, the job runs every 2 days. You can provide the
 *  schedule in [crontab format](/scheduler/docs/configuring/cron-job-schedules)
 *  or in an [English-like
 *  format](/appengine/docs/standard/python/config/cronref#schedule_format).
 *  Regardless of what you specify, the job will run at 10:00 AM UTC. Only the
 *  interval from this schedule is used, not the specific time of day.
 */
@property(nonatomic, copy, nullable) NSString *schedule;

/**
 *  Output only. Describes the current state of the job.
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob_State_Paused
 *        The job is not sampling prediction input and output into your BigQuery
 *        table and it will not run according to its schedule. You can resume
 *        the job. (Value: "PAUSED")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob_State_Running
 *        The job is currently running. When the job runs, Data Labeling Service
 *        does several things: 1. If you have configured your job to use Data
 *        Labeling Service for ground truth labeling, the service creates a
 *        Dataset and a labeling task for all data sampled since the last time
 *        the job ran. Human labelers provide ground truth labels for your data.
 *        Human labeling may take hours, or even days, depending on how much
 *        data has been sampled. The job remains in the `RUNNING` state during
 *        this time, and it can even be running multiple times in parallel if it
 *        gets triggered again (for example 24 hours later) before the earlier
 *        run has completed. When human labelers have finished labeling the
 *        data, the next step occurs. If you have configured your job to provide
 *        your own ground truth labels, Data Labeling Service still creates a
 *        Dataset for newly sampled data, but it expects that you have already
 *        added ground truth labels to the BigQuery table by this time. The next
 *        step occurs immediately. 2. Data Labeling Service creates an
 *        Evaluation by comparing your model version's predictions with the
 *        ground truth labels. If the job remains in this state for a long time,
 *        it continues to sample prediction data into your BigQuery table and
 *        will run again at the next interval, even if it causes the job to run
 *        multiple times in parallel. (Value: "RUNNING")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob_State_Scheduled
 *        The job is scheduled to run at the configured interval. You can pause
 *        or delete the job. When the job is in this state, it samples
 *        prediction input and output from your model version into your BigQuery
 *        table as predictions occur. (Value: "SCHEDULED")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob_State_StateUnspecified
 *        Value "STATE_UNSPECIFIED"
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob_State_Stopped
 *        The job has this state right before it is deleted. (Value: "STOPPED")
 */
@property(nonatomic, copy, nullable) NSString *state;

@end


/**
 *  Provides details for how an evaluation job sends email alerts based on the
 *  results of a run.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJobAlertConfig : GTLRObject

/** Required. An email address to send alerts to. */
@property(nonatomic, copy, nullable) NSString *email;

/**
 *  Required. A number between 0 and 1 that describes a minimum mean average
 *  precision threshold. When the evaluation job runs, if it calculates that
 *  your model version's predictions from the recent interval have
 *  meanAveragePrecision below this threshold, then it sends an alert to your
 *  specified email.
 *
 *  Uses NSNumber of doubleValue.
 */
@property(nonatomic, strong, nullable) NSNumber *minAcceptableMeanAveragePrecision;

@end


/**
 *  Configures specific details of how a continuous evaluation job works.
 *  Provide this configuration when you create an EvaluationJob.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJobConfig : GTLRObject

/**
 *  Required. Prediction keys that tell Data Labeling Service where to find the
 *  data for evaluation in your BigQuery table. When the service samples
 *  prediction input and output from your model version and saves it to
 *  BigQuery, the data gets stored as JSON strings in the BigQuery table. These
 *  keys tell Data Labeling Service how to parse the JSON. You can provide the
 *  following entries in this field: * `data_json_key`: the data key for
 *  prediction input. You must provide either this key or `reference_json_key`.
 *  * `reference_json_key`: the data reference key for prediction input. You
 *  must provide either this key or `data_json_key`. * `label_json_key`: the
 *  label key for prediction output. Required. * `label_score_json_key`: the
 *  score key for prediction output. Required. * `bounding_box_json_key`: the
 *  bounding box key for prediction output. Required if your model version
 *  perform image object detection. Learn [how to configure prediction
 *  keys](/ml-engine/docs/continuous-evaluation/create-job#prediction-keys).
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJobConfig_BigqueryImportKeys *bigqueryImportKeys;

/**
 *  Specify this field if your model version performs image object detection
 *  (bounding box detection). `annotationSpecSet` in this configuration must
 *  match EvaluationJob.annotationSpecSet.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BoundingPolyConfig *boundingPolyConfig;

/**
 *  Required. Details for calculating evaluation metrics and creating
 *  Evaulations. If your model version performs image object detection, you must
 *  specify the `boundingBoxEvaluationOptions` field within this configuration.
 *  Otherwise, provide an empty object for this configuration.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationConfig *evaluationConfig;

/**
 *  Optional. Configuration details for evaluation job alerts. Specify this
 *  field if you want to receive email alerts if the evaluation job finds that
 *  your predictions have low mean average precision during a run.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJobAlertConfig *evaluationJobAlertConfig;

/**
 *  Required. The maximum number of predictions to sample and save to BigQuery
 *  during each evaluation interval. This limit overrides
 *  `example_sample_percentage`: even if the service has not sampled enough
 *  predictions to fulfill `example_sample_perecentage` during an interval, it
 *  stops sampling predictions when it meets this limit.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *exampleCount;

/**
 *  Required. Fraction of predictions to sample and save to BigQuery during each
 *  evaluation interval. For example, 0.1 means 10% of predictions served by
 *  your model version get saved to BigQuery.
 *
 *  Uses NSNumber of doubleValue.
 */
@property(nonatomic, strong, nullable) NSNumber *exampleSamplePercentage;

/**
 *  Optional. Details for human annotation of your data. If you set
 *  labelMissingGroundTruth to `true` for this evaluation job, then you must
 *  specify this field. If you plan to provide your own ground truth labels,
 *  then omit this field. Note that you must create an Instruction resource
 *  before you can specify this field. Provide the name of the instruction
 *  resource in the `instruction` field within this configuration.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *humanAnnotationConfig;

/**
 *  Specify this field if your model version performs image classification or
 *  general classification. `annotationSpecSet` in this configuration must match
 *  EvaluationJob.annotationSpecSet. `allowMultiLabel` in this configuration
 *  must match `classificationMetadata.isMultiLabel` in input_config.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig *imageClassificationConfig;

/**
 *  Rquired. Details for the sampled prediction input. Within this
 *  configuration, there are requirements for several fields: * `dataType` must
 *  be one of `IMAGE`, `TEXT`, or `GENERAL_DATA`. * `annotationType` must be one
 *  of `IMAGE_CLASSIFICATION_ANNOTATION`, `TEXT_CLASSIFICATION_ANNOTATION`,
 *  `GENERAL_CLASSIFICATION_ANNOTATION`, or `IMAGE_BOUNDING_BOX_ANNOTATION`
 *  (image object detection). * If your machine learning model performs
 *  classification, you must specify `classificationMetadata.isMultiLabel`. *
 *  You must specify `bigquerySource` (not `gcsSource`).
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig *inputConfig;

/**
 *  Specify this field if your model version performs text classification.
 *  `annotationSpecSet` in this configuration must match
 *  EvaluationJob.annotationSpecSet. `allowMultiLabel` in this configuration
 *  must match `classificationMetadata.isMultiLabel` in input_config.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextClassificationConfig *textClassificationConfig;

@end


/**
 *  Required. Prediction keys that tell Data Labeling Service where to find the
 *  data for evaluation in your BigQuery table. When the service samples
 *  prediction input and output from your model version and saves it to
 *  BigQuery, the data gets stored as JSON strings in the BigQuery table. These
 *  keys tell Data Labeling Service how to parse the JSON. You can provide the
 *  following entries in this field: * `data_json_key`: the data key for
 *  prediction input. You must provide either this key or `reference_json_key`.
 *  * `reference_json_key`: the data reference key for prediction input. You
 *  must provide either this key or `data_json_key`. * `label_json_key`: the
 *  label key for prediction output. Required. * `label_score_json_key`: the
 *  score key for prediction output. Required. * `bounding_box_json_key`: the
 *  bounding box key for prediction output. Required if your model version
 *  perform image object detection. Learn [how to configure prediction
 *  keys](/ml-engine/docs/continuous-evaluation/create-job#prediction-keys).
 *
 *  @note This class is documented as having more properties of NSString. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJobConfig_BigqueryImportKeys : GTLRObject
@end


/**
 *  GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationMetrics
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationMetrics : GTLRObject

@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ClassificationMetrics *classificationMetrics;
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectDetectionMetrics *objectDetectionMetrics;

@end


/**
 *  Config for video event human labeling task.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EventConfig : GTLRObject

/**
 *  Required. The list of annotation spec set resource name. Similar to video
 *  classification, we support selecting event from multiple AnnotationSpecSet
 *  at the same time.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *annotationSpecSets;

/**
 *  Videos will be cut to smaller clips to make it easier for labelers to work
 *  on. Users can configure is field in seconds, if not set, default value is
 *  60s.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *clipLength;

/**
 *  The overlap length between different video clips. Users can configure is
 *  field in seconds, if not set, default value is 1s.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *overlapLength;

@end


/**
 *  An Example is a piece of data and its annotation. For example, an image with
 *  label "house".
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Example : GTLRObject

/**
 *  Output only. Annotations for the piece of data in Example. One piece of data
 *  can have multiple annotations.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Annotation *> *annotations;

/** The image payload, a container of the image bytes/uri. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImagePayload *imagePayload;

/**
 *  Output only. Name of the example, in format of:
 *  projects/{project_id}/datasets/{dataset_id}/annotatedDatasets/
 *  {annotated_dataset_id}/examples/{example_id}
 */
@property(nonatomic, copy, nullable) NSString *name;

/** The text payload, a container of the text content. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextPayload *textPayload;

/** The video payload, a container of the video uri. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoPayload *videoPayload;

@end


/**
 *  Example comparisons comparing ground truth output and predictions for a
 *  specific input.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ExampleComparison : GTLRObject

/** The ground truth output for the input. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Example *groundTruthExample;

/** Predictions by the model for the input. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Example *> *modelCreatedExamples;

@end


/**
 *  Metadata of an ExportData operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ExportDataOperationMetadata : GTLRObject

/**
 *  Output only. The name of annotated dataset in format "projects/ * /datasets/
 *  * /annotatedDatasets/ *".
 */
@property(nonatomic, copy, nullable) NSString *annotatedDataset;

/** Output only. Timestamp when export dataset request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Output only. The name of dataset to be exported. "projects/ * /datasets/ *"
 */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Partial failures encountered. E.g. single files that couldn't
 *  be read. Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

@end


/**
 *  Response used for ExportDataset longrunning operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ExportDataOperationResponse : GTLRObject

/**
 *  Output only. The name of annotated dataset in format "projects/ * /datasets/
 *  * /annotatedDatasets/ *".
 */
@property(nonatomic, copy, nullable) NSString *annotatedDataset;

/** Ouptut only. The name of dataset. "projects/ * /datasets/ *" */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Number of examples exported successfully.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *exportCount;

/** Output only. Statistic infos of labels in the exported dataset. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelStats *labelStats;

/** Output only. output_config in the ExportData request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1OutputConfig *outputConfig;

/**
 *  Output only. Total number of examples requested to export
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *totalCount;

@end


/**
 *  Request message for ExportData API.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ExportDataRequest : GTLRObject

/**
 *  Required. Annotated dataset resource name. DataItem in Dataset and their
 *  annotations in specified annotated dataset will be exported. It's in format
 *  of projects/{project_id}/datasets/{dataset_id}/annotatedDatasets/
 *  {annotated_dataset_id}
 */
@property(nonatomic, copy, nullable) NSString *annotatedDataset;

/** Optional. Filter is not supported at this moment. */
@property(nonatomic, copy, nullable) NSString *filter;

/** Required. Specify the output destination. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1OutputConfig *outputConfig;

/**
 *  Email of the user who started the export task and should be notified by
 *  email. If empty no notification will be sent.
 */
@property(nonatomic, copy, nullable) NSString *userEmailAddress;

@end


/**
 *  A feedback message inside a feedback thread.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackMessage : GTLRObject

/** String content of the feedback. Maximum of 10000 characters. */
@property(nonatomic, copy, nullable) NSString *body;

/** Create time. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  The image storing this feedback if the feedback is an image representing
 *  operator's comments.
 *
 *  Contains encoded binary data; GTLRBase64 can encode/decode (probably
 *  web-safe format).
 */
@property(nonatomic, copy, nullable) NSString *image;

/**
 *  Name of the feedback message in a feedback thread. Format:
 *  'project/{project_id}/datasets/{dataset_id}/annotatedDatasets/{annotated_dataset_id}/feedbackThreads/{feedback_thread_id}/feedbackMessage/{feedback_message_id}'
 */
@property(nonatomic, copy, nullable) NSString *name;

@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1OperatorFeedbackMetadata *operatorFeedbackMetadata;
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1RequesterFeedbackMetadata *requesterFeedbackMetadata;

@end


/**
 *  A feedback thread of a certain labeling task on a certain annotated dataset.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThread : GTLRObject

/** Metadata regarding the feedback thread. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThreadMetadata *feedbackThreadMetadata;

/**
 *  Name of the feedback thread. Format:
 *  'project/{project_id}/datasets/{dataset_id}/annotatedDatasets/{annotated_dataset_id}/feedbackThreads/{feedback_thread_id}'
 */
@property(nonatomic, copy, nullable) NSString *name;

@end


/**
 *  GTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThreadMetadata
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThreadMetadata : GTLRObject

/** When the thread is created */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/** When the thread is last updated. */
@property(nonatomic, strong, nullable) GTLRDateTime *lastUpdateTime;

/**
 *  status
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThreadMetadata_Status_FeedbackThreadStatusUnspecified
 *        Value "FEEDBACK_THREAD_STATUS_UNSPECIFIED"
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThreadMetadata_Status_New
 *        Feedback thread is created with no reply; (Value: "NEW")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThreadMetadata_Status_Replied
 *        Feedback thread is replied at least once; (Value: "REPLIED")
 */
@property(nonatomic, copy, nullable) NSString *status;

/**
 *  An image thumbnail of this thread.
 *
 *  Contains encoded binary data; GTLRBase64 can encode/decode (probably
 *  web-safe format).
 */
@property(nonatomic, copy, nullable) NSString *thumbnail;

@end


/**
 *  Export destination of the data.Only gcs path is allowed in output_uri.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1GcsDestination : GTLRObject

/**
 *  Required. The format of the gcs destination. Only "text/csv" and
 *  "application/json" are supported.
 */
@property(nonatomic, copy, nullable) NSString *mimeType;

/** Required. The output uri of destination file. */
@property(nonatomic, copy, nullable) NSString *outputUri;

@end


/**
 *  Export folder destination of the data.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1GcsFolderDestination : GTLRObject

/** Required. Cloud Storage directory to export data to. */
@property(nonatomic, copy, nullable) NSString *outputFolderUri;

@end


/**
 *  Source of the Cloud Storage file to be imported.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1GcsSource : GTLRObject

/**
 *  Required. The input URI of source file. This must be a Cloud Storage path
 *  (`gs://...`).
 */
@property(nonatomic, copy, nullable) NSString *inputUri;

/** Required. The format of the source file. Only "text/csv" is supported. */
@property(nonatomic, copy, nullable) NSString *mimeType;

@end


/**
 *  Configuration for how human labeling task should be done.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig : GTLRObject

/**
 *  Optional. A human-readable description for AnnotatedDataset. The description
 *  can be up to 10000 characters long.
 */
@property(nonatomic, copy, nullable) NSString *annotatedDatasetDescription;

/**
 *  Required. A human-readable name for AnnotatedDataset defined by users.
 *  Maximum of 64 characters .
 */
@property(nonatomic, copy, nullable) NSString *annotatedDatasetDisplayName;

/**
 *  Optional. If you want your own labeling contributors to manage and work on
 *  this labeling request, you can set these contributors here. We will give
 *  them access to the question types in crowdcompute. Note that these emails
 *  must be registered in crowdcompute worker UI:
 *  https://crowd-compute.appspot.com/
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *contributorEmails;

/** Required. Instruction resource name. */
@property(nonatomic, copy, nullable) NSString *instruction;

/**
 *  Optional. A human-readable label used to logically group labeling tasks.
 *  This string must match the regular expression `[a-zA-Z\\\\d_-]{0,128}`.
 */
@property(nonatomic, copy, nullable) NSString *labelGroup;

/**
 *  Optional. The Language of this question, as a
 *  [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is
 *  en-US. Only need to set this when task is language related. For example,
 *  French text classification.
 */
@property(nonatomic, copy, nullable) NSString *languageCode;

/**
 *  Optional. Maximum duration for contributors to answer a question. Maximum is
 *  3600 seconds. Default is 3600 seconds.
 */
@property(nonatomic, strong, nullable) GTLRDuration *questionDuration;

/**
 *  Optional. Replication of questions. Each question will be sent to up to this
 *  number of contributors to label. Aggregated answers will be returned.
 *  Default is set to 1. For image related labeling, valid values are 1, 3, 5.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *replicaCount;

/**
 *  Email of the user who started the labeling task and should be notified by
 *  email. If empty no notification will be sent.
 */
@property(nonatomic, copy, nullable) NSString *userEmailAddress;

@end


/**
 *  Image bounding poly annotation. It represents a polygon including bounding
 *  box in the image.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageBoundingPolyAnnotation : GTLRObject

/** Label of object in this bounding polygon. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec *annotationSpec;

@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BoundingPoly *boundingPoly;
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1NormalizedBoundingPoly *normalizedBoundingPoly;

@end


/**
 *  Image classification annotation definition.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationAnnotation : GTLRObject

/** Label of image. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec *annotationSpec;

@end


/**
 *  Config for image classification human labeling task.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig : GTLRObject

/**
 *  Optional. If allow_multi_label is true, contributors are able to choose
 *  multiple labels for one image.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *allowMultiLabel;

/** Required. Annotation spec set resource name. */
@property(nonatomic, copy, nullable) NSString *annotationSpecSet;

/**
 *  Optional. The type of how to aggregate answers.
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig_AnswerAggregationType_MajorityVote
 *        Majority vote to aggregate answers. (Value: "MAJORITY_VOTE")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig_AnswerAggregationType_NoAggregation
 *        Preserve all answers by crowd compute. (Value: "NO_AGGREGATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig_AnswerAggregationType_StringAggregationTypeUnspecified
 *        Value "STRING_AGGREGATION_TYPE_UNSPECIFIED"
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig_AnswerAggregationType_UnanimousVote
 *        Unanimous answers will be adopted. (Value: "UNANIMOUS_VOTE")
 */
@property(nonatomic, copy, nullable) NSString *answerAggregationType;

@end


/**
 *  Container of information about an image.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImagePayload : GTLRObject

/**
 *  A byte string of a thumbnail image.
 *
 *  Contains encoded binary data; GTLRBase64 can encode/decode (probably
 *  web-safe format).
 */
@property(nonatomic, copy, nullable) NSString *imageThumbnail;

/** Image uri from the user bucket. */
@property(nonatomic, copy, nullable) NSString *imageUri;

/** Image format. */
@property(nonatomic, copy, nullable) NSString *mimeType;

/** Signed uri of the image file in the service bucket. */
@property(nonatomic, copy, nullable) NSString *signedUri;

@end


/**
 *  A polyline for the image annotation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImagePolylineAnnotation : GTLRObject

/** Label of this polyline. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec *annotationSpec;

@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1NormalizedPolyline *normalizedPolyline;
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Polyline *polyline;

@end


/**
 *  Image segmentation annotation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageSegmentationAnnotation : GTLRObject

/**
 *  The mapping between rgb color and annotation spec. The key is the rgb color
 *  represented in format of rgb(0, 0, 0). The value is the AnnotationSpec.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageSegmentationAnnotation_AnnotationColors *annotationColors;

/**
 *  A byte string of a full image's color map.
 *
 *  Contains encoded binary data; GTLRBase64 can encode/decode (probably
 *  web-safe format).
 */
@property(nonatomic, copy, nullable) NSString *imageBytes;

/** Image format. */
@property(nonatomic, copy, nullable) NSString *mimeType;

@end


/**
 *  The mapping between rgb color and annotation spec. The key is the rgb color
 *  represented in format of rgb(0, 0, 0). The value is the AnnotationSpec.
 *
 *  @note This class is documented as having more properties of
 *        GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec. Use @c
 *        -additionalJSONKeys and @c -additionalPropertyForName: to get the list
 *        of properties and then fetch them; or @c -additionalProperties to
 *        fetch them all at once.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageSegmentationAnnotation_AnnotationColors : GTLRObject
@end


/**
 *  Metadata of an ImportData operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImportDataOperationMetadata : GTLRObject

/** Output only. Timestamp when import dataset request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/** Output only. The name of imported dataset. "projects/ * /datasets/ *" */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Partial failures encountered. E.g. single files that couldn't
 *  be read. Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

@end


/**
 *  Response used for ImportData longrunning operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImportDataOperationResponse : GTLRObject

/** Ouptut only. The name of imported dataset. */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Number of examples imported successfully.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *importCount;

/**
 *  Output only. Total number of examples requested to import
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *totalCount;

@end


/**
 *  Request message for ImportData API.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImportDataRequest : GTLRObject

/** Required. Specify the input source of the data. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig *inputConfig;

/**
 *  Email of the user who started the import task and should be notified by
 *  email. If empty no notification will be sent.
 */
@property(nonatomic, copy, nullable) NSString *userEmailAddress;

@end


/**
 *  The configuration of input data, including data type, location, etc.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig : GTLRObject

/**
 *  Optional. The type of annotation to be performed on this data. You must
 *  specify this field if you are using this InputConfig in an EvaluationJob.
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_AnnotationTypeUnspecified
 *        Value "ANNOTATION_TYPE_UNSPECIFIED"
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_GeneralClassificationAnnotation
 *        General classification. Allowed for continuous evaluation. (Value:
 *        "GENERAL_CLASSIFICATION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_ImageBoundingBoxAnnotation
 *        Bounding box annotations in an image. A form of image object
 *        detection. Allowed for continuous evaluation. (Value:
 *        "IMAGE_BOUNDING_BOX_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_ImageBoundingPolyAnnotation
 *        Bounding poly annotations in an image. (Value:
 *        "IMAGE_BOUNDING_POLY_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_ImageClassificationAnnotation
 *        Classification annotations in an image. Allowed for continuous
 *        evaluation. (Value: "IMAGE_CLASSIFICATION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_ImageOrientedBoundingBoxAnnotation
 *        Oriented bounding box. The box does not have to be parallel to
 *        horizontal line. (Value: "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_ImagePolylineAnnotation
 *        Polyline annotations in an image. (Value: "IMAGE_POLYLINE_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_ImageSegmentationAnnotation
 *        Segmentation annotations in an image. (Value:
 *        "IMAGE_SEGMENTATION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_TextClassificationAnnotation
 *        Classification for text. Allowed for continuous evaluation. (Value:
 *        "TEXT_CLASSIFICATION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_TextEntityExtractionAnnotation
 *        Entity extraction for text. (Value:
 *        "TEXT_ENTITY_EXTRACTION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_VideoEventAnnotation
 *        Video event annotation. (Value: "VIDEO_EVENT_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_VideoObjectDetectionAnnotation
 *        Video object detection annotation. (Value:
 *        "VIDEO_OBJECT_DETECTION_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_VideoObjectTrackingAnnotation
 *        Video object tracking annotation. (Value:
 *        "VIDEO_OBJECT_TRACKING_ANNOTATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_AnnotationType_VideoShotsClassificationAnnotation
 *        Classification annotations in video shots. (Value:
 *        "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION")
 */
@property(nonatomic, copy, nullable) NSString *annotationType;

/**
 *  Source located in BigQuery. You must specify this field if you are using
 *  this InputConfig in an EvaluationJob.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BigQuerySource *bigquerySource;

/**
 *  Optional. Metadata about annotations for the input. You must specify this
 *  field if you are using this InputConfig in an EvaluationJob for a model
 *  version that performs classification.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ClassificationMetadata *classificationMetadata;

/**
 *  Required. Data type must be specifed when user tries to import data.
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_DataType_DataTypeUnspecified
 *        Data type is unspecified. (Value: "DATA_TYPE_UNSPECIFIED")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_DataType_GeneralData
 *        Allowed for continuous evaluation. (Value: "GENERAL_DATA")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_DataType_Image
 *        Allowed for continuous evaluation. (Value: "IMAGE")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_DataType_Text
 *        Allowed for continuous evaluation. (Value: "TEXT")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1InputConfig_DataType_Video
 *        Video data type. (Value: "VIDEO")
 */
@property(nonatomic, copy, nullable) NSString *dataType;

/** Source located in Cloud Storage. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1GcsSource *gcsSource;

/** Required for text import, as language code must be specified. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextMetadata *textMetadata;

@end


/**
 *  Instruction of how to perform the labeling task for human operators.
 *  Currently only PDF instruction is supported.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction : GTLRObject

/**
 *  Output only. The names of any related resources that are blocking changes to
 *  the instruction.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *blockingResources;

/** Output only. Creation time of instruction. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Deprecated: this instruction format is not supported any more. Instruction
 *  from a CSV file, such as for classification task. The CSV file should have
 *  exact two columns, in the following format: * The first column is labeled
 *  data, such as an image reference, text. * The second column is comma
 *  separated labels associated with data.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1CsvInstruction *csvInstruction GTLR_DEPRECATED;

/**
 *  Required. The data type of this instruction.
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction_DataType_DataTypeUnspecified
 *        Data type is unspecified. (Value: "DATA_TYPE_UNSPECIFIED")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction_DataType_GeneralData
 *        Allowed for continuous evaluation. (Value: "GENERAL_DATA")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction_DataType_Image
 *        Allowed for continuous evaluation. (Value: "IMAGE")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction_DataType_Text
 *        Allowed for continuous evaluation. (Value: "TEXT")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction_DataType_Video
 *        Video data type. (Value: "VIDEO")
 */
@property(nonatomic, copy, nullable) NSString *dataType;

/**
 *  Optional. User-provided description of the instruction. The description can
 *  be up to 10000 characters long.
 *
 *  Remapped to 'descriptionProperty' to avoid NSObject's 'description'.
 */
@property(nonatomic, copy, nullable) NSString *descriptionProperty;

/**
 *  Required. The display name of the instruction. Maximum of 64 characters.
 */
@property(nonatomic, copy, nullable) NSString *displayName;

/**
 *  Output only. Instruction resource name, format:
 *  projects/{project_id}/instructions/{instruction_id}
 */
@property(nonatomic, copy, nullable) NSString *name;

/**
 *  Instruction from a PDF document. The PDF should be in a Cloud Storage
 *  bucket.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1PdfInstruction *pdfInstruction;

/** Output only. Last update time of instruction. */
@property(nonatomic, strong, nullable) GTLRDateTime *updateTime;

@end


/**
 *  Details of a LabelImageBoundingBox operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageBoundingBoxOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of LabelImageBoundingPoly operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageBoundingPolyOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Metadata of a LabelImageClassification operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageClassificationOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelImageOrientedBoundingBox operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageOrientedBoundingBoxOperationMetadata : GTLRObject

/** Basic human annotation config. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of LabelImagePolyline operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImagePolylineOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Request message for starting an image labeling task.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest : GTLRObject

/** Required. Basic human annotation config. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

/**
 *  Configuration for bounding box and bounding poly task. One of
 *  image_classification_config, bounding_poly_config, polyline_config and
 *  segmentation_config are required.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BoundingPolyConfig *boundingPolyConfig;

/**
 *  Required. The type of image labeling task.
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_BoundingBox
 *        Label image with bounding boxes for labels. (Value: "BOUNDING_BOX")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_BoundingPoly
 *        Label images with bounding poly. A bounding poly is a plane figure
 *        that is bounded by a finite chain of straight line segments closing in
 *        a loop. (Value: "BOUNDING_POLY")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_Classification
 *        Label whole image with one or more of labels. (Value:
 *        "CLASSIFICATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_FeatureUnspecified
 *        Value "FEATURE_UNSPECIFIED"
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_OrientedBoundingBox
 *        Label oriented bounding box. The box does not have to be parallel to
 *        horizontal line. (Value: "ORIENTED_BOUNDING_BOX")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_Polyline
 *        Label images with polyline. Polyline is formed by connected line
 *        segments which are not in closed form. (Value: "POLYLINE")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageRequest_Feature_Segmentation
 *        Label images with segmentation. Segmentation is different from
 *        bounding poly since it is more fine-grained, pixel level annotation.
 *        (Value: "SEGMENTATION")
 */
@property(nonatomic, copy, nullable) NSString *feature;

/**
 *  Configuration for image classification task. One of
 *  image_classification_config, bounding_poly_config, polyline_config and
 *  segmentation_config are required.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ImageClassificationConfig *imageClassificationConfig;

/**
 *  Configuration for polyline task. One of image_classification_config,
 *  bounding_poly_config, polyline_config and segmentation_config are required.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1PolylineConfig *polylineConfig;

/**
 *  Configuration for segmentation task. One of image_classification_config,
 *  bounding_poly_config, polyline_config and segmentation_config are required.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1SegmentationConfig *segmentationConfig;

@end


/**
 *  Details of a LabelImageSegmentation operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageSegmentationOperationMetadata : GTLRObject

/** Basic human annotation config. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Metadata of a labeling operation, such as LabelImage or LabelVideo. Next
 *  tag: 23
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelOperationMetadata : GTLRObject

/**
 *  Output only. The name of annotated dataset in format "projects/ * /datasets/
 *  * /annotatedDatasets/ *".
 */
@property(nonatomic, copy, nullable) NSString *annotatedDataset;

/** Output only. Timestamp when labeling request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Output only. The name of dataset to be labeled. "projects/ * /datasets/ *"
 */
@property(nonatomic, copy, nullable) NSString *dataset;

/** Details of label image bounding box operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageBoundingBoxOperationMetadata *imageBoundingBoxDetails;

/** Details of label image bounding poly operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageBoundingPolyOperationMetadata *imageBoundingPolyDetails;

/** Details of label image classification operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageClassificationOperationMetadata *imageClassificationDetails;

/** Details of label image oriented bounding box operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageOrientedBoundingBoxOperationMetadata *imageOrientedBoundingBoxDetails;

/** Details of label image polyline operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImagePolylineOperationMetadata *imagePolylineDetails;

/** Details of label image segmentation operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelImageSegmentationOperationMetadata *imageSegmentationDetails;

/**
 *  Output only. Partial failures encountered. E.g. single files that couldn't
 *  be read. Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

/**
 *  Output only. Progress of label operation. Range: [0, 100].
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *progressPercent;

/** Details of label text classification operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextClassificationOperationMetadata *textClassificationDetails;

/** Details of label text entity extraction operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextEntityExtractionOperationMetadata *textEntityExtractionDetails;

/** Details of label video classification operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoClassificationOperationMetadata *videoClassificationDetails;

/** Details of label video event operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoEventOperationMetadata *videoEventDetails;

/** Details of label video object detection operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoObjectDetectionOperationMetadata *videoObjectDetectionDetails;

/** Details of label video object tracking operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoObjectTrackingOperationMetadata *videoObjectTrackingDetails;

@end


/**
 *  Statistics about annotation specs.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelStats : GTLRObject

/**
 *  Map of each annotation spec's example count. Key is the annotation spec name
 *  and value is the number of examples for that annotation spec. If the
 *  annotated dataset does not have annotation spec, the map will return a pair
 *  where the key is empty string and value is the total number of annotations.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelStats_ExampleCount *exampleCount;

@end


/**
 *  Map of each annotation spec's example count. Key is the annotation spec name
 *  and value is the number of examples for that annotation spec. If the
 *  annotated dataset does not have annotation spec, the map will return a pair
 *  where the key is empty string and value is the total number of annotations.
 *
 *  @note This class is documented as having more properties of NSNumber (Uses
 *        NSNumber of longLongValue.). Use @c -additionalJSONKeys and @c
 *        -additionalPropertyForName: to get the list of properties and then
 *        fetch them; or @c -additionalProperties to fetch them all at once.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelStats_ExampleCount : GTLRObject
@end


/**
 *  Details of a LabelTextClassification operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextClassificationOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelTextEntityExtraction operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextEntityExtractionOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Request message for LabelText.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextRequest : GTLRObject

/** Required. Basic human annotation config. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

/**
 *  Required. The type of text labeling task.
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextRequest_Feature_FeatureUnspecified
 *        Value "FEATURE_UNSPECIFIED"
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextRequest_Feature_TextClassification
 *        Label text content to one of more labels. (Value:
 *        "TEXT_CLASSIFICATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelTextRequest_Feature_TextEntityExtraction
 *        Label entities and their span in text. (Value:
 *        "TEXT_ENTITY_EXTRACTION")
 */
@property(nonatomic, copy, nullable) NSString *feature;

/**
 *  Configuration for text classification task. One of
 *  text_classification_config and text_entity_extraction_config is required.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextClassificationConfig *textClassificationConfig;

/**
 *  Configuration for entity extraction task. One of text_classification_config
 *  and text_entity_extraction_config is required.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextEntityExtractionConfig *textEntityExtractionConfig;

@end


/**
 *  Details of a LabelVideoClassification operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoClassificationOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoEvent operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoEventOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoObjectDetection operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoObjectDetectionOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoObjectTracking operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoObjectTrackingOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Request message for LabelVideo.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoRequest : GTLRObject

/** Required. Basic human annotation config. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1HumanAnnotationConfig *basicConfig;

/**
 *  Configuration for video event task. One of video_classification_config,
 *  object_detection_config, object_tracking_config and event_config is
 *  required.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EventConfig *eventConfig;

/**
 *  Required. The type of video labeling task.
 *
 *  Likely values:
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoRequest_Feature_Classification
 *        Label whole video or video segment with one or more labels. (Value:
 *        "CLASSIFICATION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoRequest_Feature_Event
 *        Label the range of video for the specified events. (Value: "EVENT")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoRequest_Feature_FeatureUnspecified
 *        Value "FEATURE_UNSPECIFIED"
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoRequest_Feature_ObjectDetection
 *        Label objects with bounding box on image frames extracted from the
 *        video. (Value: "OBJECT_DETECTION")
 *    @arg @c kGTLRDataLabeling_GoogleCloudDatalabelingV1beta1LabelVideoRequest_Feature_ObjectTracking
 *        Label and track objects in video. (Value: "OBJECT_TRACKING")
 */
@property(nonatomic, copy, nullable) NSString *feature;

/**
 *  Configuration for video object detection task. One of
 *  video_classification_config, object_detection_config, object_tracking_config
 *  and event_config is required.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectDetectionConfig *objectDetectionConfig;

/**
 *  Configuration for video object tracking task. One of
 *  video_classification_config, object_detection_config, object_tracking_config
 *  and event_config is required.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectTrackingConfig *objectTrackingConfig;

/**
 *  Configuration for video classification task. One of
 *  video_classification_config, object_detection_config, object_tracking_config
 *  and event_config is required.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoClassificationConfig *videoClassificationConfig;

@end


/**
 *  Results of listing annotated datasets for a dataset.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "annotatedDatasets" property. If returned as the result of a
 *        query, it should support automatic pagination (when @c
 *        shouldFetchNextPages is enabled).
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ListAnnotatedDatasetsResponse : GTLRCollectionObject

/**
 *  The list of annotated datasets to return.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotatedDataset *> *annotatedDatasets;

/** A token to retrieve next page of results. */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  Results of listing annotation spec set under a project.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "annotationSpecSets" property. If returned as the result of a
 *        query, it should support automatic pagination (when @c
 *        shouldFetchNextPages is enabled).
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ListAnnotationSpecSetsResponse : GTLRCollectionObject

/**
 *  The list of annotation spec sets.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpecSet *> *annotationSpecSets;

/** A token to retrieve next page of results. */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  Results of listing data items in a dataset.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "dataItems" property. If returned as the result of a query, it
 *        should support automatic pagination (when @c shouldFetchNextPages is
 *        enabled).
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ListDataItemsResponse : GTLRCollectionObject

/**
 *  The list of data items to return.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1DataItem *> *dataItems;

/** A token to retrieve next page of results. */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  Results of listing datasets within a project.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "datasets" property. If returned as the result of a query, it
 *        should support automatic pagination (when @c shouldFetchNextPages is
 *        enabled).
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ListDatasetsResponse : GTLRCollectionObject

/**
 *  The list of datasets to return.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Dataset *> *datasets;

/** A token to retrieve next page of results. */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  Results for listing evaluation jobs.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "evaluationJobs" property. If returned as the result of a query,
 *        it should support automatic pagination (when @c shouldFetchNextPages
 *        is enabled).
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ListEvaluationJobsResponse : GTLRCollectionObject

/**
 *  The list of evaluation jobs to return.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1EvaluationJob *> *evaluationJobs;

/** A token to retrieve next page of results. */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  Results of listing Examples in and annotated dataset.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "examples" property. If returned as the result of a query, it
 *        should support automatic pagination (when @c shouldFetchNextPages is
 *        enabled).
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ListExamplesResponse : GTLRCollectionObject

/**
 *  The list of examples to return.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Example *> *examples;

/** A token to retrieve next page of results. */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  Results for listing FeedbackMessages.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "feedbackMessages" property. If returned as the result of a query,
 *        it should support automatic pagination (when @c shouldFetchNextPages
 *        is enabled).
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ListFeedbackMessagesResponse : GTLRCollectionObject

/**
 *  The list of feedback messages to return.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackMessage *> *feedbackMessages;

/** A token to retrieve next page of results. */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  Results for listing FeedbackThreads.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "feedbackThreads" property. If returned as the result of a query,
 *        it should support automatic pagination (when @c shouldFetchNextPages
 *        is enabled).
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ListFeedbackThreadsResponse : GTLRCollectionObject

/**
 *  The list of feedback threads to return.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1FeedbackThread *> *feedbackThreads;

/** A token to retrieve next page of results. */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  Results of listing instructions under a project.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "instructions" property. If returned as the result of a query, it
 *        should support automatic pagination (when @c shouldFetchNextPages is
 *        enabled).
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ListInstructionsResponse : GTLRCollectionObject

/**
 *  The list of Instructions to return.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Instruction *> *instructions;

/** A token to retrieve next page of results. */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  Normalized bounding polygon.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1NormalizedBoundingPoly : GTLRObject

/** The bounding polygon normalized vertices. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1NormalizedVertex *> *normalizedVertices;

@end


/**
 *  Normalized polyline.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1NormalizedPolyline : GTLRObject

/** The normalized polyline vertices. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1NormalizedVertex *> *normalizedVertices;

@end


/**
 *  A vertex represents a 2D point in the image. NOTE: the normalized vertex
 *  coordinates are relative to the original image and range from 0 to 1.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1NormalizedVertex : GTLRObject

/**
 *  X coordinate.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *x;

/**
 *  Y coordinate.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *y;

@end


/**
 *  Config for video object detection human labeling task. Object detection will
 *  be conducted on the images extracted from the video, and those objects will
 *  be labeled with bounding boxes. User need to specify the number of images to
 *  be extracted per second as the extraction frame rate.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectDetectionConfig : GTLRObject

/** Required. Annotation spec set resource name. */
@property(nonatomic, copy, nullable) NSString *annotationSpecSet;

/**
 *  Required. Number of frames per second to be extracted from the video.
 *
 *  Uses NSNumber of doubleValue.
 */
@property(nonatomic, strong, nullable) NSNumber *extractionFrameRate;

@end


/**
 *  Metrics calculated for an image object detection (bounding box) model.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectDetectionMetrics : GTLRObject

/** Precision-recall curve. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1PrCurve *prCurve;

@end


/**
 *  Config for video object tracking human labeling task.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectTrackingConfig : GTLRObject

/** Required. Annotation spec set resource name. */
@property(nonatomic, copy, nullable) NSString *annotationSpecSet;

/**
 *  Videos will be cut to smaller clips to make it easier for labelers to work
 *  on. Users can configure is field in seconds, if not set, default value is
 *  20s.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *clipLength;

/**
 *  The overlap length between different video clips. Users can configure is
 *  field in seconds, if not set, default value is 0.3s.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *overlapLength;

@end


/**
 *  Video frame level annotation for object detection and tracking.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectTrackingFrame : GTLRObject

@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1BoundingPoly *boundingPoly;
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1NormalizedBoundingPoly *normalizedBoundingPoly;

/** The time offset of this frame relative to the beginning of the video. */
@property(nonatomic, strong, nullable) GTLRDuration *timeOffset;

@end


/**
 *  Metadata describing the feedback from the operator.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1OperatorFeedbackMetadata : GTLRObject
@end


/**
 *  General information useful for labels coming from contributors.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1OperatorMetadata : GTLRObject

/** Comments from contributors. */
@property(nonatomic, strong, nullable) NSArray<NSString *> *comments;

/**
 *  The total number of contributors that choose this label.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *labelVotes;

/**
 *  Confidence score corresponding to a label. For examle, if 3 contributors
 *  have answered the question and 2 of them agree on the final label, the
 *  confidence score will be 0.67 (2/3).
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *score;

/**
 *  The total number of contributors that answer this question.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *totalVotes;

@end


/**
 *  The configuration of output data.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1OutputConfig : GTLRObject

/**
 *  Output to a file in Cloud Storage. Should be used for labeling output other
 *  than image segmentation.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1GcsDestination *gcsDestination;

/**
 *  Output to a folder in Cloud Storage. Should be used for image segmentation
 *  or document de-identification labeling outputs.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1GcsFolderDestination *gcsFolderDestination;

@end


/**
 *  Request message for PauseEvaluationJob.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1PauseEvaluationJobRequest : GTLRObject
@end


/**
 *  Instruction from a PDF file.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1PdfInstruction : GTLRObject

/** PDF file for the instruction. Only gcs path is allowed. */
@property(nonatomic, copy, nullable) NSString *gcsFileUri;

@end


/**
 *  A line with multiple line segments.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Polyline : GTLRObject

/** The polyline vertices. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Vertex *> *vertices;

@end


/**
 *  Config for image polyline human labeling task.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1PolylineConfig : GTLRObject

/** Required. Annotation spec set resource name. */
@property(nonatomic, copy, nullable) NSString *annotationSpecSet;

/** Optional. Instruction message showed on contributors UI. */
@property(nonatomic, copy, nullable) NSString *instructionMessage;

@end


/**
 *  GTLRDataLabeling_GoogleCloudDatalabelingV1beta1PrCurve
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1PrCurve : GTLRObject

/**
 *  The annotation spec of the label for which the precision-recall curve
 *  calculated. If this field is empty, that means the precision-recall curve is
 *  an aggregate curve for all labels.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec *annotationSpec;

/**
 *  Area under the precision-recall curve. Not to be confused with area under a
 *  receiver operating characteristic (ROC) curve.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *areaUnderCurve;

/**
 *  Entries that make up the precision-recall graph. Each entry is a "point" on
 *  the graph drawn for a different `confidence_threshold`.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ConfidenceMetricsEntry *> *confidenceMetricsEntries;

/**
 *  Mean average prcision of this curve.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *meanAveragePrecision;

@end


/**
 *  Metadata describing the feedback from the labeling task requester.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1RequesterFeedbackMetadata : GTLRObject
@end


/**
 *  Request message ResumeEvaluationJob.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ResumeEvaluationJobRequest : GTLRObject
@end


/**
 *  A row in the confusion matrix. Each entry in this row has the same ground
 *  truth label.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Row : GTLRObject

/** The annotation spec of the ground truth label for this row. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec *annotationSpec;

/**
 *  A list of the confusion matrix entries. One entry for each possible
 *  predicted label.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ConfusionMatrixEntry *> *entries;

@end


/**
 *  Results of searching evaluations.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "evaluations" property. If returned as the result of a query, it
 *        should support automatic pagination (when @c shouldFetchNextPages is
 *        enabled).
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1SearchEvaluationsResponse : GTLRCollectionObject

/**
 *  The list of evaluations matching the search.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Evaluation *> *evaluations;

/** A token to retrieve next page of results. */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  Request message of SearchExampleComparisons.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1SearchExampleComparisonsRequest : GTLRObject

/**
 *  Optional. Requested page size. Server may return fewer results than
 *  requested. Default value is 100.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *pageSize;

/**
 *  Optional. A token identifying a page of results for the server to return.
 *  Typically obtained by the nextPageToken of the response to a previous search
 *  rquest. If you don't specify this field, the API call requests the first
 *  page of the search.
 */
@property(nonatomic, copy, nullable) NSString *pageToken;

@end


/**
 *  Results of searching example comparisons.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "exampleComparisons" property. If returned as the result of a
 *        query, it should support automatic pagination (when @c
 *        shouldFetchNextPages is enabled).
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1SearchExampleComparisonsResponse : GTLRCollectionObject

/**
 *  A list of example comparisons matching the search criteria.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ExampleComparison *> *exampleComparisons;

/** A token to retrieve next page of results. */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

@end


/**
 *  Config for image segmentation
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1SegmentationConfig : GTLRObject

/**
 *  Required. Annotation spec set resource name. format:
 *  projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}
 */
@property(nonatomic, copy, nullable) NSString *annotationSpecSet;

/** Instruction message showed on labelers UI. */
@property(nonatomic, copy, nullable) NSString *instructionMessage;

@end


/**
 *  Config for setting up sentiments.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1SentimentConfig : GTLRObject

/**
 *  If set to true, contributors will have the option to select sentiment of the
 *  label they selected, to mark it as negative or positive label. Default is
 *  false.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *enableLabelSentimentSelection;

@end


/**
 *  Start and end position in a sequence (e.g. text segment).
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1SequentialSegment : GTLRObject

/**
 *  End position (exclusive).
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *end;

/**
 *  Start position (inclusive).
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *start;

@end


/**
 *  Text classification annotation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextClassificationAnnotation : GTLRObject

/** Label of the text. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec *annotationSpec;

@end


/**
 *  Config for text classification human labeling task.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextClassificationConfig : GTLRObject

/**
 *  Optional. If allow_multi_label is true, contributors are able to choose
 *  multiple labels for one text segment.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *allowMultiLabel;

/** Required. Annotation spec set resource name. */
@property(nonatomic, copy, nullable) NSString *annotationSpecSet;

/**
 *  Optional. Configs for sentiment selection. We deprecate sentiment analysis
 *  in data labeling side as it is incompatible with uCAIP.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1SentimentConfig *sentimentConfig GTLR_DEPRECATED;

@end


/**
 *  Text entity extraction annotation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextEntityExtractionAnnotation : GTLRObject

/** Label of the text entities. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec *annotationSpec;

/** Position of the entity. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1SequentialSegment *sequentialSegment;

@end


/**
 *  Config for text entity extraction human labeling task.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextEntityExtractionConfig : GTLRObject

/** Required. Annotation spec set resource name. */
@property(nonatomic, copy, nullable) NSString *annotationSpecSet;

@end


/**
 *  Metadata for the text.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextMetadata : GTLRObject

/**
 *  The language of this text, as a
 *  [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is
 *  en-US.
 */
@property(nonatomic, copy, nullable) NSString *languageCode;

@end


/**
 *  Container of information about a piece of text.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TextPayload : GTLRObject

/** Text content. */
@property(nonatomic, copy, nullable) NSString *textContent;

@end


/**
 *  A time period inside of an example that has a time dimension (e.g. video).
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TimeSegment : GTLRObject

/**
 *  End of the time segment (exclusive), represented as the duration since the
 *  example start.
 */
@property(nonatomic, strong, nullable) GTLRDuration *endTimeOffset;

/**
 *  Start of the time segment (inclusive), represented as the duration since the
 *  example start.
 */
@property(nonatomic, strong, nullable) GTLRDuration *startTimeOffset;

@end


/**
 *  A vertex represents a 2D point in the image. NOTE: the vertex coordinates
 *  are in the same scale as the original image.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1Vertex : GTLRObject

/**
 *  X coordinate.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *x;

/**
 *  Y coordinate.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *y;

@end


/**
 *  Video classification annotation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoClassificationAnnotation : GTLRObject

/** Label of the segment specified by time_segment. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec *annotationSpec;

/** The time segment of the video to which the annotation applies. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TimeSegment *timeSegment;

@end


/**
 *  Config for video classification human labeling task. Currently two types of
 *  video classification are supported: 1. Assign labels on the entire video. 2.
 *  Split the video into multiple video clips based on camera shot, and assign
 *  labels on each video clip.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoClassificationConfig : GTLRObject

/**
 *  Required. The list of annotation spec set configs. Since watching a video
 *  clip takes much longer time than an image, we support label with multiple
 *  AnnotationSpecSet at the same time. Labels in each AnnotationSpecSet will be
 *  shown in a group to contributors. Contributors can select one or more
 *  (depending on whether to allow multi label) from each group.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpecSetConfig *> *annotationSpecSetConfigs;

/**
 *  Optional. Option to apply shot detection on the video.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *applyShotDetection;

@end


/**
 *  Video event annotation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoEventAnnotation : GTLRObject

/** Label of the event in this annotation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec *annotationSpec;

/** The time segment of the video to which the annotation applies. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TimeSegment *timeSegment;

@end


/**
 *  Video object tracking annotation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoObjectTrackingAnnotation : GTLRObject

/** Label of the object tracked in this annotation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1AnnotationSpec *annotationSpec;

/** The list of frames where this object track appears. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1ObjectTrackingFrame *> *objectTrackingFrames;

/** The time segment of the video to which object tracking applies. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1beta1TimeSegment *timeSegment;

@end


/**
 *  Container of information of a video.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoPayload : GTLRObject

/**
 *  FPS of the video.
 *
 *  Uses NSNumber of floatValue.
 */
@property(nonatomic, strong, nullable) NSNumber *frameRate;

/** Video format. */
@property(nonatomic, copy, nullable) NSString *mimeType;

/** Signed uri of the video file in the service bucket. */
@property(nonatomic, copy, nullable) NSString *signedUri;

/** The list of video thumbnails. */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoThumbnail *> *videoThumbnails;

/** Video uri from the user bucket. */
@property(nonatomic, copy, nullable) NSString *videoUri;

@end


/**
 *  Container of information of a video thumbnail.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1beta1VideoThumbnail : GTLRObject

/**
 *  A byte string of the video frame.
 *
 *  Contains encoded binary data; GTLRBase64 can encode/decode (probably
 *  web-safe format).
 */
@property(nonatomic, copy, nullable) NSString *thumbnail;

/**
 *  Time offset relative to the beginning of the video, corresponding to the
 *  video frame where the thumbnail has been extracted from.
 */
@property(nonatomic, strong, nullable) GTLRDuration *timeOffset;

@end


/**
 *  Metadata of a CreateInstruction operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1CreateInstructionMetadata : GTLRObject

/** Timestamp when create instruction request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  The name of the created Instruction.
 *  projects/{project_id}/instructions/{instruction_id}
 */
@property(nonatomic, copy, nullable) NSString *instruction;

/**
 *  Partial failures encountered. E.g. single files that couldn't be read.
 *  Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

@end


/**
 *  Metadata of an ExportData operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1ExportDataOperationMetadata : GTLRObject

/**
 *  Output only. The name of annotated dataset in format "projects/ * /datasets/
 *  * /annotatedDatasets/ *".
 */
@property(nonatomic, copy, nullable) NSString *annotatedDataset;

/** Output only. Timestamp when export dataset request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Output only. The name of dataset to be exported. "projects/ * /datasets/ *"
 */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Partial failures encountered. E.g. single files that couldn't
 *  be read. Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

@end


/**
 *  Response used for ExportDataset longrunning operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1ExportDataOperationResponse : GTLRObject

/**
 *  Output only. The name of annotated dataset in format "projects/ * /datasets/
 *  * /annotatedDatasets/ *".
 */
@property(nonatomic, copy, nullable) NSString *annotatedDataset;

/** Ouptut only. The name of dataset. "projects/ * /datasets/ *" */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Number of examples exported successfully.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *exportCount;

/** Output only. Statistic infos of labels in the exported dataset. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelStats *labelStats;

/** Output only. output_config in the ExportData request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1OutputConfig *outputConfig;

/**
 *  Output only. Total number of examples requested to export
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *totalCount;

@end


/**
 *  Export destination of the data.Only gcs path is allowed in output_uri.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1GcsDestination : GTLRObject

/**
 *  Required. The format of the gcs destination. Only "text/csv" and
 *  "application/json" are supported.
 */
@property(nonatomic, copy, nullable) NSString *mimeType;

/** Required. The output uri of destination file. */
@property(nonatomic, copy, nullable) NSString *outputUri;

@end


/**
 *  Export folder destination of the data.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1GcsFolderDestination : GTLRObject

/** Required. Cloud Storage directory to export data to. */
@property(nonatomic, copy, nullable) NSString *outputFolderUri;

@end


/**
 *  Metadata of an GenerateAnalysisReport operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1GenerateAnalysisReportOperationMetadata : GTLRObject

/** Timestamp when generate report request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  The name of the dataset for which the analysis report is generated. Format:
 *  "projects/ * /datasets/ *"
 */
@property(nonatomic, copy, nullable) NSString *dataset;

@end


/**
 *  Configuration for how human labeling task should be done.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig : GTLRObject

/**
 *  Optional. A human-readable description for AnnotatedDataset. The description
 *  can be up to 10000 characters long.
 */
@property(nonatomic, copy, nullable) NSString *annotatedDatasetDescription;

/**
 *  Required. A human-readable name for AnnotatedDataset defined by users.
 *  Maximum of 64 characters .
 */
@property(nonatomic, copy, nullable) NSString *annotatedDatasetDisplayName;

/**
 *  Optional. If you want your own labeling contributors to manage and work on
 *  this labeling request, you can set these contributors here. We will give
 *  them access to the question types in crowdcompute. Note that these emails
 *  must be registered in crowdcompute worker UI:
 *  https://crowd-compute.appspot.com/
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *contributorEmails;

/** Required. Instruction resource name. */
@property(nonatomic, copy, nullable) NSString *instruction;

/**
 *  Optional. A human-readable label used to logically group labeling tasks.
 *  This string must match the regular expression `[a-zA-Z\\\\d_-]{0,128}`.
 */
@property(nonatomic, copy, nullable) NSString *labelGroup;

/**
 *  Optional. The Language of this question, as a
 *  [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is
 *  en-US. Only need to set this when task is language related. For example,
 *  French text classification.
 */
@property(nonatomic, copy, nullable) NSString *languageCode;

/**
 *  Optional. Maximum duration for contributors to answer a question. Maximum is
 *  3600 seconds. Default is 3600 seconds.
 */
@property(nonatomic, strong, nullable) GTLRDuration *questionDuration;

/**
 *  Optional. Replication of questions. Each question will be sent to up to this
 *  number of contributors to label. Aggregated answers will be returned.
 *  Default is set to 1. For image related labeling, valid values are 1, 3, 5.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *replicaCount;

/**
 *  Email of the user who started the labeling task and should be notified by
 *  email. If empty no notification will be sent.
 */
@property(nonatomic, copy, nullable) NSString *userEmailAddress;

@end


/**
 *  Metadata of an ImportData operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1ImportDataOperationMetadata : GTLRObject

/** Output only. Timestamp when import dataset request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/** Output only. The name of imported dataset. "projects/ * /datasets/ *" */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Partial failures encountered. E.g. single files that couldn't
 *  be read. Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

@end


/**
 *  Response used for ImportData longrunning operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1ImportDataOperationResponse : GTLRObject

/** Ouptut only. The name of imported dataset. */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Number of examples imported successfully.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *importCount;

/**
 *  Output only. Total number of examples requested to import
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *totalCount;

@end


/**
 *  Details of a LabelImageBoundingBox operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageBoundingBoxOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of LabelImageBoundingPoly operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageBoundingPolyOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Metadata of a LabelImageClassification operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageClassificationOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelImageOrientedBoundingBox operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageOrientedBoundingBoxOperationMetadata : GTLRObject

/** Basic human annotation config. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of LabelImagePolyline operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImagePolylineOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelImageSegmentation operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageSegmentationOperationMetadata : GTLRObject

/** Basic human annotation config. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Metadata of a labeling operation, such as LabelImage or LabelVideo. Next
 *  tag: 23
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelOperationMetadata : GTLRObject

/**
 *  Output only. The name of annotated dataset in format "projects/ * /datasets/
 *  * /annotatedDatasets/ *".
 */
@property(nonatomic, copy, nullable) NSString *annotatedDataset;

/** Output only. Timestamp when labeling request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Output only. The name of dataset to be labeled. "projects/ * /datasets/ *"
 */
@property(nonatomic, copy, nullable) NSString *dataset;

/** Details of label image bounding box operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageBoundingBoxOperationMetadata *imageBoundingBoxDetails;

/** Details of label image bounding poly operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageBoundingPolyOperationMetadata *imageBoundingPolyDetails;

/** Details of label image classification operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageClassificationOperationMetadata *imageClassificationDetails;

/** Details of label image oriented bounding box operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageOrientedBoundingBoxOperationMetadata *imageOrientedBoundingBoxDetails;

/** Details of label image polyline operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImagePolylineOperationMetadata *imagePolylineDetails;

/** Details of label image segmentation operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelImageSegmentationOperationMetadata *imageSegmentationDetails;

/**
 *  Output only. Partial failures encountered. E.g. single files that couldn't
 *  be read. Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

/**
 *  Output only. Progress of label operation. Range: [0, 100].
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *progressPercent;

/** Details of label text classification operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelTextClassificationOperationMetadata *textClassificationDetails;

/** Details of label text entity extraction operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelTextEntityExtractionOperationMetadata *textEntityExtractionDetails;

/** Details of label video classification operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelVideoClassificationOperationMetadata *videoClassificationDetails;

/** Details of label video event operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelVideoEventOperationMetadata *videoEventDetails;

/** Details of label video object detection operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelVideoObjectDetectionOperationMetadata *videoObjectDetectionDetails;

/** Details of label video object tracking operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelVideoObjectTrackingOperationMetadata *videoObjectTrackingDetails;

@end


/**
 *  Statistics about annotation specs.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelStats : GTLRObject

/**
 *  Map of each annotation spec's example count. Key is the annotation spec name
 *  and value is the number of examples for that annotation spec. If the
 *  annotated dataset does not have annotation spec, the map will return a pair
 *  where the key is empty string and value is the total number of annotations.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelStats_ExampleCount *exampleCount;

@end


/**
 *  Map of each annotation spec's example count. Key is the annotation spec name
 *  and value is the number of examples for that annotation spec. If the
 *  annotated dataset does not have annotation spec, the map will return a pair
 *  where the key is empty string and value is the total number of annotations.
 *
 *  @note This class is documented as having more properties of NSNumber (Uses
 *        NSNumber of longLongValue.). Use @c -additionalJSONKeys and @c
 *        -additionalPropertyForName: to get the list of properties and then
 *        fetch them; or @c -additionalProperties to fetch them all at once.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelStats_ExampleCount : GTLRObject
@end


/**
 *  Details of a LabelTextClassification operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelTextClassificationOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelTextEntityExtraction operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelTextEntityExtractionOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoClassification operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelVideoClassificationOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoEvent operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelVideoEventOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoObjectDetection operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelVideoObjectDetectionOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoObjectTracking operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1LabelVideoObjectTrackingOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  The configuration of output data.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1OutputConfig : GTLRObject

/**
 *  Output to a file in Cloud Storage. Should be used for labeling output other
 *  than image segmentation.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1GcsDestination *gcsDestination;

/**
 *  Output to a folder in Cloud Storage. Should be used for image segmentation
 *  or document de-identification labeling outputs.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p1alpha1GcsFolderDestination *gcsFolderDestination;

@end


/**
 *  Metadata of a CreateInstruction operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1CreateInstructionMetadata : GTLRObject

/** Timestamp when create instruction request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  The name of the created Instruction.
 *  projects/{project_id}/instructions/{instruction_id}
 */
@property(nonatomic, copy, nullable) NSString *instruction;

/**
 *  Partial failures encountered. E.g. single files that couldn't be read.
 *  Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

@end


/**
 *  Metadata of an ExportData operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1ExportDataOperationMetadata : GTLRObject

/**
 *  Output only. The name of annotated dataset in format "projects/ * /datasets/
 *  * /annotatedDatasets/ *".
 */
@property(nonatomic, copy, nullable) NSString *annotatedDataset;

/** Output only. Timestamp when export dataset request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Output only. The name of dataset to be exported. "projects/ * /datasets/ *"
 */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Partial failures encountered. E.g. single files that couldn't
 *  be read. Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

@end


/**
 *  Response used for ExportDataset longrunning operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1ExportDataOperationResponse : GTLRObject

/**
 *  Output only. The name of annotated dataset in format "projects/ * /datasets/
 *  * /annotatedDatasets/ *".
 */
@property(nonatomic, copy, nullable) NSString *annotatedDataset;

/** Ouptut only. The name of dataset. "projects/ * /datasets/ *" */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Number of examples exported successfully.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *exportCount;

/** Output only. Statistic infos of labels in the exported dataset. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelStats *labelStats;

/** Output only. output_config in the ExportData request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1OutputConfig *outputConfig;

/**
 *  Output only. Total number of examples requested to export
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *totalCount;

@end


/**
 *  Export destination of the data.Only gcs path is allowed in output_uri.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1GcsDestination : GTLRObject

/**
 *  Required. The format of the gcs destination. Only "text/csv" and
 *  "application/json" are supported.
 */
@property(nonatomic, copy, nullable) NSString *mimeType;

/** Required. The output uri of destination file. */
@property(nonatomic, copy, nullable) NSString *outputUri;

@end


/**
 *  Export folder destination of the data.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1GcsFolderDestination : GTLRObject

/** Required. Cloud Storage directory to export data to. */
@property(nonatomic, copy, nullable) NSString *outputFolderUri;

@end


/**
 *  Configuration for how human labeling task should be done.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig : GTLRObject

/**
 *  Optional. A human-readable description for AnnotatedDataset. The description
 *  can be up to 10000 characters long.
 */
@property(nonatomic, copy, nullable) NSString *annotatedDatasetDescription;

/**
 *  Required. A human-readable name for AnnotatedDataset defined by users.
 *  Maximum of 64 characters .
 */
@property(nonatomic, copy, nullable) NSString *annotatedDatasetDisplayName;

/**
 *  Optional. If you want your own labeling contributors to manage and work on
 *  this labeling request, you can set these contributors here. We will give
 *  them access to the question types in crowdcompute. Note that these emails
 *  must be registered in crowdcompute worker UI:
 *  https://crowd-compute.appspot.com/
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *contributorEmails;

/** Required. Instruction resource name. */
@property(nonatomic, copy, nullable) NSString *instruction;

/**
 *  Optional. A human-readable label used to logically group labeling tasks.
 *  This string must match the regular expression `[a-zA-Z\\\\d_-]{0,128}`.
 */
@property(nonatomic, copy, nullable) NSString *labelGroup;

/**
 *  Optional. The Language of this question, as a
 *  [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is
 *  en-US. Only need to set this when task is language related. For example,
 *  French text classification.
 */
@property(nonatomic, copy, nullable) NSString *languageCode;

/**
 *  Optional. Maximum duration for contributors to answer a question. Maximum is
 *  3600 seconds. Default is 3600 seconds.
 */
@property(nonatomic, strong, nullable) GTLRDuration *questionDuration;

/**
 *  Optional. Replication of questions. Each question will be sent to up to this
 *  number of contributors to label. Aggregated answers will be returned.
 *  Default is set to 1. For image related labeling, valid values are 1, 3, 5.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *replicaCount;

/**
 *  Email of the user who started the labeling task and should be notified by
 *  email. If empty no notification will be sent.
 */
@property(nonatomic, copy, nullable) NSString *userEmailAddress;

@end


/**
 *  Metadata of an ImportData operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1ImportDataOperationMetadata : GTLRObject

/** Output only. Timestamp when import dataset request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/** Output only. The name of imported dataset. "projects/ * /datasets/ *" */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Partial failures encountered. E.g. single files that couldn't
 *  be read. Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

@end


/**
 *  Response used for ImportData longrunning operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1ImportDataOperationResponse : GTLRObject

/** Ouptut only. The name of imported dataset. */
@property(nonatomic, copy, nullable) NSString *dataset;

/**
 *  Output only. Number of examples imported successfully.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *importCount;

/**
 *  Output only. Total number of examples requested to import
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *totalCount;

@end


/**
 *  Details of a LabelImageBoundingBox operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageBoundingBoxOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of LabelImageBoundingPoly operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageBoundingPolyOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Metadata of a LabelImageClassification operation.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageClassificationOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelImageOrientedBoundingBox operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageOrientedBoundingBoxOperationMetadata : GTLRObject

/** Basic human annotation config. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of LabelImagePolyline operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImagePolylineOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelImageSegmentation operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageSegmentationOperationMetadata : GTLRObject

/** Basic human annotation config. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Metadata of a labeling operation, such as LabelImage or LabelVideo. Next
 *  tag: 23
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelOperationMetadata : GTLRObject

/**
 *  Output only. The name of annotated dataset in format "projects/ * /datasets/
 *  * /annotatedDatasets/ *".
 */
@property(nonatomic, copy, nullable) NSString *annotatedDataset;

/** Output only. Timestamp when labeling request was created. */
@property(nonatomic, strong, nullable) GTLRDateTime *createTime;

/**
 *  Output only. The name of dataset to be labeled. "projects/ * /datasets/ *"
 */
@property(nonatomic, copy, nullable) NSString *dataset;

/** Details of label image bounding box operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageBoundingBoxOperationMetadata *imageBoundingBoxDetails;

/** Details of label image bounding poly operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageBoundingPolyOperationMetadata *imageBoundingPolyDetails;

/** Details of label image classification operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageClassificationOperationMetadata *imageClassificationDetails;

/** Details of label image oriented bounding box operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageOrientedBoundingBoxOperationMetadata *imageOrientedBoundingBoxDetails;

/** Details of label image polyline operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImagePolylineOperationMetadata *imagePolylineDetails;

/** Details of label image segmentation operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelImageSegmentationOperationMetadata *imageSegmentationDetails;

/**
 *  Output only. Partial failures encountered. E.g. single files that couldn't
 *  be read. Status details field will contain standard GCP error details.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus *> *partialFailures;

/**
 *  Output only. Progress of label operation. Range: [0, 100].
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *progressPercent;

/** Details of label text classification operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelTextClassificationOperationMetadata *textClassificationDetails;

/** Details of label text entity extraction operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelTextEntityExtractionOperationMetadata *textEntityExtractionDetails;

/** Details of label video classification operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelVideoClassificationOperationMetadata *videoClassificationDetails;

/** Details of label video event operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelVideoEventOperationMetadata *videoEventDetails;

/** Details of label video object detection operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelVideoObjectDetectionOperationMetadata *videoObjectDetectionDetails;

/** Details of label video object tracking operation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelVideoObjectTrackingOperationMetadata *videoObjectTrackingDetails;

@end


/**
 *  Statistics about annotation specs.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelStats : GTLRObject

/**
 *  Map of each annotation spec's example count. Key is the annotation spec name
 *  and value is the number of examples for that annotation spec. If the
 *  annotated dataset does not have annotation spec, the map will return a pair
 *  where the key is empty string and value is the total number of annotations.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelStats_ExampleCount *exampleCount;

@end


/**
 *  Map of each annotation spec's example count. Key is the annotation spec name
 *  and value is the number of examples for that annotation spec. If the
 *  annotated dataset does not have annotation spec, the map will return a pair
 *  where the key is empty string and value is the total number of annotations.
 *
 *  @note This class is documented as having more properties of NSNumber (Uses
 *        NSNumber of longLongValue.). Use @c -additionalJSONKeys and @c
 *        -additionalPropertyForName: to get the list of properties and then
 *        fetch them; or @c -additionalProperties to fetch them all at once.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelStats_ExampleCount : GTLRObject
@end


/**
 *  Details of a LabelTextClassification operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelTextClassificationOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelTextEntityExtraction operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelTextEntityExtractionOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoClassification operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelVideoClassificationOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoEvent operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelVideoEventOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoObjectDetection operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelVideoObjectDetectionOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  Details of a LabelVideoObjectTracking operation metadata.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1LabelVideoObjectTrackingOperationMetadata : GTLRObject

/** Basic human annotation config used in labeling request. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1HumanAnnotationConfig *basicConfig;

@end


/**
 *  The configuration of output data.
 */
@interface GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1OutputConfig : GTLRObject

/**
 *  Output to a file in Cloud Storage. Should be used for labeling output other
 *  than image segmentation.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1GcsDestination *gcsDestination;

/**
 *  Output to a folder in Cloud Storage. Should be used for image segmentation
 *  or document de-identification labeling outputs.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleCloudDatalabelingV1p2alpha1GcsFolderDestination *gcsFolderDestination;

@end


/**
 *  The response message for Operations.ListOperations.
 *
 *  @note This class supports NSFastEnumeration and indexed subscripting over
 *        its "operations" property. If returned as the result of a query, it
 *        should support automatic pagination (when @c shouldFetchNextPages is
 *        enabled).
 */
@interface GTLRDataLabeling_GoogleLongrunningListOperationsResponse : GTLRCollectionObject

/** The standard List next-page token. */
@property(nonatomic, copy, nullable) NSString *nextPageToken;

/**
 *  A list of operations that matches the specified filter in the request.
 *
 *  @note This property is used to support NSFastEnumeration and indexed
 *        subscripting on this class.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleLongrunningOperation *> *operations;

/**
 *  Unordered list. Unreachable resources. Populated when the request sets
 *  `ListOperationsRequest.return_partial_success` and reads across collections.
 *  For example, when attempting to list all resources across all supported
 *  locations.
 */
@property(nonatomic, strong, nullable) NSArray<NSString *> *unreachable;

@end


/**
 *  This resource represents a long-running operation that is the result of a
 *  network API call.
 */
@interface GTLRDataLabeling_GoogleLongrunningOperation : GTLRObject

/**
 *  If the value is `false`, it means the operation is still in progress. If
 *  `true`, the operation is completed, and either `error` or `response` is
 *  available.
 *
 *  Uses NSNumber of boolValue.
 */
@property(nonatomic, strong, nullable) NSNumber *done;

/** The error result of the operation in case of failure or cancellation. */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleRpcStatus *error;

/**
 *  Service-specific metadata associated with the operation. It typically
 *  contains progress information and common metadata such as create time. Some
 *  services might not provide such metadata. Any method that returns a
 *  long-running operation should document the metadata type, if any.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleLongrunningOperation_Metadata *metadata;

/**
 *  The server-assigned name, which is only unique within the same service that
 *  originally returns it. If you use the default HTTP mapping, the `name`
 *  should be a resource name ending with `operations/{unique_id}`.
 */
@property(nonatomic, copy, nullable) NSString *name;

/**
 *  The normal, successful response of the operation. If the original method
 *  returns no data on success, such as `Delete`, the response is
 *  `google.protobuf.Empty`. If the original method is standard
 *  `Get`/`Create`/`Update`, the response should be the resource. For other
 *  methods, the response should have the type `XxxResponse`, where `Xxx` is the
 *  original method name. For example, if the original method name is
 *  `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
 */
@property(nonatomic, strong, nullable) GTLRDataLabeling_GoogleLongrunningOperation_Response *response;

@end


/**
 *  Service-specific metadata associated with the operation. It typically
 *  contains progress information and common metadata such as create time. Some
 *  services might not provide such metadata. Any method that returns a
 *  long-running operation should document the metadata type, if any.
 *
 *  @note This class is documented as having more properties of any valid JSON
 *        type. Use @c -additionalJSONKeys and @c -additionalPropertyForName: to
 *        get the list of properties and then fetch them; or @c
 *        -additionalProperties to fetch them all at once.
 */
@interface GTLRDataLabeling_GoogleLongrunningOperation_Metadata : GTLRObject
@end


/**
 *  The normal, successful response of the operation. If the original method
 *  returns no data on success, such as `Delete`, the response is
 *  `google.protobuf.Empty`. If the original method is standard
 *  `Get`/`Create`/`Update`, the response should be the resource. For other
 *  methods, the response should have the type `XxxResponse`, where `Xxx` is the
 *  original method name. For example, if the original method name is
 *  `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
 *
 *  @note This class is documented as having more properties of any valid JSON
 *        type. Use @c -additionalJSONKeys and @c -additionalPropertyForName: to
 *        get the list of properties and then fetch them; or @c
 *        -additionalProperties to fetch them all at once.
 */
@interface GTLRDataLabeling_GoogleLongrunningOperation_Response : GTLRObject
@end


/**
 *  A generic empty message that you can re-use to avoid defining duplicated
 *  empty messages in your APIs. A typical example is to use it as the request
 *  or the response type of an API method. For instance: service Foo { rpc
 *  Bar(google.protobuf.Empty) returns (google.protobuf.Empty); }
 */
@interface GTLRDataLabeling_GoogleProtobufEmpty : GTLRObject
@end


/**
 *  The `Status` type defines a logical error model that is suitable for
 *  different programming environments, including REST APIs and RPC APIs. It is
 *  used by [gRPC](https://github.com/grpc). Each `Status` message contains
 *  three pieces of data: error code, error message, and error details. You can
 *  find out more about this error model and how to work with it in the [API
 *  Design Guide](https://cloud.google.com/apis/design/errors).
 */
@interface GTLRDataLabeling_GoogleRpcStatus : GTLRObject

/**
 *  The status code, which should be an enum value of google.rpc.Code.
 *
 *  Uses NSNumber of intValue.
 */
@property(nonatomic, strong, nullable) NSNumber *code;

/**
 *  A list of messages that carry the error details. There is a common set of
 *  message types for APIs to use.
 */
@property(nonatomic, strong, nullable) NSArray<GTLRDataLabeling_GoogleRpcStatus_Details_Item *> *details;

/**
 *  A developer-facing error message, which should be in English. Any
 *  user-facing error message should be localized and sent in the
 *  google.rpc.Status.details field, or localized by the client.
 */
@property(nonatomic, copy, nullable) NSString *message;

@end


/**
 *  GTLRDataLabeling_GoogleRpcStatus_Details_Item
 *
 *  @note This class is documented as having more properties of any valid JSON
 *        type. Use @c -additionalJSONKeys and @c -additionalPropertyForName: to
 *        get the list of properties and then fetch them; or @c
 *        -additionalProperties to fetch them all at once.
 */
@interface GTLRDataLabeling_GoogleRpcStatus_Details_Item : GTLRObject
@end

NS_ASSUME_NONNULL_END

#pragma clang diagnostic pop
